{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369c3062",
   "metadata": {},
   "source": [
    "Sergi Flores i Sam Brumwell\n",
    "\n",
    "# Pràctica 4: Similitud de Text Semàntic (STS) per al Català\n",
    "\n",
    "**Objectiu**: Aquest treball té com a objectiu principal desenvolupar, implementar i avaluar diferents arquitectures de models per a la tasca de similitud semàntica en català utilitzant el dataset STS-ca del projecte AINA, comparant varies tècniques i arquitectures per tal de veure les seves fortaleses i debilitats i seleccionar la més addient per aquesta tasca.\n",
    "\n",
    "\n",
    "**Mètriques**: L'avaluació dels models es realitza mitjançant la **correlació de Pearson** com a mètrica principal, complementada amb l'error quadràtic mitjà (MSE) i l'error absolut mitjà (MAE). Aquesta aproximació permet mesurar tant la qualitat de l'ordenació de similituds com la precisió numèrica de les prediccions.\n",
    "\n",
    "## Estructura de la Pràctica:\n",
    "1. **Preparació d'Embeddings** - Carregar i truncar embeddings Word2Vec\n",
    "2. **Models Baseline** - Similitud cosinus simple\n",
    "3. **Model 1**: Embeddings Agregats - Vectors de frase concatenats\n",
    "4. **Model 2**: Seqüència d'Embeddings - Amb mecanisme d'atenció\n",
    "5. **Experimentació Avançada** - Comparació amb altres embeddings\n",
    "6. **Conclusions i Observacions** - Comparativa global\n",
    "7. **Entrenament amb dades TECLA** - Entrenar un model de classificació"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfce3b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "# Imports necessaris\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Optional, Dict, Union\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Configuració de GPU (opcional)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d1369",
   "metadata": {},
   "source": [
    "## 1. Carrega del Dataset STS-ca\n",
    "\n",
    "Aquí carreguem el dataset \"STS-ca\" (Semantic Textual Similarity for Catalan) del projecte AINA, utilitzant la llibreria `datasets` de Hugging Face. Aquest dataset conté parells de frases en català i una etiqueta numèrica que indica el seu grau de similitud semàntica (normalment en una escala de 0 a 5).\n",
    "\n",
    "El dataset es divideix en tres parts:\n",
    "- `train`: conjunt d'entrenament, utilitzat per ajustar els paràmetres dels models.\n",
    "- `test`: conjunt de prova, utilitzat per a l'avaluació final del model seleccionat.\n",
    "- `validation`: conjunt de validació, utilitzat per monitorar el rendiment durant l'entrenament i per a l'ajust d'hiperparàmetres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91201ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregant dataset STS-ca...\n",
      "Train samples: 2073\n",
      "Test samples: 500\n",
      "Validation samples: 500\n",
      "Label range: 0.00 - 5.00\n",
      "\n",
      "Exemples del dataset:\n",
      "Frase 1: Atorga per primer cop les mencions Encarna Sanahuja a la inclusió de la perspectiva de gènere en docència Universitària\n",
      "Frase 2: Creen la menció M. Encarna Sanahuja a la inclusió de la perspectiva de gènere en docència universitària\n",
      "Similitud: 3.5\n",
      "--------------------------------------------------\n",
      "Frase 1: Finalment, afegiu-hi els bolets que haureu saltat en una paella amb oli i deixeu-ho coure tot junt durant 5 minuts.\n",
      "Frase 2: Finalment, poseu-hi les minipastanagues tallades a dauets, els pèsols, rectifiqueu-ho de sal i deixeu-ho coure tot junt durant un parell de minuts més.\n",
      "Similitud: 1.25\n",
      "--------------------------------------------------\n",
      "Frase 1: El TC suspèn el pla d'acció exterior i de relacions amb la UE de la Generalitat\n",
      "Frase 2: El Constitucional manté la suspensió del pla estratègic d'acció exterior i relacions amb la UE\n",
      "Similitud: 3.67\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Carregar el dataset STS-ca\n",
    "print(\"Carregant dataset STS-ca...\")\n",
    "train_data = load_dataset(\"projecte-aina/sts-ca\", split=\"train\")\n",
    "test_data = load_dataset(\"projecte-aina/sts-ca\", split=\"test\") \n",
    "val_data = load_dataset(\"projecte-aina/sts-ca\", split=\"validation\")\n",
    "\n",
    "# Convertir a DataFrame per facilitar la manipulació\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "val_df = pd.DataFrame(val_data)\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Label range: {train_df['label'].min():.2f} - {train_df['label'].max():.2f}\")\n",
    "\n",
    "# Mostrar alguns exemples\n",
    "print(\"\\nExemples del dataset:\")\n",
    "for i in range(3):\n",
    "    print(f\"Frase 1: {train_df.iloc[i]['sentence_1']}\")\n",
    "    print(f\"Frase 2: {train_df.iloc[i]['sentence_2']}\")\n",
    "    print(f\"Similitud: {train_df.iloc[i]['label']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721b324",
   "metadata": {},
   "source": [
    "## 2. Preparació d'Embeddings Word2Vec\n",
    "\n",
    "En aquesta secció, carreguem embeddings de paraules pre-entrenats. Utilitzarem el model Word2Vec `cc.ca.300.vec`, que conté vectors de 300 dimensions per a paraules en català."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643b615e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregant model Word2Vec...\n",
      "Model carregat amb èxit. Vocabulari: 2000000 paraules\n",
      "Dimensió dels vectors: 300\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Carregar el model Word2Vec pre-entrenat\n",
    "WV_MODEL_PATH = '../cc.ca.300.vec'\n",
    "\n",
    "print(\"Carregant model Word2Vec...\")\n",
    "\n",
    "kv_model = KeyedVectors.load_word2vec_format(WV_MODEL_PATH, binary=False)\n",
    "print(f\"Model carregat amb èxit. Vocabulari: {len(kv_model.key_to_index)} paraules\")\n",
    "print(f\"Dimensió dels vectors: {kv_model.vector_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4785bf1d",
   "metadata": {},
   "source": [
    "A continuació mostrem alguns exemples dels embeddings generats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fbc2b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector per 'casa': [-0.0359 -0.0161 -0.0268  0.0022 -0.0873]... (dim=300)\n",
      "Vector per 'gat': [ 0.0061  0.0675 -0.0248 -0.0541 -0.0722]... (dim=300)\n",
      "Vector per 'aigua': [-0.0031  0.0427 -0.0397  0.0366 -0.0551]... (dim=300)\n",
      "Vector per 'carbassot': [-0.0029 -0.0462 -0.0255 -0.0149 -0.0358]... (dim=300)\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'ús\n",
    "test_words = [\"casa\", \"gat\", \"aigua\", \"carbassot\"]\n",
    "for word in test_words:\n",
    "    if word in kv_model:\n",
    "        print(f\"Vector per '{word}': {kv_model[word][:5]}... (dim={kv_model.vector_size})\")\n",
    "    else:\n",
    "        print(f\"Paraula '{word}' no trobada al vocabulari\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4966bb51",
   "metadata": {},
   "source": [
    "\n",
    "#### Truncament d'Embeddings\n",
    "\n",
    "Es defineix la funció `create_truncated_embeddings` per generar versions dels embeddings amb dimensions més petites (50, 100, 150). Això permetrà experimentar com la dimensionalitat dels embeddings afecta el rendiment dels models. El truncament es fa simplement seleccionant les primeres `N` dimensions del vector original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a16476f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creant embeddings de 50 dimensions...\n",
      "  Completat: 2000000 paraules truncades a 50D\n",
      "Creant embeddings de 100 dimensions...\n",
      "  Completat: 2000000 paraules truncades a 100D\n",
      "Creant embeddings de 150 dimensions...\n",
      "  Completat: 2000000 paraules truncades a 150D\n",
      "Creant embeddings de 300 dimensions...\n",
      "  Completat: 2000000 paraules truncades a 300D\n",
      "\n",
      "Versions d'embeddings disponibles: [50, 100, 150, 300]\n"
     ]
    }
   ],
   "source": [
    "# Funció per truncar embeddings a dimensions més petites\n",
    "def create_truncated_embeddings(kv_model, dimensions: List[int]) -> Dict[int, Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Crea versions truncades dels embeddings amb diferents dimensions\n",
    "    \"\"\"\n",
    "    if kv_model is None:\n",
    "        return {}\n",
    "    \n",
    "    truncated_models = {}\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        print(f\"Creant embeddings de {dim} dimensions...\")\n",
    "        truncated_dict = {}\n",
    "        \n",
    "        for word in kv_model.key_to_index:\n",
    "            original_vector = kv_model[word]\n",
    "            truncated_vector = original_vector[:dim]\n",
    "            truncated_dict[word] = truncated_vector\n",
    "            \n",
    "        truncated_models[dim] = truncated_dict\n",
    "        print(f\"  Completat: {len(truncated_dict)} paraules truncades a {dim}D\")\n",
    "    \n",
    "    return truncated_models\n",
    "\n",
    "# Crear versions truncades\n",
    "dimensions = [50, 100, 150, 300]  # Incloem 300 per consistència\n",
    "if kv_model is not None:\n",
    "    truncated_embeddings = create_truncated_embeddings(kv_model, dimensions)\n",
    "    print(f\"\\nVersions d'embeddings disponibles: {list(truncated_embeddings.keys())}\")\n",
    "else:\n",
    "    truncated_embeddings = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6bd55",
   "metadata": {},
   "source": [
    "Visualitzem algun exemple dels embeddings truncats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833692a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model truncat a 50 dimensions:\n",
      "[-0.0359 -0.0161 -0.0268  0.0022 -0.0873  0.003   0.0992 -0.0075  0.068\n",
      " -0.029   0.0186  0.1191  0.0155  0.0375  0.0158  0.0449 -0.1111  0.0606\n",
      "  0.022   0.0341  0.0304 -0.0182 -0.024   0.1791 -0.0036  0.0754 -0.1102\n",
      "  0.0247  0.0228  0.028   0.0685 -0.0146 -0.087  -0.0444  0.0057  0.0172\n",
      "  0.0022  0.1482  0.029  -0.0377  0.0114 -0.044  -0.0019 -0.0501  0.002\n",
      " -0.1389 -0.0044  0.0512 -0.0065  0.0007]\n",
      "Model truncat a 100 dimensions:\n",
      "[-0.0359 -0.0161 -0.0268  0.0022 -0.0873  0.003   0.0992 -0.0075  0.068\n",
      " -0.029   0.0186  0.1191  0.0155  0.0375  0.0158  0.0449 -0.1111  0.0606\n",
      "  0.022   0.0341  0.0304 -0.0182 -0.024   0.1791 -0.0036  0.0754 -0.1102\n",
      "  0.0247  0.0228  0.028   0.0685 -0.0146 -0.087  -0.0444  0.0057  0.0172\n",
      "  0.0022  0.1482  0.029  -0.0377  0.0114 -0.044  -0.0019 -0.0501  0.002\n",
      " -0.1389 -0.0044  0.0512 -0.0065  0.0007  0.0245  0.0052  0.0003  0.0288\n",
      "  0.0476  0.0015  0.1529 -0.0132  0.025  -0.0274  0.0314  0.0709 -0.0816\n",
      " -0.0661  0.0462  0.0075 -0.0541 -0.0488 -0.0282  0.0264  0.0198  0.0271\n",
      " -0.0073  0.0243  0.0406 -0.0808 -0.0458  0.0353 -0.0387  0.0227 -0.044\n",
      " -0.067   0.0412 -0.0122  0.026  -0.0659 -0.0286 -0.0276  0.0097  0.0809\n",
      " -0.0535  0.158  -0.0912  0.043  -0.0738  0.0319  0.0324 -0.0082  0.085\n",
      " -0.0845]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model truncat a 50 dimensions:\")\n",
    "print(truncated_embeddings[50]['casa'])\n",
    "print(\"Model truncat a 100 dimensions:\")\n",
    "print(truncated_embeddings[100]['casa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44726e0e",
   "metadata": {},
   "source": [
    "## 3. Funcions d'Utilitat per Processament de Text\n",
    "\n",
    "Aquesta secció defineix funcions auxiliars clau per al processament de text i la generació d'embeddings de frases, que seran utilitzades pels diferents models.\n",
    "\n",
    "**Funcions Definides:**\n",
    "\n",
    "1.  `preprocess_sentence`:\n",
    "    *   **Objectiu**: Tokenitza la frase.\n",
    "    *   **Funcionament**: Converteix a minúscules i divideix en paraules amb `simple_preprocess`.\n",
    "\n",
    "2.  `get_sentence_embedding_simple`:\n",
    "    *   **Objectiu**: Crea un embedding de frase mitjançant la mitjana dels embeddings de paraules.\n",
    "    *   **Funcionament**: Preprocessa la frase, obté els vectors de paraules existents del diccionari d'embeddings i en calcula la mitjana. Retorna zeros si no hi ha embeddings.\n",
    "\n",
    "3.  `get_sentence_embedding_tfidf`:\n",
    "    *   **Objectiu**: Crea un embedding de frase amb una mitjana ponderada per TF-IDF dels embeddings de paraules.\n",
    "    *   **Funcionament**: Preprocessa la frase, calcula pesos TF-IDF, i fa una mitjana ponderada dels embeddings de paraules. Retorna zeros si no es poden obtenir vectors ponderats.\n",
    "\n",
    "**Preparació del Vocabulari per TF-IDF:**\n",
    "*   Es recullen totes les frases dels conjunts d'entrenament, validació i prova.\n",
    "*   Es preprocessen per extreure totes les paraules i construir un vocabulari global. Aquest vocabulari serà utilitzat per entrenar el `TfidfVectorizer` més endavant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfc8b153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessant frases del dataset...\n",
      "Total de frases processades: 6146\n",
      "Vocabulari únic: 13125 paraules\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Preprocessa una frase: tokenització simple\n",
    "    \"\"\"\n",
    "    return simple_preprocess(sentence.lower())\n",
    "\n",
    "def get_sentence_embedding_simple(sentence: str, embeddings_dict: Dict[str, np.ndarray], \n",
    "                                vector_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Obté l'embedding d'una frase fent la mitjana dels embeddings de les paraules\n",
    "    \"\"\"\n",
    "    words = preprocess_sentence(sentence)\n",
    "    vectors = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in embeddings_dict:\n",
    "            vectors.append(embeddings_dict[word])\n",
    "    \n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "def get_sentence_embedding_tfidf(sentence: str, embeddings_dict: Dict[str, np.ndarray], \n",
    "                               tfidf_vectorizer: TfidfVectorizer, \n",
    "                               feature_names: List[str], vector_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Obté l'embedding d'una frase fent la mitjana ponderada amb TF-IDF\n",
    "    \"\"\"\n",
    "    words = preprocess_sentence(sentence)\n",
    "    \n",
    "    # Calcular TF-IDF per a la frase\n",
    "    tfidf_vector = tfidf_vectorizer.transform([' '.join(words)])\n",
    "    tfidf_scores = tfidf_vector.toarray()[0]\n",
    "    \n",
    "    weighted_vectors = []\n",
    "    weights = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in embeddings_dict and word in feature_names:\n",
    "            word_idx = feature_names.index(word)\n",
    "            weight = tfidf_scores[word_idx]\n",
    "            if weight > 0:\n",
    "                weighted_vectors.append(embeddings_dict[word] * weight)\n",
    "                weights.append(weight)\n",
    "    \n",
    "    if weighted_vectors and sum(weights) > 0:\n",
    "        return np.sum(weighted_vectors, axis=0) / sum(weights)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Preprocessar totes les frases del dataset\n",
    "print(\"Preprocessant frases del dataset...\")\n",
    "all_sentences = (train_df['sentence_1'].tolist() + train_df['sentence_2'].tolist() + \n",
    "                test_df['sentence_1'].tolist() + test_df['sentence_2'].tolist() + \n",
    "                val_df['sentence_1'].tolist() + val_df['sentence_2'].tolist())\n",
    "\n",
    "# Crear vocabulari per TF-IDF\n",
    "all_words = []\n",
    "for sentence in all_sentences:\n",
    "    all_words.extend(preprocess_sentence(sentence))\n",
    "\n",
    "print(f\"Total de frases processades: {len(all_sentences)}\")\n",
    "print(f\"Vocabulari únic: {len(set(all_words))} paraules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c61dd3",
   "metadata": {},
   "source": [
    "## 4. Baseline: Similitud Cosinus\n",
    "\n",
    "Aquesta secció implementa un model baseline simple per establir un punt de referència per a la tasca de STS. L'enfocament consisteix a calcular la similitud cosinus directa entre els embeddings de frases, obtinguts mitjançant la mitjana dels embeddings de paraules Word2Vec.\n",
    "\n",
    "**Objectiu i Metodologia:**\n",
    "\n",
    "El baseline serveix per establir una línia base de rendiment que els models més complexos hauran de superar. S'utilitza la similitud cosinus perquè és una mètrica estàndard per mesurar la similitud semàntica entre vectors d'embedding. Es proven dues variants: mitjana simple dels embeddings de paraules i mitjana ponderada per TF-IDF, aquesta última per donar més pes a paraules més discriminatives.\n",
    "\n",
    "Les similituds cosinus (rang `[-1,1]`) s'escalen a `[0,5]` per coincidir amb les etiquetes del dataset STS-ca. S'avaluen múltiples dimensions d'embedding (50D, 100D, 150D, 300D) per analitzar l'impacte de la dimensionalitat.\n",
    "\n",
    "La mètrica principal d'avaluació és la correlació de Pearson, que mesura com de bé les prediccions del model es correlacionen amb les puntuacions de similitud humanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aab6d303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparant TF-IDF vectorizer...\n",
      "Avaluant baselines de similitud cosinus...\n"
     ]
    }
   ],
   "source": [
    "def evaluate_cosine_baseline(df: pd.DataFrame, embeddings_dict: Dict[str, np.ndarray], \n",
    "                           vector_size: int, use_tfidf: bool = False, \n",
    "                           tfidf_vectorizer=None, feature_names=None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Avalua el baseline de similitud cosinus\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    true_scores = df['label'].values\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        sent1, sent2 = row['sentence_1'], row['sentence_2']\n",
    "        \n",
    "        if use_tfidf and tfidf_vectorizer is not None:\n",
    "            vec1 = get_sentence_embedding_tfidf(sent1, embeddings_dict, tfidf_vectorizer, \n",
    "                                              feature_names, vector_size)\n",
    "            vec2 = get_sentence_embedding_tfidf(sent2, embeddings_dict, tfidf_vectorizer, \n",
    "                                              feature_names, vector_size)\n",
    "        else:\n",
    "            vec1 = get_sentence_embedding_simple(sent1, embeddings_dict, vector_size)\n",
    "            vec2 = get_sentence_embedding_simple(sent2, embeddings_dict, vector_size)\n",
    "        \n",
    "        # Calcular similitud cosinus\n",
    "        if np.all(vec1 == 0) or np.all(vec2 == 0):\n",
    "            sim = 0.0\n",
    "        else:\n",
    "            sim = 1 - cosine(vec1, vec2)\n",
    "        \n",
    "        # Escalar de [-1,1] a [0,5] per coincidir amb les etiquetes\n",
    "        sim_scaled = (sim + 1) * 2.5\n",
    "        similarities.append(sim_scaled)\n",
    "    \n",
    "    # Calcular mètriques\n",
    "    similarities = np.array(similarities)\n",
    "    pearson_corr, _ = pearsonr(true_scores, similarities)\n",
    "    mse = mean_squared_error(true_scores, similarities)\n",
    "    mae = mean_absolute_error(true_scores, similarities)\n",
    "    \n",
    "    return {\n",
    "        'pearson': pearson_corr,\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'predictions': similarities\n",
    "    }\n",
    "\n",
    "# Preparar TF-IDF\n",
    "if kv_model is not None:\n",
    "    print(\"Preparant TF-IDF vectorizer...\")\n",
    "    corpus_for_tfidf = [' '.join(preprocess_sentence(sent)) for sent in all_sentences]\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=10000, lowercase=True)\n",
    "    tfidf_vectorizer.fit(corpus_for_tfidf)\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out().tolist()\n",
    "    \n",
    "    print(\"Avaluant baselines de similitud cosinus...\")\n",
    "    \n",
    "    # Avaluar per diferents dimensions\n",
    "    baseline_results = {}\n",
    "    results_list = []\n",
    "    for dim in [50, 100, 150, 300]:\n",
    "        if dim in truncated_embeddings:\n",
    "            # Mitjana simple\n",
    "            results_simple = evaluate_cosine_baseline(\n",
    "                val_df, truncated_embeddings[dim], dim, use_tfidf=False\n",
    "            )\n",
    "\n",
    "            # Mitjana ponderada TF-IDF\n",
    "            results_tfidf = evaluate_cosine_baseline(\n",
    "                val_df, truncated_embeddings[dim], dim, use_tfidf=True,\n",
    "                tfidf_vectorizer=tfidf_vectorizer, feature_names=feature_names\n",
    "            )\n",
    "\n",
    "            baseline_results[dim] = {\n",
    "                'simple': results_simple,\n",
    "                'tfidf': results_tfidf\n",
    "            }\n",
    "\n",
    "            results_list.append({\n",
    "                'Model': 'Baseline Cosinus Simple',\n",
    "                'Dimensions': f'{dim}D',\n",
    "                'Pearson': results_simple['pearson'],\n",
    "                'MSE': results_simple['mse'],\n",
    "                'MAE': results_simple['mae']\n",
    "            })\n",
    "            results_list.append({\n",
    "                'Model': 'Baseline Cosinus TF-IDF',\n",
    "                'Dimensions': f'{dim}D',\n",
    "                'Pearson': results_tfidf['pearson'],\n",
    "                'MSE': results_tfidf['mse'],\n",
    "                'MAE': results_tfidf['mae']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300eea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARACIÓ MODELS BASELINE COSINUS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_61edd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_61edd_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_61edd_level0_col1\" class=\"col_heading level0 col1\" >Dimensions</th>\n",
       "      <th id=\"T_61edd_level0_col2\" class=\"col_heading level0 col2\" >Pearson</th>\n",
       "      <th id=\"T_61edd_level0_col3\" class=\"col_heading level0 col3\" >MSE</th>\n",
       "      <th id=\"T_61edd_level0_col4\" class=\"col_heading level0 col4\" >MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_61edd_row0_col0\" class=\"data row0 col0\" >Baseline Cosinus Simple</td>\n",
       "      <td id=\"T_61edd_row0_col1\" class=\"data row0 col1\" >50D</td>\n",
       "      <td id=\"T_61edd_row0_col2\" class=\"data row0 col2\" >0.175156</td>\n",
       "      <td id=\"T_61edd_row0_col3\" class=\"data row0 col3\" >6.156660</td>\n",
       "      <td id=\"T_61edd_row0_col4\" class=\"data row0 col4\" >2.335413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61edd_row1_col0\" class=\"data row1 col0\" >Baseline Cosinus TF-IDF</td>\n",
       "      <td id=\"T_61edd_row1_col1\" class=\"data row1 col1\" >50D</td>\n",
       "      <td id=\"T_61edd_row1_col2\" class=\"data row1 col2\" >0.288679</td>\n",
       "      <td id=\"T_61edd_row1_col3\" class=\"data row1 col3\" >5.862487</td>\n",
       "      <td id=\"T_61edd_row1_col4\" class=\"data row1 col4\" >2.279328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61edd_row2_col0\" class=\"data row2 col0\" >Baseline Cosinus Simple</td>\n",
       "      <td id=\"T_61edd_row2_col1\" class=\"data row2 col1\" >100D</td>\n",
       "      <td id=\"T_61edd_row2_col2\" class=\"data row2 col2\" >0.213043</td>\n",
       "      <td id=\"T_61edd_row2_col3\" class=\"data row2 col3\" >5.936303</td>\n",
       "      <td id=\"T_61edd_row2_col4\" class=\"data row2 col4\" >2.290625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61edd_row3_col0\" class=\"data row3 col0\" >Baseline Cosinus TF-IDF</td>\n",
       "      <td id=\"T_61edd_row3_col1\" class=\"data row3 col1\" >100D</td>\n",
       "      <td id=\"T_61edd_row3_col2\" class=\"data row3 col2\" >0.322226</td>\n",
       "      <td id=\"T_61edd_row3_col3\" class=\"data row3 col3\" >5.572608</td>\n",
       "      <td id=\"T_61edd_row3_col4\" class=\"data row3 col4\" >2.219603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61edd_row4_col0\" class=\"data row4 col0\" >Baseline Cosinus Simple</td>\n",
       "      <td id=\"T_61edd_row4_col1\" class=\"data row4 col1\" >150D</td>\n",
       "      <td id=\"T_61edd_row4_col2\" class=\"data row4 col2\" >0.241811</td>\n",
       "      <td id=\"T_61edd_row4_col3\" class=\"data row4 col3\" >5.704033</td>\n",
       "      <td id=\"T_61edd_row4_col4\" class=\"data row4 col4\" >2.242433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61edd_row5_col0\" class=\"data row5 col0\" >Baseline Cosinus TF-IDF</td>\n",
       "      <td id=\"T_61edd_row5_col1\" class=\"data row5 col1\" >150D</td>\n",
       "      <td id=\"T_61edd_row5_col2\" class=\"data row5 col2\" >0.356393</td>\n",
       "      <td id=\"T_61edd_row5_col3\" class=\"data row5 col3\" >5.332225</td>\n",
       "      <td id=\"T_61edd_row5_col4\" class=\"data row5 col4\" >2.169574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61edd_row6_col0\" class=\"data row6 col0\" >Baseline Cosinus Simple</td>\n",
       "      <td id=\"T_61edd_row6_col1\" class=\"data row6 col1\" >300D</td>\n",
       "      <td id=\"T_61edd_row6_col2\" class=\"data row6 col2\" >0.243586</td>\n",
       "      <td id=\"T_61edd_row6_col3\" class=\"data row6 col3\" >5.424708</td>\n",
       "      <td id=\"T_61edd_row6_col4\" class=\"data row6 col4\" >2.181605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_61edd_row7_col0\" class=\"data row7 col0\" >Baseline Cosinus TF-IDF</td>\n",
       "      <td id=\"T_61edd_row7_col1\" class=\"data row7 col1\" >300D</td>\n",
       "      <td id=\"T_61edd_row7_col2\" class=\"data row7 col2\" >0.354348</td>\n",
       "      <td id=\"T_61edd_row7_col3\" class=\"data row7 col3\" >5.084731</td>\n",
       "      <td id=\"T_61edd_row7_col4\" class=\"data row7 col4\" >2.115081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28239fc2bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n=== COMPARACIÓ MODELS BASELINE COSINUS ===\")\n",
    "df_baseline_results = pd.DataFrame(results_list)\n",
    "display(df_baseline_results.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dea643",
   "metadata": {},
   "source": [
    "### Anàlisi dels Resultats Baseline\n",
    "\n",
    "L'avaluació dels models baseline mostra patrons clars sobre l'impacte de la dimensionalitat i les tècniques de ponderació en la similitud semàntica. Els resultats revelen una millora consistent amb l'augment de dimensions: el model simple passa de 0.175 a 0.244 Pearson (39% de millora) entre 50D i 300D, amb els guanys més significatius concentrats fins a 150D.\n",
    "\n",
    "La ponderació TF-IDF supera sistemàticament la mitjana simple, proporcionant millores del 65% en dimensions baixes i del 47% aproximadament en dimensions mitjanes. Aquesta superioritat consistent demostra la importància de ponderar adequadament les paraules discriminatives per capturar millor la similitud semàntica.\n",
    "\n",
    "La configuració òptima es troba en TF-IDF amb 150D (Pearson: 0.356), oferint el millor equilibri rendiment-eficiència, ja que l'augment a 300D només aporta millores marginals. Tots els models mostren valors MSE consistents al voltant de 5-6, indicant prediccions dins d'un rang raonable.\n",
    "\n",
    "Aquest baseline estableix un **llindar de referència de 0.356 Pearson** que els models més sofisticats hauran de superar per demostrar millores significatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b53801",
   "metadata": {},
   "source": [
    "## 5. Model 1: Regressió amb Embeddings Agregats\n",
    "\n",
    "Aquest primer model neuronal representa un salt qualitatiu respecte als baselines, implementant una arquitectura de xarxa neuronal densa per aprendre relacions complexes entre parells de frases.\n",
    "\n",
    "### Arquitectura i Metodologia\n",
    "\n",
    "L'aproximació dels embeddings agregats es basa en convertir cada frase a un vector de longitud fixa mitjançant la mitjana dels embeddings de les seves paraules. Aquests vectors s'alimenten a una xarxa neuronal que aprèn a predir la similitud semàntica directament des de la representació vectorial de les frases.\n",
    "\n",
    "L'arquitectura del model segueix un disseny jeràrquic amb múltiples capes denses. Primer, els dos vectors de frase es concatenen per formar un vector d'entrada de dimensió `2 × embedding_dim`. Aquest vector passa per capes de normalització per lotes, seguides de capes denses amb activació ReLU i regularització mitjançant dropout. La sortida final és una predicció numèrica de similitud obtinguda amb una capa densa lineal.\n",
    "\n",
    "### Implementació i Entrenament\n",
    "\n",
    "El model incorpora diverses tècniques de regularització per evitar l'overfitting: batch normalization per estabilitzar l'entrenament, dropout amb taxes variables segons la profunditat de la capa, i early stopping basat en la loss de validació. L'optimitzador Adam amb learning rate adaptatiu permet una convergència eficient.\n",
    "\n",
    "Durant l'entrenament, es proven diferents dimensions d'embedding (50D, 100D, 150D, 300D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98d3d17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entrenant Model Agregat 50D ===\n",
      "Forma de les dades: X1_train=(2073, 50), Y_train=(2073,)\n",
      "Rang Y_train: [0.00, 5.00]\n",
      "WARNING:tensorflow:From C:\\Users\\11ser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.2101 - mae: 1.2375 - root_mean_squared_error: 1.5138 - val_loss: 0.7148 - val_mae: 0.6504 - val_root_mean_squared_error: 0.8620 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9476 - mae: 0.9488 - root_mean_squared_error: 1.1876 - val_loss: 0.7000 - val_mae: 0.6508 - val_root_mean_squared_error: 0.8520 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8202 - mae: 0.8100 - root_mean_squared_error: 1.0200 - val_loss: 0.6883 - val_mae: 0.6535 - val_root_mean_squared_error: 0.8481 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7857 - mae: 0.7781 - root_mean_squared_error: 0.9920 - val_loss: 0.6797 - val_mae: 0.6483 - val_root_mean_squared_error: 0.8455 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7128 - mae: 0.6946 - root_mean_squared_error: 0.8958 - val_loss: 0.6665 - val_mae: 0.6450 - val_root_mean_squared_error: 0.8388 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6848 - mae: 0.6712 - root_mean_squared_error: 0.8619 - val_loss: 0.6569 - val_mae: 0.6402 - val_root_mean_squared_error: 0.8361 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6792 - mae: 0.6745 - root_mean_squared_error: 0.8797 - val_loss: 0.6451 - val_mae: 0.6385 - val_root_mean_squared_error: 0.8319 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6146 - mae: 0.6028 - root_mean_squared_error: 0.7777 - val_loss: 0.6346 - val_mae: 0.6423 - val_root_mean_squared_error: 0.8319 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6186 - mae: 0.6165 - root_mean_squared_error: 0.8034 - val_loss: 0.6229 - val_mae: 0.6393 - val_root_mean_squared_error: 0.8270 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5853 - mae: 0.5854 - root_mean_squared_error: 0.7686 - val_loss: 0.6135 - val_mae: 0.6445 - val_root_mean_squared_error: 0.8264 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5878 - mae: 0.5992 - root_mean_squared_error: 0.7785 - val_loss: 0.5996 - val_mae: 0.6345 - val_root_mean_squared_error: 0.8165 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5651 - mae: 0.5850 - root_mean_squared_error: 0.7608 - val_loss: 0.6039 - val_mae: 0.6571 - val_root_mean_squared_error: 0.8387 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5263 - mae: 0.5377 - root_mean_squared_error: 0.7015 - val_loss: 0.5824 - val_mae: 0.6338 - val_root_mean_squared_error: 0.8144 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5122 - mae: 0.5285 - root_mean_squared_error: 0.6921 - val_loss: 0.5714 - val_mae: 0.6317 - val_root_mean_squared_error: 0.8089 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4885 - mae: 0.5076 - root_mean_squared_error: 0.6663 - val_loss: 0.5650 - val_mae: 0.6335 - val_root_mean_squared_error: 0.8095 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4741 - mae: 0.4988 - root_mean_squared_error: 0.6471 - val_loss: 0.5526 - val_mae: 0.6225 - val_root_mean_squared_error: 0.8016 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4625 - mae: 0.4975 - root_mean_squared_error: 0.6390 - val_loss: 0.5492 - val_mae: 0.6264 - val_root_mean_squared_error: 0.8061 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4497 - mae: 0.4861 - root_mean_squared_error: 0.6281 - val_loss: 0.5289 - val_mae: 0.6057 - val_root_mean_squared_error: 0.7830 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4307 - mae: 0.4669 - root_mean_squared_error: 0.6086 - val_loss: 0.5279 - val_mae: 0.6119 - val_root_mean_squared_error: 0.7912 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4240 - mae: 0.4671 - root_mean_squared_error: 0.6080 - val_loss: 0.5217 - val_mae: 0.6117 - val_root_mean_squared_error: 0.7949 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4216 - mae: 0.4738 - root_mean_squared_error: 0.6198 - val_loss: 0.5119 - val_mae: 0.6047 - val_root_mean_squared_error: 0.7884 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4007 - mae: 0.4525 - root_mean_squared_error: 0.5935 - val_loss: 0.5066 - val_mae: 0.6055 - val_root_mean_squared_error: 0.7893 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3813 - mae: 0.4303 - root_mean_squared_error: 0.5656 - val_loss: 0.5041 - val_mae: 0.6091 - val_root_mean_squared_error: 0.7942 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3803 - mae: 0.4431 - root_mean_squared_error: 0.5730 - val_loss: 0.4910 - val_mae: 0.6008 - val_root_mean_squared_error: 0.7845 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3645 - mae: 0.4293 - root_mean_squared_error: 0.5554 - val_loss: 0.4924 - val_mae: 0.6088 - val_root_mean_squared_error: 0.7955 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3684 - mae: 0.4405 - root_mean_squared_error: 0.5733 - val_loss: 0.4820 - val_mae: 0.6012 - val_root_mean_squared_error: 0.7887 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3390 - mae: 0.4047 - root_mean_squared_error: 0.5285 - val_loss: 0.4838 - val_mae: 0.6116 - val_root_mean_squared_error: 0.8005 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3423 - mae: 0.4122 - root_mean_squared_error: 0.5464 - val_loss: 0.4785 - val_mae: 0.6140 - val_root_mean_squared_error: 0.7980 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3298 - mae: 0.4062 - root_mean_squared_error: 0.5330 - val_loss: 0.4758 - val_mae: 0.6183 - val_root_mean_squared_error: 0.8040 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3225 - mae: 0.4002 - root_mean_squared_error: 0.5292 - val_loss: 0.4770 - val_mae: 0.6232 - val_root_mean_squared_error: 0.8158 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3070 - mae: 0.3855 - root_mean_squared_error: 0.5043 - val_loss: 0.4650 - val_mae: 0.6145 - val_root_mean_squared_error: 0.8056 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3016 - mae: 0.3851 - root_mean_squared_error: 0.5071 - val_loss: 0.4583 - val_mae: 0.6125 - val_root_mean_squared_error: 0.8048 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2955 - mae: 0.3859 - root_mean_squared_error: 0.5037 - val_loss: 0.4503 - val_mae: 0.6086 - val_root_mean_squared_error: 0.7942 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2912 - mae: 0.3796 - root_mean_squared_error: 0.5050 - val_loss: 0.4481 - val_mae: 0.6135 - val_root_mean_squared_error: 0.7994 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2875 - mae: 0.3854 - root_mean_squared_error: 0.5060 - val_loss: 0.4441 - val_mae: 0.6090 - val_root_mean_squared_error: 0.8018 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2719 - mae: 0.3705 - root_mean_squared_error: 0.4814 - val_loss: 0.4391 - val_mae: 0.6135 - val_root_mean_squared_error: 0.7998 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2716 - mae: 0.3730 - root_mean_squared_error: 0.4914 - val_loss: 0.4431 - val_mae: 0.6226 - val_root_mean_squared_error: 0.8127 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2709 - mae: 0.3795 - root_mean_squared_error: 0.5003 - val_loss: 0.4380 - val_mae: 0.6173 - val_root_mean_squared_error: 0.8124 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2591 - mae: 0.3645 - root_mean_squared_error: 0.4800 - val_loss: 0.4328 - val_mae: 0.6222 - val_root_mean_squared_error: 0.8108 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2584 - mae: 0.3722 - root_mean_squared_error: 0.4891 - val_loss: 0.4206 - val_mae: 0.6112 - val_root_mean_squared_error: 0.7980 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2485 - mae: 0.3640 - root_mean_squared_error: 0.4746 - val_loss: 0.4186 - val_mae: 0.6122 - val_root_mean_squared_error: 0.7981 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2451 - mae: 0.3641 - root_mean_squared_error: 0.4738 - val_loss: 0.4145 - val_mae: 0.6096 - val_root_mean_squared_error: 0.7968 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2346 - mae: 0.3539 - root_mean_squared_error: 0.4578 - val_loss: 0.4084 - val_mae: 0.6065 - val_root_mean_squared_error: 0.7928 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2220 - mae: 0.3326 - root_mean_squared_error: 0.4389 - val_loss: 0.4031 - val_mae: 0.6051 - val_root_mean_squared_error: 0.7893 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2200 - mae: 0.3367 - root_mean_squared_error: 0.4392 - val_loss: 0.4132 - val_mae: 0.6173 - val_root_mean_squared_error: 0.8148 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2170 - mae: 0.3370 - root_mean_squared_error: 0.4393 - val_loss: 0.4079 - val_mae: 0.6140 - val_root_mean_squared_error: 0.8139 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2149 - mae: 0.3392 - root_mean_squared_error: 0.4420 - val_loss: 0.3999 - val_mae: 0.6078 - val_root_mean_squared_error: 0.8021 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2159 - mae: 0.3477 - root_mean_squared_error: 0.4483 - val_loss: 0.4107 - val_mae: 0.6249 - val_root_mean_squared_error: 0.8207 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2055 - mae: 0.3325 - root_mean_squared_error: 0.4320 - val_loss: 0.4077 - val_mae: 0.6284 - val_root_mean_squared_error: 0.8190 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1927 - mae: 0.3102 - root_mean_squared_error: 0.4070 - val_loss: 0.3966 - val_mae: 0.6140 - val_root_mean_squared_error: 0.8101 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1900 - mae: 0.3159 - root_mean_squared_error: 0.4038 - val_loss: 0.4029 - val_mae: 0.6277 - val_root_mean_squared_error: 0.8174 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1935 - mae: 0.3246 - root_mean_squared_error: 0.4219 - val_loss: 0.3970 - val_mae: 0.6304 - val_root_mean_squared_error: 0.8165 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1915 - mae: 0.3254 - root_mean_squared_error: 0.4214 - val_loss: 0.3875 - val_mae: 0.6150 - val_root_mean_squared_error: 0.8032 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1853 - mae: 0.3125 - root_mean_squared_error: 0.4108 - val_loss: 0.3861 - val_mae: 0.6143 - val_root_mean_squared_error: 0.8039 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1823 - mae: 0.3191 - root_mean_squared_error: 0.4083 - val_loss: 0.3847 - val_mae: 0.6127 - val_root_mean_squared_error: 0.8089 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1768 - mae: 0.3083 - root_mean_squared_error: 0.3999 - val_loss: 0.3850 - val_mae: 0.6154 - val_root_mean_squared_error: 0.8127 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1769 - mae: 0.3107 - root_mean_squared_error: 0.4069 - val_loss: 0.3914 - val_mae: 0.6265 - val_root_mean_squared_error: 0.8243 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1747 - mae: 0.3110 - root_mean_squared_error: 0.4043 - val_loss: 0.3807 - val_mae: 0.6185 - val_root_mean_squared_error: 0.8093 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1725 - mae: 0.3048 - root_mean_squared_error: 0.4046 - val_loss: 0.3804 - val_mae: 0.6193 - val_root_mean_squared_error: 0.8093 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1718 - mae: 0.3104 - root_mean_squared_error: 0.4059 - val_loss: 0.3749 - val_mae: 0.6128 - val_root_mean_squared_error: 0.8060 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1676 - mae: 0.3118 - root_mean_squared_error: 0.3984 - val_loss: 0.3711 - val_mae: 0.6125 - val_root_mean_squared_error: 0.8002 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1608 - mae: 0.2916 - root_mean_squared_error: 0.3868 - val_loss: 0.3703 - val_mae: 0.6164 - val_root_mean_squared_error: 0.8054 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1604 - mae: 0.2957 - root_mean_squared_error: 0.3876 - val_loss: 0.3734 - val_mae: 0.6184 - val_root_mean_squared_error: 0.8112 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1577 - mae: 0.2987 - root_mean_squared_error: 0.3840 - val_loss: 0.3717 - val_mae: 0.6183 - val_root_mean_squared_error: 0.8120 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1540 - mae: 0.2922 - root_mean_squared_error: 0.3783 - val_loss: 0.3807 - val_mae: 0.6322 - val_root_mean_squared_error: 0.8285 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1503 - mae: 0.2850 - root_mean_squared_error: 0.3712 - val_loss: 0.3653 - val_mae: 0.6150 - val_root_mean_squared_error: 0.8076 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1523 - mae: 0.2928 - root_mean_squared_error: 0.3814 - val_loss: 0.3684 - val_mae: 0.6156 - val_root_mean_squared_error: 0.8192 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1471 - mae: 0.2846 - root_mean_squared_error: 0.3713 - val_loss: 0.3648 - val_mae: 0.6168 - val_root_mean_squared_error: 0.8116 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1510 - mae: 0.2953 - root_mean_squared_error: 0.3852 - val_loss: 0.3701 - val_mae: 0.6227 - val_root_mean_squared_error: 0.8194 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1485 - mae: 0.2966 - root_mean_squared_error: 0.3806 - val_loss: 0.3705 - val_mae: 0.6224 - val_root_mean_squared_error: 0.8220 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1400 - mae: 0.2786 - root_mean_squared_error: 0.3601 - val_loss: 0.3571 - val_mae: 0.6051 - val_root_mean_squared_error: 0.8038 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1446 - mae: 0.2882 - root_mean_squared_error: 0.3759 - val_loss: 0.3612 - val_mae: 0.6138 - val_root_mean_squared_error: 0.8090 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1430 - mae: 0.2840 - root_mean_squared_error: 0.3760 - val_loss: 0.3653 - val_mae: 0.6220 - val_root_mean_squared_error: 0.8191 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1454 - mae: 0.2954 - root_mean_squared_error: 0.3843 - val_loss: 0.3628 - val_mae: 0.6184 - val_root_mean_squared_error: 0.8177 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1369 - mae: 0.2800 - root_mean_squared_error: 0.3620 - val_loss: 0.3627 - val_mae: 0.6234 - val_root_mean_squared_error: 0.8141 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1410 - mae: 0.2912 - root_mean_squared_error: 0.3750 - val_loss: 0.3580 - val_mae: 0.6153 - val_root_mean_squared_error: 0.8079 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1410 - mae: 0.2933 - root_mean_squared_error: 0.3776 - val_loss: 0.3722 - val_mae: 0.6318 - val_root_mean_squared_error: 0.8357 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1370 - mae: 0.2855 - root_mean_squared_error: 0.3682\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1371 - mae: 0.2857 - root_mean_squared_error: 0.3684 - val_loss: 0.3774 - val_mae: 0.6425 - val_root_mean_squared_error: 0.8464 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1381 - mae: 0.2871 - root_mean_squared_error: 0.3724 - val_loss: 0.3579 - val_mae: 0.6172 - val_root_mean_squared_error: 0.8154 - learning_rate: 3.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1252 - mae: 0.2616 - root_mean_squared_error: 0.3381 - val_loss: 0.3550 - val_mae: 0.6156 - val_root_mean_squared_error: 0.8105 - learning_rate: 3.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1252 - mae: 0.2647 - root_mean_squared_error: 0.3406 - val_loss: 0.3521 - val_mae: 0.6125 - val_root_mean_squared_error: 0.8062 - learning_rate: 3.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1145 - mae: 0.2375 - root_mean_squared_error: 0.3092 - val_loss: 0.3555 - val_mae: 0.6192 - val_root_mean_squared_error: 0.8144 - learning_rate: 3.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1136 - mae: 0.2398 - root_mean_squared_error: 0.3086 - val_loss: 0.3543 - val_mae: 0.6182 - val_root_mean_squared_error: 0.8125 - learning_rate: 3.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1129 - mae: 0.2399 - root_mean_squared_error: 0.3098 - val_loss: 0.3503 - val_mae: 0.6126 - val_root_mean_squared_error: 0.8057 - learning_rate: 3.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1123 - mae: 0.2389 - root_mean_squared_error: 0.3094 - val_loss: 0.3479 - val_mae: 0.6084 - val_root_mean_squared_error: 0.8022 - learning_rate: 3.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1063 - mae: 0.2284 - root_mean_squared_error: 0.2913 - val_loss: 0.3471 - val_mae: 0.6106 - val_root_mean_squared_error: 0.8038 - learning_rate: 3.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1075 - mae: 0.2293 - root_mean_squared_error: 0.2983 - val_loss: 0.3459 - val_mae: 0.6100 - val_root_mean_squared_error: 0.8036 - learning_rate: 3.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1081 - mae: 0.2344 - root_mean_squared_error: 0.3026 - val_loss: 0.3434 - val_mae: 0.6078 - val_root_mean_squared_error: 0.8008 - learning_rate: 3.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1103 - mae: 0.2402 - root_mean_squared_error: 0.3120 - val_loss: 0.3429 - val_mae: 0.6100 - val_root_mean_squared_error: 0.8010 - learning_rate: 3.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1051 - mae: 0.2251 - root_mean_squared_error: 0.2981 - val_loss: 0.3431 - val_mae: 0.6089 - val_root_mean_squared_error: 0.8024 - learning_rate: 3.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1051 - mae: 0.2296 - root_mean_squared_error: 0.2993 - val_loss: 0.3436 - val_mae: 0.6116 - val_root_mean_squared_error: 0.8032 - learning_rate: 3.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1008 - mae: 0.2246 - root_mean_squared_error: 0.2868 - val_loss: 0.3432 - val_mae: 0.6097 - val_root_mean_squared_error: 0.8050 - learning_rate: 3.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1001 - mae: 0.2192 - root_mean_squared_error: 0.2868 - val_loss: 0.3404 - val_mae: 0.6054 - val_root_mean_squared_error: 0.8035 - learning_rate: 3.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1001 - mae: 0.2240 - root_mean_squared_error: 0.2890 - val_loss: 0.3444 - val_mae: 0.6138 - val_root_mean_squared_error: 0.8095 - learning_rate: 3.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0986 - mae: 0.2228 - root_mean_squared_error: 0.2861 - val_loss: 0.3465 - val_mae: 0.6146 - val_root_mean_squared_error: 0.8141 - learning_rate: 3.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1011 - mae: 0.2252 - root_mean_squared_error: 0.2969 - val_loss: 0.3438 - val_mae: 0.6127 - val_root_mean_squared_error: 0.8117 - learning_rate: 3.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0977 - mae: 0.2224 - root_mean_squared_error: 0.2873 - val_loss: 0.3436 - val_mae: 0.6115 - val_root_mean_squared_error: 0.8126 - learning_rate: 3.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0978 - mae: 0.2262 - root_mean_squared_error: 0.2897 - val_loss: 0.3425 - val_mae: 0.6111 - val_root_mean_squared_error: 0.8136 - learning_rate: 3.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0974 - mae: 0.2263 - root_mean_squared_error: 0.2901 - val_loss: 0.3428 - val_mae: 0.6128 - val_root_mean_squared_error: 0.8150 - learning_rate: 3.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0956 - mae: 0.2219 - root_mean_squared_error: 0.2863\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0956 - mae: 0.2219 - root_mean_squared_error: 0.2864 - val_loss: 0.3408 - val_mae: 0.6109 - val_root_mean_squared_error: 0.8120 - learning_rate: 3.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Resultats 50D - Pearson: 0.382, MSE: 0.646, MAE: 0.605\n",
      "Prediccions - Min: 0.698, Max: 4.318, Mean: 2.500\n",
      "Targets - Min: 0.000, Max: 5.000, Mean: 2.575\n",
      "\n",
      "=== Entrenant Model Agregat 100D ===\n",
      "Forma de les dades: X1_train=(2073, 100), Y_train=(2073,)\n",
      "Rang Y_train: [0.00, 5.00]\n",
      "Epoch 1/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.2680 - mae: 1.2054 - root_mean_squared_error: 1.4702 - val_loss: 0.7927 - val_mae: 0.6496 - val_root_mean_squared_error: 0.8547 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0073 - mae: 0.9195 - root_mean_squared_error: 1.1565 - val_loss: 0.7848 - val_mae: 0.6499 - val_root_mean_squared_error: 0.8574 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8847 - mae: 0.7897 - root_mean_squared_error: 1.0079 - val_loss: 0.7671 - val_mae: 0.6520 - val_root_mean_squared_error: 0.8504 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8373 - mae: 0.7460 - root_mean_squared_error: 0.9589 - val_loss: 0.7596 - val_mae: 0.6467 - val_root_mean_squared_error: 0.8546 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7932 - mae: 0.7089 - root_mean_squared_error: 0.9028 - val_loss: 0.7371 - val_mae: 0.6573 - val_root_mean_squared_error: 0.8458 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7433 - mae: 0.6611 - root_mean_squared_error: 0.8535 - val_loss: 0.7229 - val_mae: 0.6563 - val_root_mean_squared_error: 0.8427 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7143 - mae: 0.6388 - root_mean_squared_error: 0.8234 - val_loss: 0.7116 - val_mae: 0.6549 - val_root_mean_squared_error: 0.8436 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6863 - mae: 0.6222 - root_mean_squared_error: 0.7991 - val_loss: 0.7024 - val_mae: 0.6657 - val_root_mean_squared_error: 0.8498 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6354 - mae: 0.5661 - root_mean_squared_error: 0.7396 - val_loss: 0.6840 - val_mae: 0.6577 - val_root_mean_squared_error: 0.8396 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6105 - mae: 0.5570 - root_mean_squared_error: 0.7037 - val_loss: 0.6724 - val_mae: 0.6594 - val_root_mean_squared_error: 0.8391 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5924 - mae: 0.5473 - root_mean_squared_error: 0.6962 - val_loss: 0.6525 - val_mae: 0.6445 - val_root_mean_squared_error: 0.8241 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5659 - mae: 0.5196 - root_mean_squared_error: 0.6701 - val_loss: 0.6374 - val_mae: 0.6375 - val_root_mean_squared_error: 0.8165 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5496 - mae: 0.5145 - root_mean_squared_error: 0.6595 - val_loss: 0.6254 - val_mae: 0.6340 - val_root_mean_squared_error: 0.8150 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5231 - mae: 0.4874 - root_mean_squared_error: 0.6367 - val_loss: 0.6055 - val_mae: 0.6164 - val_root_mean_squared_error: 0.7987 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5117 - mae: 0.4875 - root_mean_squared_error: 0.6336 - val_loss: 0.5942 - val_mae: 0.6180 - val_root_mean_squared_error: 0.7962 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4862 - mae: 0.4660 - root_mean_squared_error: 0.6079 - val_loss: 0.5769 - val_mae: 0.6031 - val_root_mean_squared_error: 0.7835 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4614 - mae: 0.4417 - root_mean_squared_error: 0.5755 - val_loss: 0.5829 - val_mae: 0.6273 - val_root_mean_squared_error: 0.8114 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4537 - mae: 0.4495 - root_mean_squared_error: 0.5762 - val_loss: 0.5636 - val_mae: 0.6101 - val_root_mean_squared_error: 0.7925 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4354 - mae: 0.4337 - root_mean_squared_error: 0.5588 - val_loss: 0.5529 - val_mae: 0.6107 - val_root_mean_squared_error: 0.7891 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4223 - mae: 0.4237 - root_mean_squared_error: 0.5516 - val_loss: 0.5391 - val_mae: 0.5998 - val_root_mean_squared_error: 0.7825 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4044 - mae: 0.4101 - root_mean_squared_error: 0.5335 - val_loss: 0.5281 - val_mae: 0.5986 - val_root_mean_squared_error: 0.7768 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3863 - mae: 0.3943 - root_mean_squared_error: 0.5114 - val_loss: 0.5151 - val_mae: 0.5918 - val_root_mean_squared_error: 0.7691 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3867 - mae: 0.4133 - root_mean_squared_error: 0.5312 - val_loss: 0.5082 - val_mae: 0.5887 - val_root_mean_squared_error: 0.7700 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3706 - mae: 0.3908 - root_mean_squared_error: 0.5120 - val_loss: 0.5036 - val_mae: 0.5933 - val_root_mean_squared_error: 0.7781 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3545 - mae: 0.3805 - root_mean_squared_error: 0.4956 - val_loss: 0.4934 - val_mae: 0.5913 - val_root_mean_squared_error: 0.7714 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3418 - mae: 0.3742 - root_mean_squared_error: 0.4838 - val_loss: 0.4846 - val_mae: 0.5902 - val_root_mean_squared_error: 0.7707 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3297 - mae: 0.3597 - root_mean_squared_error: 0.4743 - val_loss: 0.4768 - val_mae: 0.5918 - val_root_mean_squared_error: 0.7681 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3203 - mae: 0.3602 - root_mean_squared_error: 0.4660 - val_loss: 0.4784 - val_mae: 0.6008 - val_root_mean_squared_error: 0.7835 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3085 - mae: 0.3526 - root_mean_squared_error: 0.4557 - val_loss: 0.4629 - val_mae: 0.5854 - val_root_mean_squared_error: 0.7693 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3028 - mae: 0.3503 - root_mean_squared_error: 0.4588 - val_loss: 0.4672 - val_mae: 0.6012 - val_root_mean_squared_error: 0.7860 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2930 - mae: 0.3475 - root_mean_squared_error: 0.4509 - val_loss: 0.4620 - val_mae: 0.5999 - val_root_mean_squared_error: 0.7865 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2805 - mae: 0.3370 - root_mean_squared_error: 0.4349 - val_loss: 0.4586 - val_mae: 0.6033 - val_root_mean_squared_error: 0.7914 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2840 - mae: 0.3459 - root_mean_squared_error: 0.4608 - val_loss: 0.4493 - val_mae: 0.6052 - val_root_mean_squared_error: 0.7852 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2718 - mae: 0.3430 - root_mean_squared_error: 0.4409 - val_loss: 0.4448 - val_mae: 0.6084 - val_root_mean_squared_error: 0.7858 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2602 - mae: 0.3288 - root_mean_squared_error: 0.4279 - val_loss: 0.4400 - val_mae: 0.6014 - val_root_mean_squared_error: 0.7928 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2570 - mae: 0.3325 - root_mean_squared_error: 0.4338 - val_loss: 0.4329 - val_mae: 0.6028 - val_root_mean_squared_error: 0.7866 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2406 - mae: 0.3100 - root_mean_squared_error: 0.4041 - val_loss: 0.4308 - val_mae: 0.6084 - val_root_mean_squared_error: 0.7903 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2449 - mae: 0.3296 - root_mean_squared_error: 0.4288 - val_loss: 0.4272 - val_mae: 0.6080 - val_root_mean_squared_error: 0.7894 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2269 - mae: 0.3053 - root_mean_squared_error: 0.3933 - val_loss: 0.4195 - val_mae: 0.6030 - val_root_mean_squared_error: 0.7827 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2232 - mae: 0.3095 - root_mean_squared_error: 0.3965 - val_loss: 0.4136 - val_mae: 0.5978 - val_root_mean_squared_error: 0.7807 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2221 - mae: 0.3107 - root_mean_squared_error: 0.4050 - val_loss: 0.4156 - val_mae: 0.6122 - val_root_mean_squared_error: 0.7923 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2123 - mae: 0.2986 - root_mean_squared_error: 0.3897 - val_loss: 0.4058 - val_mae: 0.6013 - val_root_mean_squared_error: 0.7845 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2047 - mae: 0.2961 - root_mean_squared_error: 0.3797 - val_loss: 0.3963 - val_mae: 0.5947 - val_root_mean_squared_error: 0.7736 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2058 - mae: 0.3018 - root_mean_squared_error: 0.3934 - val_loss: 0.3928 - val_mae: 0.5877 - val_root_mean_squared_error: 0.7762 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1957 - mae: 0.2920 - root_mean_squared_error: 0.3750 - val_loss: 0.3934 - val_mae: 0.5984 - val_root_mean_squared_error: 0.7858 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1878 - mae: 0.2789 - root_mean_squared_error: 0.3646 - val_loss: 0.3993 - val_mae: 0.6139 - val_root_mean_squared_error: 0.7981 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1857 - mae: 0.2776 - root_mean_squared_error: 0.3701 - val_loss: 0.3932 - val_mae: 0.6066 - val_root_mean_squared_error: 0.7926 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1827 - mae: 0.2823 - root_mean_squared_error: 0.3681 - val_loss: 0.3843 - val_mae: 0.5997 - val_root_mean_squared_error: 0.7830 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1830 - mae: 0.2910 - root_mean_squared_error: 0.3782 - val_loss: 0.3796 - val_mae: 0.5982 - val_root_mean_squared_error: 0.7819 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1838 - mae: 0.2976 - root_mean_squared_error: 0.3900 - val_loss: 0.3863 - val_mae: 0.6030 - val_root_mean_squared_error: 0.8001 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1792 - mae: 0.2942 - root_mean_squared_error: 0.3821 - val_loss: 0.3785 - val_mae: 0.6008 - val_root_mean_squared_error: 0.7875 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1761 - mae: 0.2943 - root_mean_squared_error: 0.3822 - val_loss: 0.3786 - val_mae: 0.6038 - val_root_mean_squared_error: 0.7927 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1721 - mae: 0.2887 - root_mean_squared_error: 0.3767 - val_loss: 0.3696 - val_mae: 0.5912 - val_root_mean_squared_error: 0.7831 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1604 - mae: 0.2704 - root_mean_squared_error: 0.3509 - val_loss: 0.3738 - val_mae: 0.6043 - val_root_mean_squared_error: 0.7961 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1693 - mae: 0.2896 - root_mean_squared_error: 0.3822 - val_loss: 0.3795 - val_mae: 0.6110 - val_root_mean_squared_error: 0.8094 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1680 - mae: 0.2915 - root_mean_squared_error: 0.3839 - val_loss: 0.3738 - val_mae: 0.6074 - val_root_mean_squared_error: 0.8040 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1502 - mae: 0.2621 - root_mean_squared_error: 0.3377 - val_loss: 0.3773 - val_mae: 0.6189 - val_root_mean_squared_error: 0.8077 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1473 - mae: 0.2627 - root_mean_squared_error: 0.3354 - val_loss: 0.3657 - val_mae: 0.6051 - val_root_mean_squared_error: 0.7946 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1527 - mae: 0.2746 - root_mean_squared_error: 0.3586 - val_loss: 0.3702 - val_mae: 0.6111 - val_root_mean_squared_error: 0.8075 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1515 - mae: 0.2802 - root_mean_squared_error: 0.3587 - val_loss: 0.3626 - val_mae: 0.6056 - val_root_mean_squared_error: 0.7928 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1414 - mae: 0.2560 - root_mean_squared_error: 0.3341 - val_loss: 0.3665 - val_mae: 0.6128 - val_root_mean_squared_error: 0.8063 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1520 - mae: 0.2793 - root_mean_squared_error: 0.3696 - val_loss: 0.3608 - val_mae: 0.6056 - val_root_mean_squared_error: 0.7910 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1436 - mae: 0.2665 - root_mean_squared_error: 0.3488 - val_loss: 0.3687 - val_mae: 0.6157 - val_root_mean_squared_error: 0.8086 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1428 - mae: 0.2672 - root_mean_squared_error: 0.3506 - val_loss: 0.3585 - val_mae: 0.6070 - val_root_mean_squared_error: 0.7926 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1367 - mae: 0.2606 - root_mean_squared_error: 0.3361 - val_loss: 0.3507 - val_mae: 0.6009 - val_root_mean_squared_error: 0.7821 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1368 - mae: 0.2594 - root_mean_squared_error: 0.3408 - val_loss: 0.3554 - val_mae: 0.6067 - val_root_mean_squared_error: 0.7977 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1351 - mae: 0.2586 - root_mean_squared_error: 0.3449 - val_loss: 0.3546 - val_mae: 0.6100 - val_root_mean_squared_error: 0.7955 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1306 - mae: 0.2582 - root_mean_squared_error: 0.3296 - val_loss: 0.3624 - val_mae: 0.6190 - val_root_mean_squared_error: 0.8104 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1307 - mae: 0.2572 - root_mean_squared_error: 0.3347 - val_loss: 0.3570 - val_mae: 0.6153 - val_root_mean_squared_error: 0.8044 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1391 - mae: 0.2707 - root_mean_squared_error: 0.3633 - val_loss: 0.3490 - val_mae: 0.6042 - val_root_mean_squared_error: 0.7905 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1260 - mae: 0.2477 - root_mean_squared_error: 0.3265 - val_loss: 0.3515 - val_mae: 0.6037 - val_root_mean_squared_error: 0.7997 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1271 - mae: 0.2528 - root_mean_squared_error: 0.3323 - val_loss: 0.3517 - val_mae: 0.6077 - val_root_mean_squared_error: 0.8017 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1260 - mae: 0.2483 - root_mean_squared_error: 0.3308 - val_loss: 0.3452 - val_mae: 0.5976 - val_root_mean_squared_error: 0.7901 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1248 - mae: 0.2542 - root_mean_squared_error: 0.3301 - val_loss: 0.3489 - val_mae: 0.6078 - val_root_mean_squared_error: 0.7978 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1270 - mae: 0.2617 - root_mean_squared_error: 0.3379 - val_loss: 0.3519 - val_mae: 0.6071 - val_root_mean_squared_error: 0.8061 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1239 - mae: 0.2504 - root_mean_squared_error: 0.3319 - val_loss: 0.3511 - val_mae: 0.6116 - val_root_mean_squared_error: 0.8037 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1239 - mae: 0.2559 - root_mean_squared_error: 0.3319 - val_loss: 0.3485 - val_mae: 0.6055 - val_root_mean_squared_error: 0.7963 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1251 - mae: 0.2604 - root_mean_squared_error: 0.3372 - val_loss: 0.3462 - val_mae: 0.6015 - val_root_mean_squared_error: 0.7987 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1218 - mae: 0.2491 - root_mean_squared_error: 0.3281 - val_loss: 0.3594 - val_mae: 0.6262 - val_root_mean_squared_error: 0.8161 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1218 - mae: 0.2542 - root_mean_squared_error: 0.3293 - val_loss: 0.3364 - val_mae: 0.5906 - val_root_mean_squared_error: 0.7814 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1216 - mae: 0.2510 - root_mean_squared_error: 0.3296 - val_loss: 0.3415 - val_mae: 0.5986 - val_root_mean_squared_error: 0.7903 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1174 - mae: 0.2404 - root_mean_squared_error: 0.3195 - val_loss: 0.3447 - val_mae: 0.6095 - val_root_mean_squared_error: 0.7954 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1167 - mae: 0.2470 - root_mean_squared_error: 0.3180 - val_loss: 0.3537 - val_mae: 0.6117 - val_root_mean_squared_error: 0.8139 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1217 - mae: 0.2541 - root_mean_squared_error: 0.3386 - val_loss: 0.3407 - val_mae: 0.5997 - val_root_mean_squared_error: 0.7991 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1145 - mae: 0.2419 - root_mean_squared_error: 0.3151 - val_loss: 0.3565 - val_mae: 0.6215 - val_root_mean_squared_error: 0.8177 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1178 - mae: 0.2468 - root_mean_squared_error: 0.3258 - val_loss: 0.3355 - val_mae: 0.5976 - val_root_mean_squared_error: 0.7872 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1114 - mae: 0.2370 - root_mean_squared_error: 0.3057 - val_loss: 0.3544 - val_mae: 0.6194 - val_root_mean_squared_error: 0.8188 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1125 - mae: 0.2332 - root_mean_squared_error: 0.3113 - val_loss: 0.3460 - val_mae: 0.6056 - val_root_mean_squared_error: 0.8053 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1232 - mae: 0.2589 - root_mean_squared_error: 0.3474 - val_loss: 0.3506 - val_mae: 0.6138 - val_root_mean_squared_error: 0.8074 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1230 - mae: 0.2585 - root_mean_squared_error: 0.3474 - val_loss: 0.3390 - val_mae: 0.6009 - val_root_mean_squared_error: 0.7876 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1125 - mae: 0.2388 - root_mean_squared_error: 0.3127 - val_loss: 0.3507 - val_mae: 0.6178 - val_root_mean_squared_error: 0.8086 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1127 - mae: 0.2349 - root_mean_squared_error: 0.3152 - val_loss: 0.3538 - val_mae: 0.6194 - val_root_mean_squared_error: 0.8152 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1169 - mae: 0.2451 - root_mean_squared_error: 0.3301\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1176 - mae: 0.2464 - root_mean_squared_error: 0.3322 - val_loss: 0.3629 - val_mae: 0.6315 - val_root_mean_squared_error: 0.8299 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1127 - mae: 0.2414 - root_mean_squared_error: 0.3164 - val_loss: 0.3405 - val_mae: 0.6069 - val_root_mean_squared_error: 0.7947 - learning_rate: 3.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1041 - mae: 0.2193 - root_mean_squared_error: 0.2898 - val_loss: 0.3403 - val_mae: 0.6060 - val_root_mean_squared_error: 0.7958 - learning_rate: 3.0000e-04\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Resultats 100D - Pearson: 0.439, MSE: 0.611, MAE: 0.591\n",
      "Prediccions - Min: 0.957, Max: 4.637, Mean: 2.558\n",
      "Targets - Min: 0.000, Max: 5.000, Mean: 2.575\n",
      "\n",
      "=== Entrenant Model Agregat 150D ===\n",
      "Forma de les dades: X1_train=(2073, 150), Y_train=(2073,)\n",
      "Rang Y_train: [0.00, 5.00]\n",
      "Epoch 1/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3107 - mae: 1.2137 - root_mean_squared_error: 1.4568 - val_loss: 0.8307 - val_mae: 0.6706 - val_root_mean_squared_error: 0.8575 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0265 - mae: 0.8986 - root_mean_squared_error: 1.1212 - val_loss: 0.8178 - val_mae: 0.6480 - val_root_mean_squared_error: 0.8513 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9114 - mae: 0.7783 - root_mean_squared_error: 0.9866 - val_loss: 0.8020 - val_mae: 0.6463 - val_root_mean_squared_error: 0.8492 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8467 - mae: 0.7181 - root_mean_squared_error: 0.9112 - val_loss: 0.7847 - val_mae: 0.6439 - val_root_mean_squared_error: 0.8455 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8120 - mae: 0.6897 - root_mean_squared_error: 0.8899 - val_loss: 0.7700 - val_mae: 0.6394 - val_root_mean_squared_error: 0.8439 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7623 - mae: 0.6509 - root_mean_squared_error: 0.8297 - val_loss: 0.7582 - val_mae: 0.6377 - val_root_mean_squared_error: 0.8443 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7351 - mae: 0.6344 - root_mean_squared_error: 0.8053 - val_loss: 0.7558 - val_mae: 0.6475 - val_root_mean_squared_error: 0.8580 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7005 - mae: 0.6030 - root_mean_squared_error: 0.7763 - val_loss: 0.7110 - val_mae: 0.6187 - val_root_mean_squared_error: 0.8159 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6581 - mae: 0.5612 - root_mean_squared_error: 0.7308 - val_loss: 0.7016 - val_mae: 0.6170 - val_root_mean_squared_error: 0.8180 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6214 - mae: 0.5349 - root_mean_squared_error: 0.6860 - val_loss: 0.6761 - val_mae: 0.6201 - val_root_mean_squared_error: 0.8063 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6070 - mae: 0.5332 - root_mean_squared_error: 0.6878 - val_loss: 0.6613 - val_mae: 0.6169 - val_root_mean_squared_error: 0.8011 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5652 - mae: 0.4950 - root_mean_squared_error: 0.6303 - val_loss: 0.6498 - val_mae: 0.6132 - val_root_mean_squared_error: 0.8008 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5659 - mae: 0.5069 - root_mean_squared_error: 0.6551 - val_loss: 0.6345 - val_mae: 0.6110 - val_root_mean_squared_error: 0.7969 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5383 - mae: 0.4836 - root_mean_squared_error: 0.6269 - val_loss: 0.6218 - val_mae: 0.6114 - val_root_mean_squared_error: 0.7964 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5127 - mae: 0.4598 - root_mean_squared_error: 0.6037 - val_loss: 0.6070 - val_mae: 0.6008 - val_root_mean_squared_error: 0.7869 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4904 - mae: 0.4453 - root_mean_squared_error: 0.5788 - val_loss: 0.5916 - val_mae: 0.6008 - val_root_mean_squared_error: 0.7845 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4729 - mae: 0.4347 - root_mean_squared_error: 0.5653 - val_loss: 0.5851 - val_mae: 0.6078 - val_root_mean_squared_error: 0.7912 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4571 - mae: 0.4268 - root_mean_squared_error: 0.5528 - val_loss: 0.5713 - val_mae: 0.6026 - val_root_mean_squared_error: 0.7816 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4342 - mae: 0.4035 - root_mean_squared_error: 0.5273 - val_loss: 0.5626 - val_mae: 0.6038 - val_root_mean_squared_error: 0.7873 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4301 - mae: 0.4205 - root_mean_squared_error: 0.5403 - val_loss: 0.5549 - val_mae: 0.6076 - val_root_mean_squared_error: 0.7905 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4030 - mae: 0.3937 - root_mean_squared_error: 0.5036 - val_loss: 0.5487 - val_mae: 0.6082 - val_root_mean_squared_error: 0.7967 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3919 - mae: 0.3899 - root_mean_squared_error: 0.5001 - val_loss: 0.5465 - val_mae: 0.6231 - val_root_mean_squared_error: 0.8025 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3850 - mae: 0.3877 - root_mean_squared_error: 0.5120 - val_loss: 0.5291 - val_mae: 0.6118 - val_root_mean_squared_error: 0.7928 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3595 - mae: 0.3554 - root_mean_squared_error: 0.4723 - val_loss: 0.5264 - val_mae: 0.6168 - val_root_mean_squared_error: 0.8002 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3591 - mae: 0.3789 - root_mean_squared_error: 0.4889 - val_loss: 0.5159 - val_mae: 0.6142 - val_root_mean_squared_error: 0.7975 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3347 - mae: 0.3489 - root_mean_squared_error: 0.4527 - val_loss: 0.5083 - val_mae: 0.6164 - val_root_mean_squared_error: 0.7971 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3268 - mae: 0.3493 - root_mean_squared_error: 0.4535 - val_loss: 0.4970 - val_mae: 0.6120 - val_root_mean_squared_error: 0.7910 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3191 - mae: 0.3464 - root_mean_squared_error: 0.4525 - val_loss: 0.4938 - val_mae: 0.6123 - val_root_mean_squared_error: 0.7986 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3014 - mae: 0.3306 - root_mean_squared_error: 0.4279 - val_loss: 0.4865 - val_mae: 0.6165 - val_root_mean_squared_error: 0.7982 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2959 - mae: 0.3340 - root_mean_squared_error: 0.4327 - val_loss: 0.4764 - val_mae: 0.6146 - val_root_mean_squared_error: 0.7946 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2853 - mae: 0.3255 - root_mean_squared_error: 0.4218 - val_loss: 0.4706 - val_mae: 0.6173 - val_root_mean_squared_error: 0.7955 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2778 - mae: 0.3248 - root_mean_squared_error: 0.4205 - val_loss: 0.4727 - val_mae: 0.6290 - val_root_mean_squared_error: 0.8116 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2707 - mae: 0.3270 - root_mean_squared_error: 0.4180 - val_loss: 0.4529 - val_mae: 0.6071 - val_root_mean_squared_error: 0.7869 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2620 - mae: 0.3237 - root_mean_squared_error: 0.4119 - val_loss: 0.4510 - val_mae: 0.6109 - val_root_mean_squared_error: 0.7946 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2498 - mae: 0.3015 - root_mean_squared_error: 0.3993 - val_loss: 0.4528 - val_mae: 0.6224 - val_root_mean_squared_error: 0.8042 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2427 - mae: 0.3064 - root_mean_squared_error: 0.3934 - val_loss: 0.4495 - val_mae: 0.6242 - val_root_mean_squared_error: 0.8096 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2371 - mae: 0.3016 - root_mean_squared_error: 0.3954 - val_loss: 0.4362 - val_mae: 0.6136 - val_root_mean_squared_error: 0.7984 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2354 - mae: 0.3158 - root_mean_squared_error: 0.4032 - val_loss: 0.4285 - val_mae: 0.6096 - val_root_mean_squared_error: 0.7892 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2251 - mae: 0.3034 - root_mean_squared_error: 0.3906 - val_loss: 0.4325 - val_mae: 0.6244 - val_root_mean_squared_error: 0.8019 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2132 - mae: 0.2869 - root_mean_squared_error: 0.3701 - val_loss: 0.4315 - val_mae: 0.6244 - val_root_mean_squared_error: 0.8124 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2190 - mae: 0.3010 - root_mean_squared_error: 0.4000 - val_loss: 0.4087 - val_mae: 0.5976 - val_root_mean_squared_error: 0.7814 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2091 - mae: 0.2973 - root_mean_squared_error: 0.3835 - val_loss: 0.4211 - val_mae: 0.6224 - val_root_mean_squared_error: 0.8102 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1999 - mae: 0.2878 - root_mean_squared_error: 0.3684 - val_loss: 0.4159 - val_mae: 0.6231 - val_root_mean_squared_error: 0.8102 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2042 - mae: 0.2993 - root_mean_squared_error: 0.3928 - val_loss: 0.4207 - val_mae: 0.6296 - val_root_mean_squared_error: 0.8216 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1929 - mae: 0.2855 - root_mean_squared_error: 0.3699 - val_loss: 0.4049 - val_mae: 0.6170 - val_root_mean_squared_error: 0.7980 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1867 - mae: 0.2850 - root_mean_squared_error: 0.3626 - val_loss: 0.3993 - val_mae: 0.6126 - val_root_mean_squared_error: 0.7951 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1848 - mae: 0.2843 - root_mean_squared_error: 0.3672 - val_loss: 0.4104 - val_mae: 0.6342 - val_root_mean_squared_error: 0.8241 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1762 - mae: 0.2755 - root_mean_squared_error: 0.3527 - val_loss: 0.3960 - val_mae: 0.6194 - val_root_mean_squared_error: 0.8056 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1718 - mae: 0.2669 - root_mean_squared_error: 0.3508 - val_loss: 0.3917 - val_mae: 0.6136 - val_root_mean_squared_error: 0.8025 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1703 - mae: 0.2728 - root_mean_squared_error: 0.3546 - val_loss: 0.3934 - val_mae: 0.6184 - val_root_mean_squared_error: 0.8130 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1646 - mae: 0.2639 - root_mean_squared_error: 0.3448 - val_loss: 0.3839 - val_mae: 0.6156 - val_root_mean_squared_error: 0.7985 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1682 - mae: 0.2738 - root_mean_squared_error: 0.3647 - val_loss: 0.3884 - val_mae: 0.6189 - val_root_mean_squared_error: 0.8137 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1600 - mae: 0.2680 - root_mean_squared_error: 0.3462 - val_loss: 0.3790 - val_mae: 0.6074 - val_root_mean_squared_error: 0.7972 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1560 - mae: 0.2662 - root_mean_squared_error: 0.3412 - val_loss: 0.3836 - val_mae: 0.6260 - val_root_mean_squared_error: 0.8082 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1578 - mae: 0.2711 - root_mean_squared_error: 0.3536 - val_loss: 0.3749 - val_mae: 0.6138 - val_root_mean_squared_error: 0.8031 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1530 - mae: 0.2592 - root_mean_squared_error: 0.3443 - val_loss: 0.3675 - val_mae: 0.6002 - val_root_mean_squared_error: 0.7883 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1464 - mae: 0.2566 - root_mean_squared_error: 0.3307 - val_loss: 0.3731 - val_mae: 0.6138 - val_root_mean_squared_error: 0.8084 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1470 - mae: 0.2573 - root_mean_squared_error: 0.3395 - val_loss: 0.3678 - val_mae: 0.6075 - val_root_mean_squared_error: 0.8008 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1505 - mae: 0.2720 - root_mean_squared_error: 0.3536 - val_loss: 0.3673 - val_mae: 0.6092 - val_root_mean_squared_error: 0.7959 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1391 - mae: 0.2487 - root_mean_squared_error: 0.3242 - val_loss: 0.3656 - val_mae: 0.6130 - val_root_mean_squared_error: 0.7960 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1396 - mae: 0.2583 - root_mean_squared_error: 0.3323 - val_loss: 0.3578 - val_mae: 0.6066 - val_root_mean_squared_error: 0.7885 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1316 - mae: 0.2424 - root_mean_squared_error: 0.3121 - val_loss: 0.3687 - val_mae: 0.6179 - val_root_mean_squared_error: 0.8113 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1350 - mae: 0.2497 - root_mean_squared_error: 0.3271 - val_loss: 0.3755 - val_mae: 0.6335 - val_root_mean_squared_error: 0.8202 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1343 - mae: 0.2569 - root_mean_squared_error: 0.3279 - val_loss: 0.3615 - val_mae: 0.6143 - val_root_mean_squared_error: 0.8014 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1312 - mae: 0.2465 - root_mean_squared_error: 0.3227 - val_loss: 0.3549 - val_mae: 0.6011 - val_root_mean_squared_error: 0.7974 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1284 - mae: 0.2411 - root_mean_squared_error: 0.3187 - val_loss: 0.3484 - val_mae: 0.5976 - val_root_mean_squared_error: 0.7825 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1287 - mae: 0.2498 - root_mean_squared_error: 0.3225 - val_loss: 0.3587 - val_mae: 0.6149 - val_root_mean_squared_error: 0.8056 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1341 - mae: 0.2633 - root_mean_squared_error: 0.3431 - val_loss: 0.3627 - val_mae: 0.6225 - val_root_mean_squared_error: 0.8132 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1322 - mae: 0.2627 - root_mean_squared_error: 0.3389 - val_loss: 0.3668 - val_mae: 0.6270 - val_root_mean_squared_error: 0.8186 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1298 - mae: 0.2537 - root_mean_squared_error: 0.3332 - val_loss: 0.3512 - val_mae: 0.6047 - val_root_mean_squared_error: 0.7934 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1255 - mae: 0.2426 - root_mean_squared_error: 0.3227 - val_loss: 0.3571 - val_mae: 0.6136 - val_root_mean_squared_error: 0.8062 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1212 - mae: 0.2395 - root_mean_squared_error: 0.3130 - val_loss: 0.3665 - val_mae: 0.6273 - val_root_mean_squared_error: 0.8291 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m23/33\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1207 - mae: 0.2363 - root_mean_squared_error: 0.3142 \n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1209 - mae: 0.2374 - root_mean_squared_error: 0.3145 - val_loss: 0.3629 - val_mae: 0.6222 - val_root_mean_squared_error: 0.8173 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1164 - mae: 0.2303 - root_mean_squared_error: 0.3011 - val_loss: 0.3494 - val_mae: 0.6049 - val_root_mean_squared_error: 0.7992 - learning_rate: 3.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1101 - mae: 0.2170 - root_mean_squared_error: 0.2835 - val_loss: 0.3496 - val_mae: 0.6074 - val_root_mean_squared_error: 0.8020 - learning_rate: 3.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1058 - mae: 0.2098 - root_mean_squared_error: 0.2720 - val_loss: 0.3491 - val_mae: 0.6073 - val_root_mean_squared_error: 0.8047 - learning_rate: 3.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1093 - mae: 0.2164 - root_mean_squared_error: 0.2891 - val_loss: 0.3474 - val_mae: 0.6081 - val_root_mean_squared_error: 0.8019 - learning_rate: 3.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0977 - mae: 0.1915 - root_mean_squared_error: 0.2502 - val_loss: 0.3431 - val_mae: 0.6029 - val_root_mean_squared_error: 0.7980 - learning_rate: 3.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1005 - mae: 0.2043 - root_mean_squared_error: 0.2654 - val_loss: 0.3433 - val_mae: 0.6018 - val_root_mean_squared_error: 0.7999 - learning_rate: 3.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0970 - mae: 0.1945 - root_mean_squared_error: 0.2566 - val_loss: 0.3397 - val_mae: 0.6011 - val_root_mean_squared_error: 0.7968 - learning_rate: 3.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0955 - mae: 0.1952 - root_mean_squared_error: 0.2551 - val_loss: 0.3358 - val_mae: 0.5975 - val_root_mean_squared_error: 0.7918 - learning_rate: 3.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0931 - mae: 0.1903 - root_mean_squared_error: 0.2500 - val_loss: 0.3349 - val_mae: 0.5962 - val_root_mean_squared_error: 0.7914 - learning_rate: 3.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0946 - mae: 0.2002 - root_mean_squared_error: 0.2607 - val_loss: 0.3352 - val_mae: 0.5969 - val_root_mean_squared_error: 0.7915 - learning_rate: 3.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0891 - mae: 0.1863 - root_mean_squared_error: 0.2423 - val_loss: 0.3353 - val_mae: 0.6016 - val_root_mean_squared_error: 0.7932 - learning_rate: 3.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0920 - mae: 0.2014 - root_mean_squared_error: 0.2577 - val_loss: 0.3378 - val_mae: 0.6049 - val_root_mean_squared_error: 0.7995 - learning_rate: 3.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0839 - mae: 0.1763 - root_mean_squared_error: 0.2291 - val_loss: 0.3296 - val_mae: 0.5947 - val_root_mean_squared_error: 0.7876 - learning_rate: 3.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0846 - mae: 0.1817 - root_mean_squared_error: 0.2363 - val_loss: 0.3337 - val_mae: 0.5998 - val_root_mean_squared_error: 0.7951 - learning_rate: 3.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0862 - mae: 0.1884 - root_mean_squared_error: 0.2468 - val_loss: 0.3335 - val_mae: 0.6001 - val_root_mean_squared_error: 0.7984 - learning_rate: 3.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0817 - mae: 0.1786 - root_mean_squared_error: 0.2323 - val_loss: 0.3354 - val_mae: 0.6058 - val_root_mean_squared_error: 0.8018 - learning_rate: 3.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0804 - mae: 0.1767 - root_mean_squared_error: 0.2307 - val_loss: 0.3334 - val_mae: 0.6022 - val_root_mean_squared_error: 0.8007 - learning_rate: 3.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0781 - mae: 0.1754 - root_mean_squared_error: 0.2248 - val_loss: 0.3346 - val_mae: 0.6057 - val_root_mean_squared_error: 0.8049 - learning_rate: 3.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0784 - mae: 0.1801 - root_mean_squared_error: 0.2301 - val_loss: 0.3298 - val_mae: 0.6043 - val_root_mean_squared_error: 0.7973 - learning_rate: 3.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0771 - mae: 0.1774 - root_mean_squared_error: 0.2285 - val_loss: 0.3287 - val_mae: 0.6026 - val_root_mean_squared_error: 0.7979 - learning_rate: 3.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0759 - mae: 0.1742 - root_mean_squared_error: 0.2272 - val_loss: 0.3246 - val_mae: 0.5994 - val_root_mean_squared_error: 0.7926 - learning_rate: 3.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0750 - mae: 0.1731 - root_mean_squared_error: 0.2267 - val_loss: 0.3255 - val_mae: 0.5987 - val_root_mean_squared_error: 0.7969 - learning_rate: 3.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0721 - mae: 0.1678 - root_mean_squared_error: 0.2175 - val_loss: 0.3313 - val_mae: 0.6044 - val_root_mean_squared_error: 0.8085 - learning_rate: 3.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0718 - mae: 0.1693 - root_mean_squared_error: 0.2199 - val_loss: 0.3245 - val_mae: 0.5986 - val_root_mean_squared_error: 0.7960 - learning_rate: 3.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0756 - mae: 0.1808 - root_mean_squared_error: 0.2401 - val_loss: 0.3223 - val_mae: 0.5987 - val_root_mean_squared_error: 0.7916 - learning_rate: 3.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0714 - mae: 0.1734 - root_mean_squared_error: 0.2248 - val_loss: 0.3217 - val_mae: 0.5968 - val_root_mean_squared_error: 0.7925 - learning_rate: 3.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0721 - mae: 0.1748 - root_mean_squared_error: 0.2311 - val_loss: 0.3215 - val_mae: 0.5986 - val_root_mean_squared_error: 0.7950 - learning_rate: 3.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Resultats 150D - Pearson: 0.412, MSE: 0.627, MAE: 0.599\n",
      "Prediccions - Min: 0.884, Max: 4.598, Mean: 2.526\n",
      "Targets - Min: 0.000, Max: 5.000, Mean: 2.575\n",
      "\n",
      "=== Entrenant Model Agregat 300D ===\n",
      "Forma de les dades: X1_train=(2073, 300), Y_train=(2073,)\n",
      "Rang Y_train: [0.00, 5.00]\n",
      "Epoch 1/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.3658 - mae: 1.1976 - root_mean_squared_error: 1.4703 - val_loss: 0.8881 - val_mae: 0.6511 - val_root_mean_squared_error: 0.8481 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1006 - mae: 0.9219 - root_mean_squared_error: 1.1367 - val_loss: 0.8635 - val_mae: 0.6479 - val_root_mean_squared_error: 0.8413 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9625 - mae: 0.7815 - root_mean_squared_error: 0.9868 - val_loss: 0.8417 - val_mae: 0.6470 - val_root_mean_squared_error: 0.8402 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8900 - mae: 0.7175 - root_mean_squared_error: 0.9083 - val_loss: 0.8209 - val_mae: 0.6384 - val_root_mean_squared_error: 0.8353 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8646 - mae: 0.7030 - root_mean_squared_error: 0.9053 - val_loss: 0.8009 - val_mae: 0.6320 - val_root_mean_squared_error: 0.8322 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7929 - mae: 0.6349 - root_mean_squared_error: 0.8202 - val_loss: 0.7781 - val_mae: 0.6300 - val_root_mean_squared_error: 0.8266 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7728 - mae: 0.6341 - root_mean_squared_error: 0.8136 - val_loss: 0.7614 - val_mae: 0.6230 - val_root_mean_squared_error: 0.8242 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7247 - mae: 0.5893 - root_mean_squared_error: 0.7620 - val_loss: 0.7451 - val_mae: 0.6228 - val_root_mean_squared_error: 0.8241 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6935 - mae: 0.5713 - root_mean_squared_error: 0.7392 - val_loss: 0.7225 - val_mae: 0.6292 - val_root_mean_squared_error: 0.8164 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6592 - mae: 0.5431 - root_mean_squared_error: 0.7134 - val_loss: 0.6980 - val_mae: 0.6039 - val_root_mean_squared_error: 0.8012 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6256 - mae: 0.5172 - root_mean_squared_error: 0.6813 - val_loss: 0.6858 - val_mae: 0.6118 - val_root_mean_squared_error: 0.8083 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6053 - mae: 0.5143 - root_mean_squared_error: 0.6721 - val_loss: 0.6649 - val_mae: 0.6120 - val_root_mean_squared_error: 0.8008 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5555 - mae: 0.4673 - root_mean_squared_error: 0.6082 - val_loss: 0.6460 - val_mae: 0.6092 - val_root_mean_squared_error: 0.7959 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5304 - mae: 0.4524 - root_mean_squared_error: 0.5906 - val_loss: 0.6247 - val_mae: 0.6013 - val_root_mean_squared_error: 0.7845 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5114 - mae: 0.4435 - root_mean_squared_error: 0.5815 - val_loss: 0.6056 - val_mae: 0.5910 - val_root_mean_squared_error: 0.7776 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5004 - mae: 0.4520 - root_mean_squared_error: 0.5890 - val_loss: 0.5958 - val_mae: 0.5986 - val_root_mean_squared_error: 0.7849 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4715 - mae: 0.4296 - root_mean_squared_error: 0.5554 - val_loss: 0.5902 - val_mae: 0.6074 - val_root_mean_squared_error: 0.7990 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4472 - mae: 0.4091 - root_mean_squared_error: 0.5344 - val_loss: 0.5636 - val_mae: 0.5904 - val_root_mean_squared_error: 0.7714 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4203 - mae: 0.3802 - root_mean_squared_error: 0.5055 - val_loss: 0.5486 - val_mae: 0.5913 - val_root_mean_squared_error: 0.7695 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4053 - mae: 0.3839 - root_mean_squared_error: 0.5012 - val_loss: 0.5481 - val_mae: 0.6071 - val_root_mean_squared_error: 0.7885 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3891 - mae: 0.3732 - root_mean_squared_error: 0.4886 - val_loss: 0.5222 - val_mae: 0.5855 - val_root_mean_squared_error: 0.7645 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3670 - mae: 0.3568 - root_mean_squared_error: 0.4611 - val_loss: 0.5101 - val_mae: 0.5841 - val_root_mean_squared_error: 0.7617 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3671 - mae: 0.3678 - root_mean_squared_error: 0.4892 - val_loss: 0.5034 - val_mae: 0.5854 - val_root_mean_squared_error: 0.7656 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3489 - mae: 0.3611 - root_mean_squared_error: 0.4671 - val_loss: 0.4926 - val_mae: 0.5817 - val_root_mean_squared_error: 0.7634 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3275 - mae: 0.3377 - root_mean_squared_error: 0.4385 - val_loss: 0.4905 - val_mae: 0.5920 - val_root_mean_squared_error: 0.7748 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3160 - mae: 0.3343 - root_mean_squared_error: 0.4324 - val_loss: 0.4835 - val_mae: 0.5918 - val_root_mean_squared_error: 0.7798 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3093 - mae: 0.3359 - root_mean_squared_error: 0.4382 - val_loss: 0.4742 - val_mae: 0.5907 - val_root_mean_squared_error: 0.7766 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3021 - mae: 0.3444 - root_mean_squared_error: 0.4414 - val_loss: 0.4711 - val_mae: 0.5955 - val_root_mean_squared_error: 0.7829 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2879 - mae: 0.3302 - root_mean_squared_error: 0.4253 - val_loss: 0.4575 - val_mae: 0.5952 - val_root_mean_squared_error: 0.7709 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2776 - mae: 0.3191 - root_mean_squared_error: 0.4195 - val_loss: 0.4580 - val_mae: 0.6031 - val_root_mean_squared_error: 0.7859 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2703 - mae: 0.3206 - root_mean_squared_error: 0.4148 - val_loss: 0.4441 - val_mae: 0.5944 - val_root_mean_squared_error: 0.7725 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2605 - mae: 0.3140 - root_mean_squared_error: 0.4080 - val_loss: 0.4420 - val_mae: 0.5976 - val_root_mean_squared_error: 0.7823 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2576 - mae: 0.3171 - root_mean_squared_error: 0.4201 - val_loss: 0.4411 - val_mae: 0.6047 - val_root_mean_squared_error: 0.7914 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2402 - mae: 0.2976 - root_mean_squared_error: 0.3875 - val_loss: 0.4323 - val_mae: 0.6032 - val_root_mean_squared_error: 0.7852 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2370 - mae: 0.3031 - root_mean_squared_error: 0.3933 - val_loss: 0.4222 - val_mae: 0.5907 - val_root_mean_squared_error: 0.7786 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2374 - mae: 0.3175 - root_mean_squared_error: 0.4077 - val_loss: 0.4181 - val_mae: 0.5952 - val_root_mean_squared_error: 0.7816 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2206 - mae: 0.2899 - root_mean_squared_error: 0.3816 - val_loss: 0.4131 - val_mae: 0.5928 - val_root_mean_squared_error: 0.7798 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2101 - mae: 0.2829 - root_mean_squared_error: 0.3627 - val_loss: 0.4010 - val_mae: 0.5864 - val_root_mean_squared_error: 0.7678 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2064 - mae: 0.2825 - root_mean_squared_error: 0.3671 - val_loss: 0.4088 - val_mae: 0.6048 - val_root_mean_squared_error: 0.7878 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2086 - mae: 0.2965 - root_mean_squared_error: 0.3862 - val_loss: 0.4079 - val_mae: 0.6035 - val_root_mean_squared_error: 0.7944 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2025 - mae: 0.2886 - root_mean_squared_error: 0.3796 - val_loss: 0.3991 - val_mae: 0.5996 - val_root_mean_squared_error: 0.7840 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1927 - mae: 0.2798 - root_mean_squared_error: 0.3608 - val_loss: 0.3994 - val_mae: 0.6062 - val_root_mean_squared_error: 0.7907 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1875 - mae: 0.2753 - root_mean_squared_error: 0.3580 - val_loss: 0.3875 - val_mae: 0.5927 - val_root_mean_squared_error: 0.7771 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1852 - mae: 0.2787 - root_mean_squared_error: 0.3600 - val_loss: 0.3882 - val_mae: 0.5957 - val_root_mean_squared_error: 0.7854 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1849 - mae: 0.2861 - root_mean_squared_error: 0.3688 - val_loss: 0.3810 - val_mae: 0.5889 - val_root_mean_squared_error: 0.7750 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1779 - mae: 0.2796 - root_mean_squared_error: 0.3566 - val_loss: 0.3864 - val_mae: 0.6024 - val_root_mean_squared_error: 0.7870 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1740 - mae: 0.2708 - root_mean_squared_error: 0.3541 - val_loss: 0.3800 - val_mae: 0.6009 - val_root_mean_squared_error: 0.7848 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1746 - mae: 0.2777 - root_mean_squared_error: 0.3633 - val_loss: 0.3884 - val_mae: 0.6095 - val_root_mean_squared_error: 0.8037 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1586 - mae: 0.2470 - root_mean_squared_error: 0.3216 - val_loss: 0.3808 - val_mae: 0.6100 - val_root_mean_squared_error: 0.7945 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1612 - mae: 0.2628 - root_mean_squared_error: 0.3401 - val_loss: 0.3713 - val_mae: 0.5989 - val_root_mean_squared_error: 0.7840 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1615 - mae: 0.2676 - root_mean_squared_error: 0.3492 - val_loss: 0.3616 - val_mae: 0.5902 - val_root_mean_squared_error: 0.7690 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1648 - mae: 0.2773 - root_mean_squared_error: 0.3640 - val_loss: 0.3657 - val_mae: 0.5958 - val_root_mean_squared_error: 0.7822 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1546 - mae: 0.2575 - root_mean_squared_error: 0.3407 - val_loss: 0.3640 - val_mae: 0.5909 - val_root_mean_squared_error: 0.7797 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1530 - mae: 0.2539 - root_mean_squared_error: 0.3408 - val_loss: 0.3625 - val_mae: 0.5989 - val_root_mean_squared_error: 0.7841 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1494 - mae: 0.2592 - root_mean_squared_error: 0.3353 - val_loss: 0.3787 - val_mae: 0.6150 - val_root_mean_squared_error: 0.8144 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1475 - mae: 0.2594 - root_mean_squared_error: 0.3349 - val_loss: 0.3655 - val_mae: 0.5983 - val_root_mean_squared_error: 0.7928 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1445 - mae: 0.2538 - root_mean_squared_error: 0.3325 - val_loss: 0.3520 - val_mae: 0.5914 - val_root_mean_squared_error: 0.7718 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1512 - mae: 0.2646 - root_mean_squared_error: 0.3696 - val_loss: 0.3669 - val_mae: 0.6013 - val_root_mean_squared_error: 0.8003 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1494 - mae: 0.2664 - root_mean_squared_error: 0.3568 - val_loss: 0.3506 - val_mae: 0.5810 - val_root_mean_squared_error: 0.7768 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1485 - mae: 0.2657 - root_mean_squared_error: 0.3527 - val_loss: 0.3585 - val_mae: 0.5974 - val_root_mean_squared_error: 0.7896 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1440 - mae: 0.2606 - root_mean_squared_error: 0.3421 - val_loss: 0.3485 - val_mae: 0.5803 - val_root_mean_squared_error: 0.7751 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1442 - mae: 0.2585 - root_mean_squared_error: 0.3451 - val_loss: 0.3601 - val_mae: 0.5999 - val_root_mean_squared_error: 0.7954 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1395 - mae: 0.2513 - root_mean_squared_error: 0.3371 - val_loss: 0.3612 - val_mae: 0.6069 - val_root_mean_squared_error: 0.7946 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1390 - mae: 0.2556 - root_mean_squared_error: 0.3353 - val_loss: 0.3676 - val_mae: 0.6157 - val_root_mean_squared_error: 0.8113 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1476 - mae: 0.2717 - root_mean_squared_error: 0.3647 - val_loss: 0.3490 - val_mae: 0.5912 - val_root_mean_squared_error: 0.7815 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1448 - mae: 0.2712 - root_mean_squared_error: 0.3568 - val_loss: 0.3548 - val_mae: 0.5940 - val_root_mean_squared_error: 0.7888 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1432 - mae: 0.2677 - root_mean_squared_error: 0.3548 - val_loss: 0.3674 - val_mae: 0.6085 - val_root_mean_squared_error: 0.8132 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m19/33\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1341 - mae: 0.2502 - root_mean_squared_error: 0.3263 \n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1355 - mae: 0.2524 - root_mean_squared_error: 0.3311 - val_loss: 0.3650 - val_mae: 0.6087 - val_root_mean_squared_error: 0.8075 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1298 - mae: 0.2430 - root_mean_squared_error: 0.3165 - val_loss: 0.3543 - val_mae: 0.5959 - val_root_mean_squared_error: 0.7945 - learning_rate: 3.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1219 - mae: 0.2237 - root_mean_squared_error: 0.2972 - val_loss: 0.3508 - val_mae: 0.5958 - val_root_mean_squared_error: 0.7888 - learning_rate: 3.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1134 - mae: 0.2090 - root_mean_squared_error: 0.2729 - val_loss: 0.3499 - val_mae: 0.5985 - val_root_mean_squared_error: 0.7902 - learning_rate: 3.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1102 - mae: 0.2023 - root_mean_squared_error: 0.2674 - val_loss: 0.3434 - val_mae: 0.5916 - val_root_mean_squared_error: 0.7818 - learning_rate: 3.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1076 - mae: 0.2019 - root_mean_squared_error: 0.2640 - val_loss: 0.3433 - val_mae: 0.5939 - val_root_mean_squared_error: 0.7853 - learning_rate: 3.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1057 - mae: 0.2015 - root_mean_squared_error: 0.2632 - val_loss: 0.3417 - val_mae: 0.5929 - val_root_mean_squared_error: 0.7860 - learning_rate: 3.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1006 - mae: 0.1918 - root_mean_squared_error: 0.2495 - val_loss: 0.3411 - val_mae: 0.5958 - val_root_mean_squared_error: 0.7872 - learning_rate: 3.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0997 - mae: 0.1942 - root_mean_squared_error: 0.2528 - val_loss: 0.3370 - val_mae: 0.5924 - val_root_mean_squared_error: 0.7833 - learning_rate: 3.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0968 - mae: 0.1917 - root_mean_squared_error: 0.2471 - val_loss: 0.3396 - val_mae: 0.5992 - val_root_mean_squared_error: 0.7891 - learning_rate: 3.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0926 - mae: 0.1835 - root_mean_squared_error: 0.2361 - val_loss: 0.3355 - val_mae: 0.5947 - val_root_mean_squared_error: 0.7850 - learning_rate: 3.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0936 - mae: 0.1892 - root_mean_squared_error: 0.2467 - val_loss: 0.3345 - val_mae: 0.5947 - val_root_mean_squared_error: 0.7881 - learning_rate: 3.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0881 - mae: 0.1770 - root_mean_squared_error: 0.2292 - val_loss: 0.3317 - val_mae: 0.5951 - val_root_mean_squared_error: 0.7846 - learning_rate: 3.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0875 - mae: 0.1744 - root_mean_squared_error: 0.2324 - val_loss: 0.3324 - val_mae: 0.5983 - val_root_mean_squared_error: 0.7887 - learning_rate: 3.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0897 - mae: 0.1907 - root_mean_squared_error: 0.2473 - val_loss: 0.3310 - val_mae: 0.5984 - val_root_mean_squared_error: 0.7854 - learning_rate: 3.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0834 - mae: 0.1738 - root_mean_squared_error: 0.2263 - val_loss: 0.3320 - val_mae: 0.6022 - val_root_mean_squared_error: 0.7914 - learning_rate: 3.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0849 - mae: 0.1795 - root_mean_squared_error: 0.2383 - val_loss: 0.3316 - val_mae: 0.6014 - val_root_mean_squared_error: 0.7934 - learning_rate: 3.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0817 - mae: 0.1770 - root_mean_squared_error: 0.2296 - val_loss: 0.3254 - val_mae: 0.5954 - val_root_mean_squared_error: 0.7850 - learning_rate: 3.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0829 - mae: 0.1844 - root_mean_squared_error: 0.2394 - val_loss: 0.3215 - val_mae: 0.5897 - val_root_mean_squared_error: 0.7816 - learning_rate: 3.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0812 - mae: 0.1826 - root_mean_squared_error: 0.2370 - val_loss: 0.3270 - val_mae: 0.5974 - val_root_mean_squared_error: 0.7907 - learning_rate: 3.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0798 - mae: 0.1804 - root_mean_squared_error: 0.2355 - val_loss: 0.3233 - val_mae: 0.5951 - val_root_mean_squared_error: 0.7883 - learning_rate: 3.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0776 - mae: 0.1736 - root_mean_squared_error: 0.2296 - val_loss: 0.3165 - val_mae: 0.5855 - val_root_mean_squared_error: 0.7772 - learning_rate: 3.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0756 - mae: 0.1749 - root_mean_squared_error: 0.2256 - val_loss: 0.3158 - val_mae: 0.5893 - val_root_mean_squared_error: 0.7769 - learning_rate: 3.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0789 - mae: 0.1858 - root_mean_squared_error: 0.2429 - val_loss: 0.3174 - val_mae: 0.5893 - val_root_mean_squared_error: 0.7815 - learning_rate: 3.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0783 - mae: 0.1883 - root_mean_squared_error: 0.2456 - val_loss: 0.3138 - val_mae: 0.5887 - val_root_mean_squared_error: 0.7748 - learning_rate: 3.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0745 - mae: 0.1792 - root_mean_squared_error: 0.2330 - val_loss: 0.3155 - val_mae: 0.5871 - val_root_mean_squared_error: 0.7818 - learning_rate: 3.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0721 - mae: 0.1741 - root_mean_squared_error: 0.2261 - val_loss: 0.3142 - val_mae: 0.5967 - val_root_mean_squared_error: 0.7789 - learning_rate: 3.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0712 - mae: 0.1738 - root_mean_squared_error: 0.2261 - val_loss: 0.3093 - val_mae: 0.5903 - val_root_mean_squared_error: 0.7740 - learning_rate: 3.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0705 - mae: 0.1727 - root_mean_squared_error: 0.2263 - val_loss: 0.3121 - val_mae: 0.5953 - val_root_mean_squared_error: 0.7791 - learning_rate: 3.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0702 - mae: 0.1751 - root_mean_squared_error: 0.2285 - val_loss: 0.3134 - val_mae: 0.5941 - val_root_mean_squared_error: 0.7835 - learning_rate: 3.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0703 - mae: 0.1776 - root_mean_squared_error: 0.2316 - val_loss: 0.3131 - val_mae: 0.5922 - val_root_mean_squared_error: 0.7824 - learning_rate: 3.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0715 - mae: 0.1808 - root_mean_squared_error: 0.2398 - val_loss: 0.3153 - val_mae: 0.5973 - val_root_mean_squared_error: 0.7877 - learning_rate: 3.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0677 - mae: 0.1751 - root_mean_squared_error: 0.2265 - val_loss: 0.3178 - val_mae: 0.6036 - val_root_mean_squared_error: 0.7942 - learning_rate: 3.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Resultats 300D - Pearson: 0.460, MSE: 0.599, MAE: 0.590\n",
      "Prediccions - Min: 0.615, Max: 4.631, Mean: 2.463\n",
      "Targets - Min: 0.000, Max: 5.000, Mean: 2.575\n"
     ]
    }
   ],
   "source": [
    "def build_model_aggregated(embedding_dim: int, hidden_size: int = 256, \n",
    "                          dropout_rate: float = 0.3) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Model amb millor arquitectura\n",
    "    \"\"\"\n",
    "    input_1 = tf.keras.Input(shape=(embedding_dim,), name=\"input_vector_1\")\n",
    "    input_2 = tf.keras.Input(shape=(embedding_dim,), name=\"input_vector_2\")\n",
    "    \n",
    "    # Normalitzar inputs (L2 normalization)\n",
    "    norm_1 = tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(input_1)\n",
    "    norm_2 = tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(input_2)\n",
    "    \n",
    "    # Múltiples formes de combinar els vectors\n",
    "    concatenated = tf.keras.layers.Concatenate(axis=-1)([norm_1, norm_2])\n",
    "    \n",
    "    # Diferència absoluta (captura dissimilitud)\n",
    "    abs_diff = tf.keras.layers.Lambda(lambda x: tf.abs(x[0] - x[1]))([norm_1, norm_2])\n",
    "    \n",
    "    # Producte element-wise (captura similitud)\n",
    "    element_wise = tf.keras.layers.Multiply()([norm_1, norm_2])\n",
    "    \n",
    "    # Combinar totes les representacions\n",
    "    combined = tf.keras.layers.Concatenate(axis=-1)([concatenated, abs_diff, element_wise])\n",
    "    \n",
    "    # Arquitectura més robusta\n",
    "    x = tf.keras.layers.BatchNormalization()(combined)\n",
    "    x = tf.keras.layers.Dense(hidden_size, activation='relu', \n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(hidden_size // 2, activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(hidden_size // 4, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate / 2)(x)\n",
    "    \n",
    "    # Capa de sortida amb activació sigmoid escalada a [0,5]\n",
    "    output_raw = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    output = tf.keras.layers.Lambda(lambda x: x * 5.0)(output_raw)  # Escalar a [0,5]\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output)\n",
    "    \n",
    "    # Utilitzar Huber loss (més robust a outliers)\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.Huber(delta=1.0),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "        metrics=['mae', tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def prepare_aggregated_data(df: pd.DataFrame, embeddings_dict: Dict[str, np.ndarray], \n",
    "                           vector_size: int, use_tfidf: bool = False,\n",
    "                           tfidf_vectorizer=None, feature_names=None) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \n",
    "    X1, X2, Y = [], [], []\n",
    "    invalid_count = 0\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        sent1, sent2, label = row['sentence_1'], row['sentence_2'], row['label']\n",
    "        \n",
    "        if use_tfidf and tfidf_vectorizer is not None:\n",
    "            vec1 = get_sentence_embedding_tfidf(sent1, embeddings_dict, tfidf_vectorizer, \n",
    "                                              feature_names, vector_size)\n",
    "            vec2 = get_sentence_embedding_tfidf(sent2, embeddings_dict, tfidf_vectorizer, \n",
    "                                              feature_names, vector_size)\n",
    "        else:\n",
    "            vec1 = get_sentence_embedding_simple(sent1, embeddings_dict, vector_size)\n",
    "            vec2 = get_sentence_embedding_simple(sent2, embeddings_dict, vector_size)\n",
    "        \n",
    "        # Validar embeddings\n",
    "        if np.any(np.isnan(vec1)) or np.any(np.isnan(vec2)):\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "            \n",
    "        X1.append(vec1)\n",
    "        X2.append(vec2)\n",
    "        Y.append(label)\n",
    "    \n",
    "    if invalid_count > 0:\n",
    "        print(f\"Warning: {invalid_count} mostres amb embeddings invàlids eliminades\")\n",
    "    \n",
    "    return np.array(X1), np.array(X2), np.array(Y)\n",
    "\n",
    "# Codi d'entrenament\n",
    "if kv_model is not None:\n",
    "    aggregated_results = {}\n",
    "    \n",
    "    for dim in [50, 100, 150, 300]:\n",
    "        if dim in truncated_embeddings:\n",
    "            print(f\"\\n=== Entrenant Model Agregat {dim}D ===\")\n",
    "            \n",
    "            # Preparar dades\n",
    "            X1_train, X2_train, Y_train = prepare_aggregated_data(\n",
    "                train_df, truncated_embeddings[dim], dim\n",
    "            )\n",
    "            X1_val, X2_val, Y_val = prepare_aggregated_data(\n",
    "                val_df, truncated_embeddings[dim], dim\n",
    "            )\n",
    "            \n",
    "            print(f\"Forma de les dades: X1_train={X1_train.shape}, Y_train={Y_train.shape}\")\n",
    "            print(f\"Rang Y_train: [{Y_train.min():.2f}, {Y_train.max():.2f}]\")\n",
    "            \n",
    "            # Construir model\n",
    "            model = build_model_aggregated(embedding_dim=dim, hidden_size=256)\n",
    "            \n",
    "            # Callbacks\n",
    "            early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss', patience=15, restore_best_weights=True, \n",
    "                verbose=1, min_delta=0.001\n",
    "            )\n",
    "            \n",
    "            reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss', factor=0.3, patience=7, min_lr=1e-7, verbose=1\n",
    "            )\n",
    "            \n",
    "            # Learning rate scheduler\n",
    "            lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "                lambda epoch: 0.001 * (0.9 ** epoch)\n",
    "            )\n",
    "            \n",
    "            # Entrenament\n",
    "            history = model.fit(\n",
    "                [X1_train, X2_train], Y_train,\n",
    "                validation_data=([X1_val, X2_val], Y_val),\n",
    "                epochs=100,  # Més èpoques\n",
    "                batch_size=64,  # Batch size més gran\n",
    "                callbacks=[early_stopping, reduce_lr],\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # Avaluació\n",
    "            Y_pred = model.predict([X1_val, X2_val]).flatten()\n",
    "            \n",
    "            # Clips predictions to valid range\n",
    "            Y_pred = np.clip(Y_pred, 0, 5)\n",
    "            \n",
    "            pearson_corr, _ = pearsonr(Y_val, Y_pred)\n",
    "            mse = mean_squared_error(Y_val, Y_pred)\n",
    "            mae = mean_absolute_error(Y_val, Y_pred)\n",
    "            \n",
    "            aggregated_results[dim] = {\n",
    "                'model': model,\n",
    "                'history': history,\n",
    "                'pearson': pearson_corr,\n",
    "                'mse': mse,\n",
    "                'mae': mae,\n",
    "                'predictions': Y_pred\n",
    "            }\n",
    "            \n",
    "            print(f\"Resultats {dim}D - Pearson: {pearson_corr:.3f}, MSE: {mse:.3f}, MAE: {mae:.3f}\")\n",
    "            \n",
    "            # Diagnosis adicional\n",
    "            print(f\"Prediccions - Min: {Y_pred.min():.3f}, Max: {Y_pred.max():.3f}, Mean: {Y_pred.mean():.3f}\")\n",
    "            print(f\"Targets - Min: {Y_val.min():.3f}, Max: {Y_val.max():.3f}, Mean: {Y_val.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6363fef0",
   "metadata": {},
   "source": [
    "A continuació fem una comparativa dels models agregats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f41c4195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARACIÓ MODELS AGREGATS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8bfce\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_8bfce_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_8bfce_level0_col1\" class=\"col_heading level0 col1\" >Dimensions</th>\n",
       "      <th id=\"T_8bfce_level0_col2\" class=\"col_heading level0 col2\" >Pearson</th>\n",
       "      <th id=\"T_8bfce_level0_col3\" class=\"col_heading level0 col3\" >MSE</th>\n",
       "      <th id=\"T_8bfce_level0_col4\" class=\"col_heading level0 col4\" >MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_8bfce_row0_col0\" class=\"data row0 col0\" >Model Agregat</td>\n",
       "      <td id=\"T_8bfce_row0_col1\" class=\"data row0 col1\" >50D</td>\n",
       "      <td id=\"T_8bfce_row0_col2\" class=\"data row0 col2\" >0.381791</td>\n",
       "      <td id=\"T_8bfce_row0_col3\" class=\"data row0 col3\" >0.645532</td>\n",
       "      <td id=\"T_8bfce_row0_col4\" class=\"data row0 col4\" >0.605375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bfce_row1_col0\" class=\"data row1 col0\" >Model Agregat</td>\n",
       "      <td id=\"T_8bfce_row1_col1\" class=\"data row1 col1\" >100D</td>\n",
       "      <td id=\"T_8bfce_row1_col2\" class=\"data row1 col2\" >0.438910</td>\n",
       "      <td id=\"T_8bfce_row1_col3\" class=\"data row1 col3\" >0.610619</td>\n",
       "      <td id=\"T_8bfce_row1_col4\" class=\"data row1 col4\" >0.590582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bfce_row2_col0\" class=\"data row2 col0\" >Model Agregat</td>\n",
       "      <td id=\"T_8bfce_row2_col1\" class=\"data row2 col1\" >150D</td>\n",
       "      <td id=\"T_8bfce_row2_col2\" class=\"data row2 col2\" >0.412181</td>\n",
       "      <td id=\"T_8bfce_row2_col3\" class=\"data row2 col3\" >0.626643</td>\n",
       "      <td id=\"T_8bfce_row2_col4\" class=\"data row2 col4\" >0.598671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bfce_row3_col0\" class=\"data row3 col0\" >Model Agregat</td>\n",
       "      <td id=\"T_8bfce_row3_col1\" class=\"data row3 col1\" >300D</td>\n",
       "      <td id=\"T_8bfce_row3_col2\" class=\"data row3 col2\" >0.460064</td>\n",
       "      <td id=\"T_8bfce_row3_col3\" class=\"data row3 col3\" >0.599063</td>\n",
       "      <td id=\"T_8bfce_row3_col4\" class=\"data row3 col4\" >0.590259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28239f70950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n=== COMPARACIÓ MODELS AGREGATS ===\")\n",
    "# Crear un DataFrame amb els resultats dels models agregats\n",
    "aggr_data = []\n",
    "for dim in [50, 100, 150, 300]:\n",
    "    if dim in aggregated_results:\n",
    "        aggr_data.append({\n",
    "            'Model': 'Model Agregat',\n",
    "            'Dimensions': f'{dim}D',\n",
    "            'Pearson': aggregated_results[dim]['pearson'],\n",
    "            'MSE': aggregated_results[dim]['mse'],\n",
    "            'MAE': aggregated_results[dim]['mae']\n",
    "        })\n",
    "\n",
    "df_aggregated = pd.DataFrame(aggr_data)\n",
    "df_results = pd.concat([df_baseline_results, df_aggregated], ignore_index=True)\n",
    "display(df_aggregated.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd033a",
   "metadata": {},
   "source": [
    "### Anàlisi dels Models Agregats\n",
    "\n",
    "Els models agregats mostren una millora significativa respecte als resultats anteriors, amb correlacions de Pearson que oscil·len entre 0.39 i 0.44, superant clarament el llindar de referència establert pels baselines (0.356). El millor resultat s'obté amb 300D (Pearson: 0.440), seguint un patró de millora gradual amb l'augment de dimensions fins als 100D, després es manté relativament estable.\n",
    "\n",
    "Els errors MSE es mantenen consistents al voltant de 0.61-0.65, mentre que els MAE oscil·len entre 0.59-0.61, indicant prediccions més precises que les versions anteriors. La millora més notable es produeix entre 50D i 100D (increment del 7.5% en Pearson), mentre que l'augment posterior és més moderat.\n",
    "\n",
    "Aquests resultats demostren que les millores implementades en l'arquitectura del model (normalització L2, múltiples formes de combinació de vectors, regularització Huber loss) han tingut un impacte positiu substancial, convertint els models agregats en una alternativa viable que supera els baselines tradicionals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7c417",
   "metadata": {},
   "source": [
    "## 6. Model 2: Seqüència d'Embeddings amb Atenció\n",
    "\n",
    "Aquest segon model neuronal representa una aproximació més sofisticada que processa les frases com a seqüències d'embeddings de paraules, incorporant un mecanisme d'atenció per capturar millor les dependències entre paraules i la importància relativa de cada terme en el context de la similitud semàntica.\n",
    "\n",
    "### Arquitectura i Metodologia\n",
    "\n",
    "L'enfocament de seqüències d'embeddings manté l'ordre i la informació posicional de les paraules dins de cada frase, contrastant amb l'agregació simple del Model 1. L'arquitectura utilitza una capa d'embedding compartida que mapeja els índexs de paraules a vectors densos, seguida d'un mecanisme d'atenció que aprèn a ponderar automàticament la importància de cada paraula per a la tasca de similitud.\n",
    "\n",
    "La **capa d'atenció simple** implementada calcula pesos d'atenció mitjançant una xarxa neuronal de dues capes: primer transforma els embeddings d'entrada amb una capa densa amb activació `tanh`, després computa puntuacions d'atenció amb una segona capa densa. Els pesos resultants s'apliquen per generar un vector de context que representa tota la seqüència.\n",
    "\n",
    "El model calcula la **similitud cosinus** entre els vectors de context normalitzats de les dues frases, escalant el resultat de `[-1,1]` a `[0,1]` per coincidir amb les etiquetes del dataset. Aquest enfocament és més principiat que la regressió directa, ja que explota la naturalesa geomètrica de la similitud semàntica.\n",
    "\n",
    "### Experimentació amb Embeddings Entrenables\n",
    "\n",
    "Seguint els requeriments de la pràctica, s'implementen tres configuracions d'embeddings per analitzar l'impacte del fine-tuning:\n",
    "\n",
    "1. **Embeddings Pre-entrenats Frozen**: Els pesos de Word2Vec es mantenen fixos durant l'entrenament, preservant el coneixement semàntic original.\n",
    "\n",
    "2. **Embeddings Pre-entrenats Trainable**: Els embeddings s'inicialitzen amb Word2Vec però s'actualitzen durant l'entrenament, permetent l'adaptació a la tasca específica.\n",
    "\n",
    "3. **Embeddings Aleatoris**: Inicialització aleatòria dels embeddings, entrenant-los completament des de zero.\n",
    "\n",
    "Durant l'entrenament, es proven aquestes configuracions en diferents dimensions d'embedding (50D, 100D, 150D, 300D) per analitzar com la dimensionalitat interactua amb el fine-tuning dels embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21fdee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "class SimpleAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Capa d'atenció simple per agregar seqüències d'embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, units: int, **kwargs):\n",
    "        super(SimpleAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.dropout_s1 = tf.keras.layers.Dropout(0.3)\n",
    "        self.dropout_s2 = tf.keras.layers.Dropout(0.2)\n",
    "        self.W_s1 = tf.keras.layers.Dense(units, activation='tanh', use_bias=True, name=\"attention_transform\")\n",
    "        # Capa densa per calcular puntuacions d'atenció (vector de context)\n",
    "        self.W_s2 = tf.keras.layers.Dense(1, use_bias=False, name=\"attention_scorer\")\n",
    "        self.supports_masking = True  # Declara que aquesta capa suporta masking\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
    "        # forma dels inputs: (batch_size, sequence_length, embedding_dim)\n",
    "        # forma de la màscara: (batch_size, sequence_length) tensor booleà\n",
    "\n",
    "        # Estats ocults d'atenció\n",
    "        hidden_states = self.dropout_s1(self.W_s1(inputs))\n",
    "\n",
    "        # Calcular puntuacions d'atenció\n",
    "        scores = self.dropout_s2(self.W_s2(hidden_states))\n",
    "\n",
    "        if mask is not None:\n",
    "            # Aplicar la màscara a les puntuacions abans del softmax\n",
    "            expanded_mask = tf.expand_dims(tf.cast(mask, dtype=tf.float32), axis=-1)\n",
    "            # Afegir un número negatiu gran a les puntuacions emmascerades (padding)\n",
    "            scores += (1.0 - expanded_mask) * -1e9\n",
    "\n",
    "        # Calcular pesos d'atenció\n",
    "        attention_weights = tf.nn.softmax(scores, axis=1)\n",
    "\n",
    "        # Calcular el vector de context (suma ponderada dels embeddings d'entrada)\n",
    "        context_vector = tf.reduce_sum(inputs * attention_weights, axis=1)\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        config = super(SimpleAttention, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "\n",
    "    def compute_mask(self, inputs: tf.Tensor, mask: Optional[tf.Tensor] = None) -> Optional[tf.Tensor]:\n",
    "        return None\n",
    "\n",
    "\n",
    "def build_model_sequence(vocab_size: int = 1000, \n",
    "                        embedding_dim: int = 300,\n",
    "                        sequence_length: int = 32,\n",
    "                        learning_rate: float = 0.001,\n",
    "                        trainable_embeddings: bool = False,\n",
    "                        pretrained_weights: Optional[np.ndarray] = None,\n",
    "                        use_attention: bool = True,\n",
    "                        attention_units: int = 4) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Model de seqüència millorat basat en build_and_compile_model_2\n",
    "    Incorpora similitud cosinus i escalat adequat per STS\n",
    "    \"\"\"\n",
    "    input_1 = tf.keras.Input((sequence_length,), dtype=tf.int32, name=\"input_1\")\n",
    "    input_2 = tf.keras.Input((sequence_length,), dtype=tf.int32, name=\"input_2\")\n",
    "\n",
    "    # Determinar paràmetres efectius d'embedding\n",
    "    if pretrained_weights is not None:\n",
    "        effective_dictionary_size = pretrained_weights.shape[0]\n",
    "        effective_embedding_size = pretrained_weights.shape[1]\n",
    "        embedding_initializer = tf.keras.initializers.Constant(pretrained_weights)\n",
    "        is_embedding_trainable = trainable_embeddings\n",
    "        embedding_layer_name = \"embedding_pretrained\"\n",
    "    else:\n",
    "        effective_dictionary_size = vocab_size\n",
    "        effective_embedding_size = embedding_dim\n",
    "        embedding_initializer = 'uniform'\n",
    "        is_embedding_trainable = True\n",
    "        embedding_layer_name = \"embedding\"\n",
    "\n",
    "    # Capa d'Embedding Compartida\n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        input_dim=effective_dictionary_size,\n",
    "        output_dim=effective_embedding_size,\n",
    "        input_length=sequence_length,\n",
    "        mask_zero=True,\n",
    "        embeddings_initializer=embedding_initializer,\n",
    "        trainable=is_embedding_trainable,\n",
    "        name=embedding_layer_name\n",
    "    )\n",
    "\n",
    "    # Aplicar la capa d'embedding a ambdues entrades\n",
    "    embedded_1 = embedding_layer(input_1)  # Forma: (batch_size, sequence_length, effective_embedding_size)\n",
    "    embedded_2 = embedding_layer(input_2)  # Forma: (batch_size, sequence_length, effective_embedding_size)\n",
    "\n",
    "    # Capa compartida de pooling/atenció\n",
    "    if use_attention:\n",
    "        # Utilitzar mecanisme d'atenció\n",
    "        sentence_pooling_layer = SimpleAttention(units=attention_units, name=\"sentence_attention\")\n",
    "    else:\n",
    "        # Utilitzar pooling mitjà global simple\n",
    "        sentence_pooling_layer = tf.keras.layers.GlobalAveragePooling1D(name=\"sentence_attention_layer\")\n",
    "\n",
    "    # Aplicar pooling/atenció per obtenir vectors de frase\n",
    "    sentence_vector_1 = sentence_pooling_layer(embedded_1)\n",
    "    sentence_vector_2 = sentence_pooling_layer(embedded_2)\n",
    "\n",
    "    # Capa de projecció\n",
    "    first_projection_layer = tf.keras.layers.Dense(\n",
    "        effective_embedding_size,\n",
    "        activation='tanh',\n",
    "        kernel_initializer=tf.keras.initializers.Identity(),\n",
    "        bias_initializer=tf.keras.initializers.Zeros(),\n",
    "        name=\"projection_layer\"\n",
    "    )\n",
    "    dropout = tf.keras.layers.Dropout(0.2, name=\"projection_dropout\")\n",
    "    projected_1 = dropout(first_projection_layer(sentence_vector_1))\n",
    "    projected_2 = dropout(first_projection_layer(sentence_vector_2))\n",
    "\n",
    "    # Normalitzar els vectors projectats (normalització L2)\n",
    "    normalized_1 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_1\"\n",
    "    )(projected_1)\n",
    "    normalized_2 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_2\"\n",
    "    )(projected_2)\n",
    "\n",
    "    # Calcular Similitud Cosinus\n",
    "    similarity_score = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"cosine_similarity\"\n",
    "    )([normalized_1, normalized_2])\n",
    "\n",
    "    # Escalar similitud\n",
    "    output_layer = tf.keras.layers.Lambda(\n",
    "        lambda x: 0.5 * (1.0 + x), name=\"output_scaling\"\n",
    "    )(similarity_score)\n",
    "\n",
    "    # Definir el Model de Keras\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_1, input_2],\n",
    "        outputs=output_layer,\n",
    "        name=\"sequence_similarity_attention_model\"\n",
    "    )\n",
    "\n",
    "    # Compilar el model\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics=['mae'],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccb5fd",
   "metadata": {},
   "source": [
    "\n",
    "Aquestes són les funcions que es defineixen i seràn utilitzades posteriorment:\n",
    "\n",
    "*   `create_vocabulary_mapping`: Crea un diccionari que assigna a cada paraula un índex únic i viceversa. Això és essencial per convertir text en dades numèriques que els models poden processar.\n",
    "\n",
    "*   `sentence_to_sequence`: Transforma una frase en una seqüència d'índexs utilitzant el diccionari creat anteriorment. Aquesta funció també s'encarrega de fer padding o truncament per assegurar que totes les seqüències tinguin la mateixa longitud.\n",
    "\n",
    "*   `create_pretrained_embedding_matrix`: Crea una matriu d'embeddings pre-entrenats on cada fila correspon a l'embedding d'una paraula del vocabulari. Si una paraula no es troba en els embeddings pre-entrenats, el seu vector es manté a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6139a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Preparació de dades per al model de seqüències\n",
    "def create_vocabulary_mapping(sentences: List[str], max_vocab_size: int = 10000) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    \"\"\"\n",
    "    Crea un mapatge de vocabulari paraula->índex i índex->paraula\n",
    "    \"\"\"\n",
    "    word_counts = {}\n",
    "    for sentence in sentences:\n",
    "        words = preprocess_sentence(sentence)\n",
    "        for word in words:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    \n",
    "    # Ordenar per freqüència i prendre les més comunes\n",
    "    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Reservar índexs especials: 0=PAD, 1=UNK\n",
    "    word_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "    idx_to_word = {0: \"<PAD>\", 1: \"<UNK>\"}\n",
    "    \n",
    "    for word, count in sorted_words[:max_vocab_size-2]:  # -2 per PAD i UNK\n",
    "        idx = len(word_to_idx)\n",
    "        word_to_idx[word] = idx\n",
    "        idx_to_word[idx] = word\n",
    "    \n",
    "    return word_to_idx, idx_to_word\n",
    "\n",
    "def sentence_to_sequence(sentence: str, word_to_idx: Dict[str, int], \n",
    "                        max_length: int = 32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converteix una frase a seqüència d'índexs\n",
    "    \"\"\"\n",
    "    words = preprocess_sentence(sentence)\n",
    "    sequence = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in word_to_idx:\n",
    "            sequence.append(word_to_idx[word])\n",
    "        else:\n",
    "            sequence.append(word_to_idx[\"<UNK>\"])\n",
    "    \n",
    "    # Padding o truncament\n",
    "    if len(sequence) > max_length:\n",
    "        sequence = sequence[:max_length]\n",
    "    else:\n",
    "        sequence.extend([word_to_idx[\"<PAD>\"]] * (max_length - len(sequence)))\n",
    "    \n",
    "    return np.array(sequence)\n",
    "\n",
    "def create_pretrained_embedding_matrix(word_to_idx: Dict[str, int], \n",
    "                                     embeddings_dict: Dict[str, np.ndarray],\n",
    "                                     embedding_dim: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Crea una matriu d'embeddings pre-entrenats\n",
    "    \"\"\"\n",
    "    vocab_size = len(word_to_idx)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    \n",
    "    for word, idx in word_to_idx.items():\n",
    "        if word in embeddings_dict:\n",
    "            embedding_matrix[idx] = embeddings_dict[word]\n",
    "        # Les paraules no trobades mantenen vectors zero\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db06fa0",
   "metadata": {},
   "source": [
    "\n",
    "### Execució dels Models de Seqüència\n",
    "\n",
    "Aquesta secció obté els resultats obtinguts pels models de seqüència, que processen les frases com a seqüències d'embeddings de paraules i utilitzen un mecanisme d'atenció per capturar les dependències entre les paraules. S'han entrenat tres variants d'aquests models mencionades anteriorment, diferenciant-se en com s'han gestionat els embeddings:\n",
    "\n",
    "L'objectiu és comparar el rendiment d'aquestes variants i determinar quin enfocament proporciona els millors resultats en la tasca de similitud semàntica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67dc3a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparant dades per al model de seqüències...\n",
      "Vocabulari creat: 10000 paraules\n",
      "Longitud de seqüència: 32\n",
      "Dades de seqüència preparades: (2073, 32)\n",
      "\n",
      "=== MODELS DE SEQÜÈNCIA 50D ===\n",
      "Entrenant model amb embeddings pre-entrenats frozen (50D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "  Frozen - Pearson: 0.323, MSE: 3.210, MAE: 1.598\n",
      "Entrenant model amb embeddings pre-entrenats trainable (50D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "  Trainable - Pearson: 0.194, MSE: 3.210, MAE: 1.598\n",
      "Entrenant model amb embeddings aleatoris (50D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "  Random - Pearson: 0.117, MSE: 3.210, MAE: 1.598\n",
      "\n",
      "=== MODELS DE SEQÜÈNCIA 100D ===\n",
      "Entrenant model amb embeddings pre-entrenats frozen (100D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "  Frozen - Pearson: 0.278, MSE: 3.210, MAE: 1.598\n",
      "Entrenant model amb embeddings pre-entrenats trainable (100D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "  Trainable - Pearson: 0.201, MSE: 3.210, MAE: 1.598\n",
      "Entrenant model amb embeddings aleatoris (100D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "  Random - Pearson: 0.034, MSE: 3.210, MAE: 1.598\n",
      "\n",
      "=== MODELS DE SEQÜÈNCIA 150D ===\n",
      "Entrenant model amb embeddings pre-entrenats frozen (150D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "  Frozen - Pearson: 0.223, MSE: 3.210, MAE: 1.598\n",
      "Entrenant model amb embeddings pre-entrenats trainable (150D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "  Trainable - Pearson: 0.138, MSE: 3.210, MAE: 1.598\n",
      "Entrenant model amb embeddings aleatoris (150D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "  Random - Pearson: 0.032, MSE: 3.210, MAE: 1.598\n",
      "\n",
      "=== MODELS DE SEQÜÈNCIA 300D ===\n",
      "Entrenant model amb embeddings pre-entrenats frozen (300D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "  Frozen - Pearson: 0.219, MSE: 3.210, MAE: 1.598\n",
      "Entrenant model amb embeddings pre-entrenats trainable (300D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "  Trainable - Pearson: 0.061, MSE: 3.210, MAE: 1.598\n",
      "Entrenant model amb embeddings aleatoris (300D)...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "  Random - Pearson: -0.007, MSE: 3.210, MAE: 1.598\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparant dades per al model de seqüències...\")\n",
    "\n",
    "# Crear vocabulari\n",
    "word_to_idx, idx_to_word = create_vocabulary_mapping(all_sentences, max_vocab_size=10000)\n",
    "vocab_size = len(word_to_idx)\n",
    "sequence_length = 32\n",
    "\n",
    "print(f\"Vocabulari creat: {vocab_size} paraules\")\n",
    "print(f\"Longitud de seqüència: {sequence_length}\")\n",
    "\n",
    "# Convertir dades per a models de seqüència\n",
    "def prepare_sequence_data(df):\n",
    "    X1_seq, X2_seq, Y_seq = [], [], []\n",
    "    for _, row in df.iterrows():\n",
    "        seq1 = sentence_to_sequence(row['sentence_1'], word_to_idx, sequence_length)\n",
    "        seq2 = sentence_to_sequence(row['sentence_2'], word_to_idx, sequence_length)\n",
    "        X1_seq.append(seq1)\n",
    "        X2_seq.append(seq2)\n",
    "        Y_seq.append(row['label'])\n",
    "    return np.array(X1_seq), np.array(X2_seq), np.array(Y_seq)\n",
    "\n",
    "X1_train_seq, X2_train_seq, Y_train_seq = prepare_sequence_data(train_df)\n",
    "X1_val_seq, X2_val_seq, Y_val_seq = prepare_sequence_data(val_df)\n",
    "\n",
    "print(f\"Dades de seqüència preparades: {X1_train_seq.shape}\")\n",
    "\n",
    "# Entrenar models de seqüència per diferents dimensions\n",
    "sequence_results = {}\n",
    "\n",
    "for embedding_dim in [50, 100, 150, 300]:\n",
    "    if embedding_dim in truncated_embeddings:\n",
    "        print(f\"\\n=== MODELS DE SEQÜÈNCIA {embedding_dim}D ===\")\n",
    "        \n",
    "        # Preparar matriu d'embeddings pre-entrenats\n",
    "        pretrained_matrix = create_pretrained_embedding_matrix(\n",
    "            word_to_idx, truncated_embeddings[embedding_dim], embedding_dim\n",
    "        )\n",
    "        \n",
    "        # Model 1: Embeddings pre-entrenats (frozen)\n",
    "        print(f\"Entrenant model amb embeddings pre-entrenats frozen ({embedding_dim}D)...\")\n",
    "        model_seq_frozen = build_model_sequence(\n",
    "            vocab_size=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            sequence_length=sequence_length,\n",
    "            pretrained_weights=pretrained_matrix,\n",
    "            trainable_embeddings=False\n",
    "        )\n",
    "        \n",
    "        history_frozen = model_seq_frozen.fit(\n",
    "            [X1_train_seq, X2_train_seq], Y_train_seq,\n",
    "            validation_data=([X1_val_seq, X2_val_seq], Y_val_seq),\n",
    "            epochs=30,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        Y_pred_frozen = model_seq_frozen.predict([X1_val_seq, X2_val_seq]).flatten()\n",
    "        pearson_frozen, _ = pearsonr(Y_val_seq, Y_pred_frozen)\n",
    "        mse_frozen = mean_squared_error(Y_val_seq, Y_pred_frozen)\n",
    "        mae_frozen = mean_absolute_error(Y_val_seq, Y_pred_frozen)\n",
    "        \n",
    "        print(f\"  Frozen - Pearson: {pearson_frozen:.3f}, MSE: {mse_frozen:.3f}, MAE: {mae_frozen:.3f}\")\n",
    "        \n",
    "        # Model 2: Embeddings pre-entrenats (trainable)\n",
    "        print(f\"Entrenant model amb embeddings pre-entrenats trainable ({embedding_dim}D)...\")\n",
    "        model_seq_trainable = build_model_sequence(\n",
    "            vocab_size=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            sequence_length=sequence_length,\n",
    "            pretrained_weights=pretrained_matrix,\n",
    "            trainable_embeddings=True\n",
    "        )\n",
    "        \n",
    "        history_trainable = model_seq_trainable.fit(\n",
    "            [X1_train_seq, X2_train_seq], Y_train_seq,\n",
    "            validation_data=([X1_val_seq, X2_val_seq], Y_val_seq),\n",
    "            epochs=30,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        Y_pred_trainable = model_seq_trainable.predict([X1_val_seq, X2_val_seq]).flatten()\n",
    "        pearson_trainable, _ = pearsonr(Y_val_seq, Y_pred_trainable)\n",
    "        mse_trainable = mean_squared_error(Y_val_seq, Y_pred_trainable)\n",
    "        mae_trainable = mean_absolute_error(Y_val_seq, Y_pred_trainable)\n",
    "        \n",
    "        print(f\"  Trainable - Pearson: {pearson_trainable:.3f}, MSE: {mse_trainable:.3f}, MAE: {mae_trainable:.3f}\")\n",
    "        \n",
    "        # Model 3: Embeddings aleatoris\n",
    "        \n",
    "        print(f\"Entrenant model amb embeddings aleatoris ({embedding_dim}D)...\")\n",
    "        model_seq_random = build_model_sequence(\n",
    "            vocab_size=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            sequence_length=sequence_length,\n",
    "            pretrained_weights=None,\n",
    "            trainable_embeddings=True\n",
    "        )\n",
    "        \n",
    "        history_random = model_seq_random.fit(\n",
    "            [X1_train_seq, X2_train_seq], Y_train_seq,\n",
    "            validation_data=([X1_val_seq, X2_val_seq], Y_val_seq),\n",
    "            epochs=30,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        Y_pred_random = model_seq_random.predict([X1_val_seq, X2_val_seq]).flatten()\n",
    "        pearson_random, _ = pearsonr(Y_val_seq, Y_pred_random)\n",
    "        mse_random = mean_squared_error(Y_val_seq, Y_pred_random)\n",
    "        mae_random = mean_absolute_error(Y_val_seq, Y_pred_random)\n",
    "        \n",
    "        print(f\"  Random - Pearson: {pearson_random:.3f}, MSE: {mse_random:.3f}, MAE: {mae_random:.3f}\")\n",
    "        \n",
    "        sequence_results[embedding_dim] = {\n",
    "            'frozen': {'model': model_seq_frozen, 'pearson': pearson_frozen, 'mse': mse_frozen, 'mae': mae_frozen},\n",
    "            'trainable': {'model': model_seq_trainable, 'pearson': pearson_trainable, 'mse': mse_trainable, 'mae': mae_trainable},\n",
    "            'random': {'model': model_seq_random, 'pearson': pearson_random, 'mse': mse_random, 'mae': mae_random}\n",
    "        }\n",
    "    else:\n",
    "        sequence_results[embedding_dim] = {\n",
    "            'frozen': {'model': model_seq_frozen, 'pearson': pearson_frozen, 'mse': mse_frozen, 'mae': mae_frozen},\n",
    "            'trainable': {'model': model_seq_trainable, 'pearson': pearson_trainable, 'mse': mse_trainable, 'mae': mae_trainable}\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23decbc0",
   "metadata": {},
   "source": [
    "### Comparativa dels resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b76a9bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6ba58\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_6ba58_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6ba58_level0_col1\" class=\"col_heading level0 col1\" >Dimensions</th>\n",
       "      <th id=\"T_6ba58_level0_col2\" class=\"col_heading level0 col2\" >Pearson</th>\n",
       "      <th id=\"T_6ba58_level0_col3\" class=\"col_heading level0 col3\" >MSE</th>\n",
       "      <th id=\"T_6ba58_level0_col4\" class=\"col_heading level0 col4\" >MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row0_col0\" class=\"data row0 col0\" >Model Agregat</td>\n",
       "      <td id=\"T_6ba58_row0_col1\" class=\"data row0 col1\" >300D</td>\n",
       "      <td id=\"T_6ba58_row0_col2\" class=\"data row0 col2\" >0.460064</td>\n",
       "      <td id=\"T_6ba58_row0_col3\" class=\"data row0 col3\" >0.599063</td>\n",
       "      <td id=\"T_6ba58_row0_col4\" class=\"data row0 col4\" >0.590259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row1_col0\" class=\"data row1 col0\" >Model Agregat</td>\n",
       "      <td id=\"T_6ba58_row1_col1\" class=\"data row1 col1\" >100D</td>\n",
       "      <td id=\"T_6ba58_row1_col2\" class=\"data row1 col2\" >0.438910</td>\n",
       "      <td id=\"T_6ba58_row1_col3\" class=\"data row1 col3\" >0.610619</td>\n",
       "      <td id=\"T_6ba58_row1_col4\" class=\"data row1 col4\" >0.590582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row2_col0\" class=\"data row2 col0\" >Model Agregat</td>\n",
       "      <td id=\"T_6ba58_row2_col1\" class=\"data row2 col1\" >150D</td>\n",
       "      <td id=\"T_6ba58_row2_col2\" class=\"data row2 col2\" >0.412181</td>\n",
       "      <td id=\"T_6ba58_row2_col3\" class=\"data row2 col3\" >0.626643</td>\n",
       "      <td id=\"T_6ba58_row2_col4\" class=\"data row2 col4\" >0.598671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row3_col0\" class=\"data row3 col0\" >Model Agregat</td>\n",
       "      <td id=\"T_6ba58_row3_col1\" class=\"data row3 col1\" >50D</td>\n",
       "      <td id=\"T_6ba58_row3_col2\" class=\"data row3 col2\" >0.381791</td>\n",
       "      <td id=\"T_6ba58_row3_col3\" class=\"data row3 col3\" >0.645532</td>\n",
       "      <td id=\"T_6ba58_row3_col4\" class=\"data row3 col4\" >0.605375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row4_col0\" class=\"data row4 col0\" >Baseline Cosinus TF-IDF</td>\n",
       "      <td id=\"T_6ba58_row4_col1\" class=\"data row4 col1\" >150D</td>\n",
       "      <td id=\"T_6ba58_row4_col2\" class=\"data row4 col2\" >0.356393</td>\n",
       "      <td id=\"T_6ba58_row4_col3\" class=\"data row4 col3\" >5.332225</td>\n",
       "      <td id=\"T_6ba58_row4_col4\" class=\"data row4 col4\" >2.169574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row5_col0\" class=\"data row5 col0\" >Baseline Cosinus TF-IDF</td>\n",
       "      <td id=\"T_6ba58_row5_col1\" class=\"data row5 col1\" >300D</td>\n",
       "      <td id=\"T_6ba58_row5_col2\" class=\"data row5 col2\" >0.354348</td>\n",
       "      <td id=\"T_6ba58_row5_col3\" class=\"data row5 col3\" >5.084731</td>\n",
       "      <td id=\"T_6ba58_row5_col4\" class=\"data row5 col4\" >2.115081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row6_col0\" class=\"data row6 col0\" >Baseline Cosinus TF-IDF</td>\n",
       "      <td id=\"T_6ba58_row6_col1\" class=\"data row6 col1\" >100D</td>\n",
       "      <td id=\"T_6ba58_row6_col2\" class=\"data row6 col2\" >0.322226</td>\n",
       "      <td id=\"T_6ba58_row6_col3\" class=\"data row6 col3\" >5.572608</td>\n",
       "      <td id=\"T_6ba58_row6_col4\" class=\"data row6 col4\" >2.219603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row7_col0\" class=\"data row7 col0\" >Baseline Cosinus TF-IDF</td>\n",
       "      <td id=\"T_6ba58_row7_col1\" class=\"data row7 col1\" >50D</td>\n",
       "      <td id=\"T_6ba58_row7_col2\" class=\"data row7 col2\" >0.288679</td>\n",
       "      <td id=\"T_6ba58_row7_col3\" class=\"data row7 col3\" >5.862487</td>\n",
       "      <td id=\"T_6ba58_row7_col4\" class=\"data row7 col4\" >2.279328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row8_col0\" class=\"data row8 col0\" >Baseline Cosinus Simple</td>\n",
       "      <td id=\"T_6ba58_row8_col1\" class=\"data row8 col1\" >300D</td>\n",
       "      <td id=\"T_6ba58_row8_col2\" class=\"data row8 col2\" >0.243586</td>\n",
       "      <td id=\"T_6ba58_row8_col3\" class=\"data row8 col3\" >5.424708</td>\n",
       "      <td id=\"T_6ba58_row8_col4\" class=\"data row8 col4\" >2.181605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row9_col0\" class=\"data row9 col0\" >Baseline Cosinus Simple</td>\n",
       "      <td id=\"T_6ba58_row9_col1\" class=\"data row9 col1\" >150D</td>\n",
       "      <td id=\"T_6ba58_row9_col2\" class=\"data row9 col2\" >0.241811</td>\n",
       "      <td id=\"T_6ba58_row9_col3\" class=\"data row9 col3\" >5.704033</td>\n",
       "      <td id=\"T_6ba58_row9_col4\" class=\"data row9 col4\" >2.242433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row10_col0\" class=\"data row10 col0\" >Baseline Cosinus Simple</td>\n",
       "      <td id=\"T_6ba58_row10_col1\" class=\"data row10 col1\" >100D</td>\n",
       "      <td id=\"T_6ba58_row10_col2\" class=\"data row10 col2\" >0.213043</td>\n",
       "      <td id=\"T_6ba58_row10_col3\" class=\"data row10 col3\" >5.936303</td>\n",
       "      <td id=\"T_6ba58_row10_col4\" class=\"data row10 col4\" >2.290625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6ba58_row11_col0\" class=\"data row11 col0\" >Baseline Cosinus Simple</td>\n",
       "      <td id=\"T_6ba58_row11_col1\" class=\"data row11 col1\" >50D</td>\n",
       "      <td id=\"T_6ba58_row11_col2\" class=\"data row11 col2\" >0.175156</td>\n",
       "      <td id=\"T_6ba58_row11_col3\" class=\"data row11 col3\" >6.156660</td>\n",
       "      <td id=\"T_6ba58_row11_col4\" class=\"data row11 col4\" >2.335413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28259d2e570>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Recopilar datos para la comparación\n",
    "baseline_simple_pearson = []\n",
    "aggregated_pearson = []\n",
    "sequence_frozen_pearson = []\n",
    "dimensions = []\n",
    "\n",
    "for dim in [50, 100, 150, 300]:\n",
    "    if dim in baseline_results and dim in aggregated_results and dim in sequence_results:\n",
    "        baseline_simple_pearson.append(baseline_results[dim]['simple']['pearson'])\n",
    "        aggregated_pearson.append(aggregated_results[dim]['pearson'])\n",
    "        sequence_frozen_pearson.append(sequence_results[dim]['frozen']['pearson'])\n",
    "        dimensions.append(dim)\n",
    "\n",
    "# Crear gráfico de barras\n",
    "x = np.arange(len(dimensions))\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - width, baseline_simple_pearson, width, label='Baseline Simple')\n",
    "rects2 = ax.bar(x, aggregated_pearson, width, label='Aggregated')\n",
    "rects3 = ax.bar(x + width, sequence_frozen_pearson, width, label='Sequence Frozen')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "ax.set_xlabel('Embedding Dimensions')\n",
    "ax.set_ylabel('Pearson Correlation')\n",
    "ax.set_title('Comparison of Pearson Correlation for Different Models')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(dimensions)\n",
    "ax.legend()\n",
    "\n",
    "# Añadir valores en las barras\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(round(height, 3)),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "display(df_results.sort_values(by='Pearson', ascending=False).style.hide(axis=\"index\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82222528",
   "metadata": {},
   "source": [
    "L'anàlisi comparatiu dels diferents models implementats revela que el model Aggregated obté consistentment la correlació de Pearson més alta en totes les configuracions d'embedding, assolint un màxim de 0.440 amb dimensions de 300. Aquest model supera clarament el llindar de referència establert pels baselines de similitud cosinus.\n",
    "\n",
    "El model Baseline Simple mostra una millora progressiva amb l'augment de dimensions, tot i que sempre es manté per sota del rendiment del model Aggregated. La ponderació TF-IDF proporciona millores sistemàtiques respecte a la mitjana simple, especialment en dimensions baixes.\n",
    "\n",
    "El model Sequence Frozen presenta un comportament contraintuïtiu, obtenint bons resultats amb 50 dimensions però experimentant una degradació del rendiment en augmentar les dimensions. Això suggereix limitacions arquitectòniques o problemes d'optimització en espais d'alta dimensionalitat.\n",
    "\n",
    "## Conclusió\n",
    "\n",
    "El model Aggregated s'estableix com la solució més robusta i efectiva segons la correlació de Pearson, demostrant superioritat consistent que el converteix en l'opció recomanada per a la tasca de similitud semàntica. La seva arquitectura, que combina múltiples formes de representació vectorial juntament amb tècniques de regularització avançades, és especialment efectiva per a configuracions d'embedding d'alta dimensionalitat.\n",
    "\n",
    "Per a implementacions pràctiques, es recomana utilitzar configuracions de 100 dimensions o més per obtenir el millor equilibri entre rendiment i recursos computacionals. La configuració òptima es troba en 300 dimensions per maximitzar el rendiment absolut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "067130f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARACIÓ MODELS DE SEQÜÈNCIA (Pearson) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_be8e4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_be8e4_level0_col0\" class=\"col_heading level0 col0\" >Dimensions</th>\n",
       "      <th id=\"T_be8e4_level0_col1\" class=\"col_heading level0 col1\" >Frozen</th>\n",
       "      <th id=\"T_be8e4_level0_col2\" class=\"col_heading level0 col2\" >Trainable</th>\n",
       "      <th id=\"T_be8e4_level0_col3\" class=\"col_heading level0 col3\" >Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_be8e4_row0_col0\" class=\"data row0 col0\" >50D</td>\n",
       "      <td id=\"T_be8e4_row0_col1\" class=\"data row0 col1\" >0.323218</td>\n",
       "      <td id=\"T_be8e4_row0_col2\" class=\"data row0 col2\" >0.194175</td>\n",
       "      <td id=\"T_be8e4_row0_col3\" class=\"data row0 col3\" >0.117362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_be8e4_row1_col0\" class=\"data row1 col0\" >100D</td>\n",
       "      <td id=\"T_be8e4_row1_col1\" class=\"data row1 col1\" >0.277828</td>\n",
       "      <td id=\"T_be8e4_row1_col2\" class=\"data row1 col2\" >0.201211</td>\n",
       "      <td id=\"T_be8e4_row1_col3\" class=\"data row1 col3\" >0.034287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_be8e4_row2_col0\" class=\"data row2 col0\" >150D</td>\n",
       "      <td id=\"T_be8e4_row2_col1\" class=\"data row2 col1\" >0.222975</td>\n",
       "      <td id=\"T_be8e4_row2_col2\" class=\"data row2 col2\" >0.137989</td>\n",
       "      <td id=\"T_be8e4_row2_col3\" class=\"data row2 col3\" >0.031756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_be8e4_row3_col0\" class=\"data row3 col0\" >300D</td>\n",
       "      <td id=\"T_be8e4_row3_col1\" class=\"data row3 col1\" >0.218723</td>\n",
       "      <td id=\"T_be8e4_row3_col2\" class=\"data row3 col2\" >0.061040</td>\n",
       "      <td id=\"T_be8e4_row3_col3\" class=\"data row3 col3\" >-0.007457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28275623ce0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparació dels models de seqüència\n",
    "print(\"\\n=== COMPARACIÓ MODELS DE SEQÜÈNCIA (Pearson) ===\")\n",
    "\n",
    "sequence_comparison_data = []\n",
    "sequence_metrics = []\n",
    "\n",
    "for dim in [50, 100, 150, 300]:\n",
    "    if dim in sequence_results:\n",
    "        seq = sequence_results[dim]\n",
    "        # Comparació Pearson\n",
    "        frozen_r = seq['frozen']['pearson']\n",
    "        trainable_r = seq['trainable']['pearson']\n",
    "        row = {\n",
    "            'Dimensions': f'{dim}D',\n",
    "            'Frozen': frozen_r,\n",
    "            'Trainable': trainable_r,\n",
    "        }\n",
    "        if 'random' in seq:\n",
    "            row['Random'] = seq['random']['pearson']\n",
    "        sequence_comparison_data.append(row)\n",
    "        # Mètriques detallades\n",
    "        for key in ['frozen', 'trainable', 'random']:\n",
    "            if key in seq:\n",
    "                sequence_metrics.append({\n",
    "                    'Model': f\"Model Seqüència ({key.capitalize()})\",\n",
    "                    'Dimensions': f'{dim}D',\n",
    "                    'Pearson': seq[key]['pearson'],\n",
    "                    'MSE': seq[key]['mse'],\n",
    "                    'MAE': seq[key]['mae']\n",
    "                })\n",
    "\n",
    "# Mostrar taules\n",
    "display(pd.DataFrame(sequence_comparison_data).style.hide(axis=\"index\"))\n",
    "df_results = pd.concat([df_results, pd.DataFrame(sequence_metrics)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edfe48c",
   "metadata": {},
   "source": [
    "### Resultats i Anàlisi del Model de Seqüència\n",
    "\n",
    "Els resultats del Model 2 revelen patrons contraintuïtius sobre l'impacte del fine-tuning d'embeddings i la dimensionalitat en el rendiment. L'observació més destacada és que els embeddings pre-entrenats frozen superen consistentment els trainable en totes les configuracions de dimensions, amb diferències que oscil·len entre 0.086 en 50D i 0.175 en 300D. Aquesta superioritat suggereix que el coneixement semàntic original capurat pels vectors de Word2Vec és més valuós que l'adaptació específica a la tasca de similitud semàntica per a aquesta arquitectura particular.\n",
    "\n",
    "Contràriament a les expectatives teòriques, el rendiment dels embeddings frozen experimenta una degradació progressiva amb l'augment de dimensions, passant de 0.284 en 50D a 0.232 en 300D. Aquest comportament invers indica possibles problemes d'overfitting o dificultats d'optimització en espais d'alta dimensionalitat, suggerint que l'arquitectura de seqüència amb atenció no escala adequadament amb la complexitat dimensional. Els embeddings aleatoris confirmen la importància del pre-entrenament, mostrant rendiment molt pobre en dimensions extremes però una lleugera millora en 150D.\n",
    "\n",
    "La comparació amb el Model Agregat revela una diferència substancial de rendiment, ja que els millors resultats del Model 2 (frozen 50D: 0.284) són significativament inferiors al Model 1 (50D: 0.389). Aquesta disparitat indica que l'arquitectura de seqüència amb atenció no captura adequadament la similitud semàntica en aquest dataset. Les limitacions identificades inclouen un escalat subòptim de similitud cosinus al rang d'etiquetes, un mecanisme d'atenció massa simple, i una possible necessitat d'hiperparàmetres d'optimització més específics per a l'arquitectura complexa. Aquests resultats demostren que l'agregació simple és més efectiva que el processament seqüencial per aquesta tasca específica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae3b521",
   "metadata": {},
   "source": [
    "## 7. Experimentació Avançada\n",
    "\n",
    "Aquesta secció explora tècniques d'embedding alternatives per ampliar l'anàlisi comparativa i establir un marc de referència més complet per avaluar el rendiment dels models implementats. S'investiguen tres enfocaments diferents que representen metodologies diverses en el processament de llenguatge natural.\n",
    "\n",
    "### 7.1 Baseline One-Hot Encoding\n",
    "\n",
    "Com a punt de referència fonamental, s'implementa un baseline basat en representacions one-hot binàries del vocabulari. Aquest enfocament tradicional utilitza vectors esparsos on cada dimensió correspon a una paraula específica del vocabulari, prenent valor 1 si la paraula està present i 0 en cas contrari.\n",
    "\n",
    "La metodologia utilitza un `CountVectorizer` amb codificació binària limitada a vocabularis de mida variable (50, 100, 150, 300 característiques), permetent analitzar l'impacte de la mida del vocabulari en el rendiment. Les similituds cosinus entre vectors one-hot s'escalen linealment al rang d'etiquetes del dataset mitjançant normalització adaptativa que preserva la distribució original dels valors.\n",
    "\n",
    "Els resultats mostren un rendiment consistent però limitat, amb correlacions Pearson al voltant de 0.2-0.3, confirmant les limitacions inherents de les representacions esparses per capturar similitud semàntica. No obstant això, estableix una línia base robusta que demostra la necessitat d'embeddings densos pre-entrenats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ea6318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASELINE ONE-HOT ENCODING ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_08dfc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_08dfc_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_08dfc_level0_col1\" class=\"col_heading level0 col1\" >Dimensions</th>\n",
       "      <th id=\"T_08dfc_level0_col2\" class=\"col_heading level0 col2\" >Pearson</th>\n",
       "      <th id=\"T_08dfc_level0_col3\" class=\"col_heading level0 col3\" >MSE</th>\n",
       "      <th id=\"T_08dfc_level0_col4\" class=\"col_heading level0 col4\" >MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_08dfc_row0_col0\" class=\"data row0 col0\" >Baseline One-Hot</td>\n",
       "      <td id=\"T_08dfc_row0_col1\" class=\"data row0 col1\" >50D</td>\n",
       "      <td id=\"T_08dfc_row0_col2\" class=\"data row0 col2\" >0.208720</td>\n",
       "      <td id=\"T_08dfc_row0_col3\" class=\"data row0 col3\" >2.436487</td>\n",
       "      <td id=\"T_08dfc_row0_col4\" class=\"data row0 col4\" >1.304387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_08dfc_row1_col0\" class=\"data row1 col0\" >Baseline One-Hot</td>\n",
       "      <td id=\"T_08dfc_row1_col1\" class=\"data row1 col1\" >100D</td>\n",
       "      <td id=\"T_08dfc_row1_col2\" class=\"data row1 col2\" >0.224404</td>\n",
       "      <td id=\"T_08dfc_row1_col3\" class=\"data row1 col3\" >2.233863</td>\n",
       "      <td id=\"T_08dfc_row1_col4\" class=\"data row1 col4\" >1.237489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_08dfc_row2_col0\" class=\"data row2 col0\" >Baseline One-Hot</td>\n",
       "      <td id=\"T_08dfc_row2_col1\" class=\"data row2 col1\" >150D</td>\n",
       "      <td id=\"T_08dfc_row2_col2\" class=\"data row2 col2\" >0.240449</td>\n",
       "      <td id=\"T_08dfc_row2_col3\" class=\"data row2 col3\" >2.083808</td>\n",
       "      <td id=\"T_08dfc_row2_col4\" class=\"data row2 col4\" >1.189351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_08dfc_row3_col0\" class=\"data row3 col0\" >Baseline One-Hot</td>\n",
       "      <td id=\"T_08dfc_row3_col1\" class=\"data row3 col1\" >300D</td>\n",
       "      <td id=\"T_08dfc_row3_col2\" class=\"data row3 col2\" >0.286610</td>\n",
       "      <td id=\"T_08dfc_row3_col3\" class=\"data row3 col3\" >1.815696</td>\n",
       "      <td id=\"T_08dfc_row3_col4\" class=\"data row3 col4\" >1.098128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2827558bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baseline One-Hot (vocabulari limitat)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def evaluate_onehot(df: pd.DataFrame, max_features: int = 1000) -> Dict[str, float]:\n",
    "    all_sents = df['sentence_1'].tolist() + df['sentence_2'].tolist()\n",
    "    vectorizer = CountVectorizer(max_features=max_features, binary=True, lowercase=True)\n",
    "    vectorizer.fit(all_sents)\n",
    "    \n",
    "    similarities_raw = []\n",
    "    true_scores = df['label'].values\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        vec1 = vectorizer.transform([row['sentence_1']]).toarray()[0]\n",
    "        vec2 = vectorizer.transform([row['sentence_2']]).toarray()[0]\n",
    "        \n",
    "        if np.sum(vec1) == 0 or np.sum(vec2) == 0:\n",
    "            sim = 0.0\n",
    "        else:\n",
    "            sim = 1 - cosine(vec1, vec2)\n",
    "        \n",
    "        similarities_raw.append(sim)\n",
    "    \n",
    "    similarities_raw = np.array(similarities_raw)\n",
    "    \n",
    "    min_label, max_label = true_scores.min(), true_scores.max()\n",
    "    min_sim, max_sim = similarities_raw.min(), similarities_raw.max()\n",
    "    \n",
    "    # Escalat lineal\n",
    "    if max_sim > min_sim:\n",
    "        similarities_scaled = (similarities_raw - min_sim) / (max_sim - min_sim) * (max_label - min_label) + min_label\n",
    "    else:\n",
    "        similarities_scaled = np.full_like(similarities_raw, np.mean(true_scores))\n",
    "    \n",
    "    # Calcular mètriques\t\n",
    "    pearson_corr, _ = pearsonr(true_scores, similarities_scaled)\n",
    "    mse = mean_squared_error(true_scores, similarities_scaled)\n",
    "    mae = mean_absolute_error(true_scores, similarities_scaled)\n",
    "    \n",
    "    return {'pearson': pearson_corr, 'mse': mse, 'mae': mae, 'predictions': similarities_scaled}\n",
    "\n",
    "# Evaluar con escalado mejorado\n",
    "print(\"=== BASELINE ONE-HOT ENCODING ===\")\n",
    "onehot_improved_results = []\n",
    "onehot_dims = [50, 100, 150, 300]\n",
    "\n",
    "for max_features in onehot_dims:\n",
    "    res = evaluate_onehot(val_df, max_features=max_features)\n",
    "    onehot_improved_results.append({\n",
    "        'Model': 'Baseline One-Hot',\n",
    "        'Dimensions': f'{max_features}D',\n",
    "        'Pearson': res['pearson'],\n",
    "        'MSE': res['mse'],\n",
    "        'MAE': res['mae']\n",
    "    })\n",
    "\n",
    "df_onehot = pd.DataFrame(onehot_improved_results)\n",
    "df_results = pd.concat([df_results, df_onehot], ignore_index=True)\n",
    "display(df_onehot.style.hide(axis=\"index\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04fa074",
   "metadata": {},
   "source": [
    "Els resultats mostren un rendiment consistent però limitat, amb correlacions Pearson que milloren progressivament des de 0.209 (50D) fins a 0.287 (300D), representant una millora del 37% en augmentar la mida del vocabulari. Els valors MSE disminueixen corresponentment de 2.44 a 1.82, mentre que els MAE es redueixen de 1.30 a 1.10, indicant prediccions més precises amb vocabularis més extensos.\n",
    "\n",
    "Aquest patró de millora demostra que l'augment de la mida del vocabulari permet capturar més informació discriminativa, tot i que les correlacions es mantenen significativament per sota dels embeddings densos. Els resultats estableixen una línia base robusta que confirma les limitacions inherents de les representacions esparses per capturar similitud semàntica, justificant la necessitat d'embeddings densos pre-entrenats per a "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb17ff",
   "metadata": {},
   "source": [
    "\n",
    "### 7.2 Embeddings spaCy\n",
    "\n",
    "S'avaluen els embeddings del model spaCy `ca_core_news_md` per al català, que proporciona vectors densos de 300 dimensions entrenats amb tècniques de Word2Vec en un corpus especialitzat. Aquests embeddings representen una alternativa madura i optimitzada als vectors Word2Vec utilitzats anteriorment.\n",
    "\n",
    "Els vectors spaCy es trunquen a dimensions variables (50D, 100D, 150D, 300D) per mantenir la comparabilitat amb els experiments previs. El processament segueix la mateixa metodologia de similitud cosinus amb escalat adequat, permetent una avaluació directa del rendiment relatiu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "628ae46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTATS AMB SPAcy ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2f875\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_2f875_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_2f875_level0_col1\" class=\"col_heading level0 col1\" >Dimensions</th>\n",
       "      <th id=\"T_2f875_level0_col2\" class=\"col_heading level0 col2\" >Pearson</th>\n",
       "      <th id=\"T_2f875_level0_col3\" class=\"col_heading level0 col3\" >MSE</th>\n",
       "      <th id=\"T_2f875_level0_col4\" class=\"col_heading level0 col4\" >MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_2f875_row0_col0\" class=\"data row0 col0\" >spaCy Embeddings</td>\n",
       "      <td id=\"T_2f875_row0_col1\" class=\"data row0 col1\" >50D</td>\n",
       "      <td id=\"T_2f875_row0_col2\" class=\"data row0 col2\" >0.213691</td>\n",
       "      <td id=\"T_2f875_row0_col3\" class=\"data row0 col3\" >5.228719</td>\n",
       "      <td id=\"T_2f875_row0_col4\" class=\"data row0 col4\" >2.133155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2f875_row1_col0\" class=\"data row1 col0\" >spaCy Embeddings</td>\n",
       "      <td id=\"T_2f875_row1_col1\" class=\"data row1 col1\" >100D</td>\n",
       "      <td id=\"T_2f875_row1_col2\" class=\"data row1 col2\" >0.222045</td>\n",
       "      <td id=\"T_2f875_row1_col3\" class=\"data row1 col3\" >5.206132</td>\n",
       "      <td id=\"T_2f875_row1_col4\" class=\"data row1 col4\" >2.129271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2f875_row2_col0\" class=\"data row2 col0\" >spaCy Embeddings</td>\n",
       "      <td id=\"T_2f875_row2_col1\" class=\"data row2 col1\" >150D</td>\n",
       "      <td id=\"T_2f875_row2_col2\" class=\"data row2 col2\" >0.213552</td>\n",
       "      <td id=\"T_2f875_row2_col3\" class=\"data row2 col3\" >5.187900</td>\n",
       "      <td id=\"T_2f875_row2_col4\" class=\"data row2 col4\" >2.125197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2f875_row3_col0\" class=\"data row3 col0\" >spaCy Embeddings</td>\n",
       "      <td id=\"T_2f875_row3_col1\" class=\"data row3 col1\" >300D</td>\n",
       "      <td id=\"T_2f875_row3_col2\" class=\"data row3 col2\" >0.220473</td>\n",
       "      <td id=\"T_2f875_row3_col3\" class=\"data row3 col3\" >5.222367</td>\n",
       "      <td id=\"T_2f875_row3_col4\" class=\"data row3 col4\" >2.133863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2827526ec90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Carregar model de spaCy per al català\n",
    "nlp = spacy.load(\"ca_core_news_md\")\n",
    "\n",
    "spacy_results_list = []\n",
    "\n",
    "for dim in [50, 100, 150, 300]:\n",
    "    def get_spacy_embedding(sentence: str) -> np.ndarray:\n",
    "        \"\"\"Obté l'embedding de spaCy truncat a la dimensió desitjada\"\"\"\n",
    "        doc = nlp(sentence)\n",
    "        return doc.vector[:dim]\n",
    "\n",
    "    similarities = []\n",
    "    for _, row in val_df.iterrows():\n",
    "        vec1 = get_spacy_embedding(row['sentence_1'])\n",
    "        vec2 = get_spacy_embedding(row['sentence_2'])\n",
    "        if np.all(vec1 == 0) or np.all(vec2 == 0):\n",
    "            sim = 0.0\n",
    "        else:\n",
    "            sim = 1 - cosine(vec1, vec2)\n",
    "        sim_scaled = (sim + 1) * 2.5\n",
    "        similarities.append(sim_scaled)\n",
    "\n",
    "    pearson_corr, _ = pearsonr(val_df['label'].values, similarities)\n",
    "    mse = mean_squared_error(val_df['label'].values, similarities)\n",
    "    mae = mean_absolute_error(val_df['label'].values, similarities)\n",
    "    \n",
    "    spacy_results_list.append({\n",
    "        'Model': 'spaCy Embeddings',\n",
    "        'Dimensions': f\"{dim}D\",\n",
    "        'Pearson': pearson_corr,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae\n",
    "    })\n",
    "\n",
    "df_spacy_results = pd.DataFrame(spacy_results_list)\n",
    "df_results = pd.concat([df_results, df_spacy_results], ignore_index=True)\n",
    "print(\"\\n=== RESULTATS AMB SPAcy ===\")\n",
    "display(df_spacy_results.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40193aaf",
   "metadata": {},
   "source": [
    "Els resultats mostren un rendiment modest però consistent, amb correlacions Pearson al voltant de 0.21-0.22 en totes les dimensions i valors MSE estables entre 5.18-5.23. Aquest rendiment es situa clarament per sobre dels baselines one-hot però significativament inferior als embeddings Word2Vec truncats utilitzats anteriorment. \n",
    "\n",
    "La variació mínima entre dimensions (Pearson: 0.213-0.222; MSE: 5.18-5.23) suggereix que els embeddings spaCy mantenen informació semàntica robusta fins i tot en representacions truncades. No obstant això, la diferència substancial respecte als embeddings Word2Vec indica que l'optimització específica del corpus d'entrenament i la metodologia de pre-entrenament tenen un impacte crític en la qualitat dels embeddings per a tasques de similitud semàntica en català."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a803051",
   "metadata": {},
   "source": [
    "\n",
    "### 7.3 Models Transformer: RoBERTa Base i Fine-tuned\n",
    "\n",
    "#### RoBERTa Base\n",
    "\n",
    "S'implementa l'avaluació amb el model `projecte-aina/roberta-base-ca-v2`, un transformer pre-entrenat específicament per al català. Els embeddings s'obtenen dels tokens [CLS] de la darrera capa oculta, proporcionant representacions contextualitzades de frases completes.\n",
    "\n",
    "El processament es realitza en lots per optimitzar l'eficiència computacional, amb truncament adaptatiu a múltiples dimensions (50D, 100D, 150D, 300D, 768D (embeddings originals)) que permet analitzar l'impacte de la dimensionalitat en models transformer. La similitud cosinus vectoritzada entre embeddings normalitzats proporciona prediccions escalades al rang d'etiquetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bcfe699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at projecte-aina/roberta-base-ca-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Avaluant RoBERTa 50D ===\n",
      "Obtenint embeddings per frases 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 16/16 [00:09<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtenint embeddings per frases 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 16/16 [00:09<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculant similituds...\n",
      "Resultats 50D - Pearson: 0.470, MSE: 6.194, MAE: 2.347\n",
      "\n",
      "=== Avaluant RoBERTa 100D ===\n",
      "Obtenint embeddings per frases 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 16/16 [00:09<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtenint embeddings per frases 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 16/16 [00:10<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculant similituds...\n",
      "Resultats 100D - Pearson: 0.467, MSE: 6.308, MAE: 2.368\n",
      "\n",
      "=== Avaluant RoBERTa 150D ===\n",
      "Obtenint embeddings per frases 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 16/16 [00:09<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtenint embeddings per frases 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 16/16 [00:09<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculant similituds...\n",
      "Resultats 150D - Pearson: 0.480, MSE: 6.298, MAE: 2.366\n",
      "\n",
      "=== Avaluant RoBERTa 300D ===\n",
      "Obtenint embeddings per frases 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 16/16 [00:09<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtenint embeddings per frases 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 16/16 [00:10<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculant similituds...\n",
      "Resultats 300D - Pearson: 0.485, MSE: 6.267, MAE: 2.360\n",
      "\n",
      "=== Avaluant RoBERTa 768D ===\n",
      "Obtenint embeddings per frases 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 16/16 [00:09<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtenint embeddings per frases 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 16/16 [00:09<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculant similituds...\n",
      "Resultats 768D - Pearson: 0.478, MSE: 6.535, MAE: 2.411\n",
      "\n",
      "=== RESULTATS ROBERTA (BATCH PROCESSING) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3979d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_3979d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_3979d_level0_col1\" class=\"col_heading level0 col1\" >Dimensions</th>\n",
       "      <th id=\"T_3979d_level0_col2\" class=\"col_heading level0 col2\" >Pearson</th>\n",
       "      <th id=\"T_3979d_level0_col3\" class=\"col_heading level0 col3\" >MSE</th>\n",
       "      <th id=\"T_3979d_level0_col4\" class=\"col_heading level0 col4\" >MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_3979d_row0_col0\" class=\"data row0 col0\" >RoBERTa Base</td>\n",
       "      <td id=\"T_3979d_row0_col1\" class=\"data row0 col1\" >50D</td>\n",
       "      <td id=\"T_3979d_row0_col2\" class=\"data row0 col2\" >0.469612</td>\n",
       "      <td id=\"T_3979d_row0_col3\" class=\"data row0 col3\" >6.194461</td>\n",
       "      <td id=\"T_3979d_row0_col4\" class=\"data row0 col4\" >2.346709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3979d_row1_col0\" class=\"data row1 col0\" >RoBERTa Base</td>\n",
       "      <td id=\"T_3979d_row1_col1\" class=\"data row1 col1\" >100D</td>\n",
       "      <td id=\"T_3979d_row1_col2\" class=\"data row1 col2\" >0.466663</td>\n",
       "      <td id=\"T_3979d_row1_col3\" class=\"data row1 col3\" >6.307838</td>\n",
       "      <td id=\"T_3979d_row1_col4\" class=\"data row1 col4\" >2.368261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3979d_row2_col0\" class=\"data row2 col0\" >RoBERTa Base</td>\n",
       "      <td id=\"T_3979d_row2_col1\" class=\"data row2 col1\" >150D</td>\n",
       "      <td id=\"T_3979d_row2_col2\" class=\"data row2 col2\" >0.479817</td>\n",
       "      <td id=\"T_3979d_row2_col3\" class=\"data row2 col3\" >6.297709</td>\n",
       "      <td id=\"T_3979d_row2_col4\" class=\"data row2 col4\" >2.366380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3979d_row3_col0\" class=\"data row3 col0\" >RoBERTa Base</td>\n",
       "      <td id=\"T_3979d_row3_col1\" class=\"data row3 col1\" >300D</td>\n",
       "      <td id=\"T_3979d_row3_col2\" class=\"data row3 col2\" >0.484706</td>\n",
       "      <td id=\"T_3979d_row3_col3\" class=\"data row3 col3\" >6.267374</td>\n",
       "      <td id=\"T_3979d_row3_col4\" class=\"data row3 col4\" >2.360459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3979d_row4_col0\" class=\"data row4 col0\" >RoBERTa Base</td>\n",
       "      <td id=\"T_3979d_row4_col1\" class=\"data row4 col1\" >768D</td>\n",
       "      <td id=\"T_3979d_row4_col2\" class=\"data row4 col2\" >0.477782</td>\n",
       "      <td id=\"T_3979d_row4_col3\" class=\"data row4 col3\" >6.534671</td>\n",
       "      <td id=\"T_3979d_row4_col4\" class=\"data row4 col4\" >2.411201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x282921a3050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.spatial.distance import cosine\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = 'projecte-aina/roberta-base-ca-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_roberta_embeddings_batch(sentences: List[str], target_dim: int, batch_size: int = 32) -> np.ndarray:\n",
    "    \"\"\"Obté embeddings de RoBERTa per un batch de frases\"\"\"\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Processant batches\"):\n",
    "        batch_sentences = sentences[i:i+batch_size]\n",
    "        \n",
    "        # Tokenitzar el batch\n",
    "        inputs = tokenizer(\n",
    "            batch_sentences, \n",
    "            return_tensors=\"pt\", \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # Usar els tokens [CLS] com a representació de les frases\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "            # Truncar a la dimensió desitjada\n",
    "            batch_embeddings = batch_embeddings[:, :target_dim]\n",
    "            all_embeddings.append(batch_embeddings)\n",
    "    \n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "def calculate_cosine_similarities_vectorized(embeddings1: np.ndarray, embeddings2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calcula similituds cosinus de forma vectoritzada\"\"\"\n",
    "    # Normalitzar vectors\n",
    "    norms1 = np.linalg.norm(embeddings1, axis=1, keepdims=True)\n",
    "    norms2 = np.linalg.norm(embeddings2, axis=1, keepdims=True)\n",
    "    \n",
    "    # Evitar divisió per zero\n",
    "    norms1 = np.where(norms1 == 0, 1, norms1)\n",
    "    norms2 = np.where(norms2 == 0, 1, norms2)\n",
    "    \n",
    "    embeddings1_norm = embeddings1 / norms1\n",
    "    embeddings2_norm = embeddings2 / norms2\n",
    "    \n",
    "    # Calcular similitud cosinus\n",
    "    cosine_sims = np.sum(embeddings1_norm * embeddings2_norm, axis=1)\n",
    "    \n",
    "    return cosine_sims\n",
    "\n",
    "# Dimensions a avaluar\n",
    "dimensions = [50, 100, 150, 300, 768]  # Afegim més dimensions per comparar\n",
    "roberta_results_list = []\n",
    "\n",
    "for dim in dimensions:\n",
    "    print(f\"\\n=== Avaluant RoBERTa {dim}D ===\")\n",
    "    \n",
    "    # Preparar les frases\n",
    "    sentences1 = val_df['sentence_1'].tolist()\n",
    "    sentences2 = val_df['sentence_2'].tolist()\n",
    "    true_labels = val_df['label'].values\n",
    "    \n",
    "    print(\"Obtenint embeddings per frases 1...\")\n",
    "    embeddings1 = get_roberta_embeddings_batch(sentences1, target_dim=dim, batch_size=32)\n",
    "    \n",
    "    print(\"Obtenint embeddings per frases 2...\")\n",
    "    embeddings2 = get_roberta_embeddings_batch(sentences2, target_dim=dim, batch_size=32)\n",
    "    \n",
    "    print(\"Calculant similituds...\")\n",
    "    cosine_sims = calculate_cosine_similarities_vectorized(embeddings1, embeddings2)\n",
    "    \n",
    "    # Escalar similituds de [-1,1] a [0,5]\n",
    "    similarities_scaled = (cosine_sims + 1) * 2.5  # Escalar a [0, 5]\n",
    "    similarities_scaled = np.clip(similarities_scaled, 0, 5)  # Assegurar límits\n",
    "    \n",
    "    # Verificar valors problemàtics\n",
    "    if np.any(np.isnan(similarities_scaled)) or np.any(np.isinf(similarities_scaled)):\n",
    "        similarities_scaled = np.nan_to_num(similarities_scaled, nan=2.5, posinf=5.0, neginf=0.0)\n",
    "    \n",
    "    # Calcular mètriques\n",
    "    pearson_corr, p_value = pearsonr(true_labels, similarities_scaled)\n",
    "    mse = mean_squared_error(true_labels, similarities_scaled)\n",
    "    mae = mean_absolute_error(true_labels, similarities_scaled)\n",
    "    \n",
    "    print(f\"Resultats {dim}D - Pearson: {pearson_corr:.3f}, MSE: {mse:.3f}, MAE: {mae:.3f}\")\n",
    "    \n",
    "    # Afegir als resultats\n",
    "    roberta_results_list.append({\n",
    "        'Model': 'RoBERTa Base',\n",
    "        'Dimensions': f'{dim}D',\n",
    "        'Pearson': pearson_corr,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae\n",
    "    })\n",
    "\n",
    "# Crear DataFrame amb tots els resultats\n",
    "df_roberta_results = pd.DataFrame(roberta_results_list)\n",
    "df_results = pd.concat([df_results, df_roberta_results], ignore_index=True)\n",
    "\n",
    "# Mostrar resultats\n",
    "print(\"\\n=== RESULTATS ROBERTA (BATCH PROCESSING) ===\")\n",
    "display(df_roberta_results.style.hide(axis=\"index\"))\n",
    "\n",
    "# Opcional: Netejar memòria\n",
    "del model, tokenizer\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0fa92d",
   "metadata": {},
   "source": [
    "#### Anàlisi dels Resultats RoBERTa Base\n",
    "\n",
    "Els resultats de RoBERTa Base revelen un **rendiment substancialment superior** amb correlacions Pearson entre 0.467-0.485, superant significativament el millor model agregat (0.440) i establint un nou estàndard per a la similitud semàntica en català.\n",
    "\n",
    "**Patró dimensional**: RoBERTa mostra menor sensibilitat a la dimensionalitat que els embeddings estàtics, assolint el rendiment òptim amb 300D (Pearson: 0.485). La configuració completa de 768D experimenta lleugera degradació (0.478), possiblement per sobreajustament dimensional.\n",
    "\n",
    "**Eficàcia contextual**: La superioritat del 10% respecte al millor model neuronal anterior demostra l'eficàcia dels embeddings contextualitzats dels tokens [CLS]. La capacitat transformer per capturar dependències semàntiques complexes supera clarament les limitacions dels embeddings agregats estàtics.\n",
    "\n",
    "**Limitació dels errors**: Tot i l'excel·lent correlació, els **errors MSE es mantenen molt alts (5.9-6.5)** comparats amb els models agregats (~0.6), indicant un possible problema en l'escalat de similituds al rang [0,5]. Això suggereix que, malgrat la correlació superior, les prediccions absolutes de RoBERTa requereixen calibratge per a aplicacions que necessitin precisió en els valors numèrics específics, ja que RoBERTa produeix embeddings contextualitzats molt densos, de manera que la majoria de parelles de frase presenten similituds cosinus altes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa8374",
   "metadata": {},
   "source": [
    "\n",
    "#### RoBERTa STS Fine-tuned\n",
    "\n",
    "Com a referència d'estat de l'art, s'avalua el model `projecte-aina/roberta-base-ca-v2-cased-sts`, específicament fine-tunat per a tasques de similitud textual semàntica. Aquest model representa l'aproximació òptima per a la tasca específica, entrenat amb dades de STS en català.\n",
    "\n",
    "La implementació utilitza pipelines de classificació de text que processen parells de frases amb el format estàndard \"[sentence1] [SEP] [sentence2]\". El processament en lots optimitza el rendiment mentre manté la precisió de les prediccions.\n",
    "\n",
    "Els resultats estableixen el llindar superior de rendiment per a la tasca, amb correlacions Pearson significativament més altes que tots els enfocaments anteriors, confirmant l'eficàcia del fine-tuning específic per STS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b281f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AVALUANT RoBERTa STS FINE-TUNED ===\n",
      "WARNING:tensorflow:From C:\\Users\\11ser\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESULTATS RoBERTa STS FINE-TUNED ===\n",
      "Pearson: 0.750 (p-value: 0.000)\n",
      "MSE: 0.324\n",
      "MAE: 0.422\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_23447\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_23447_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_23447_level0_col1\" class=\"col_heading level0 col1\" >Dimensions</th>\n",
       "      <th id=\"T_23447_level0_col2\" class=\"col_heading level0 col2\" >Pearson</th>\n",
       "      <th id=\"T_23447_level0_col3\" class=\"col_heading level0 col3\" >MSE</th>\n",
       "      <th id=\"T_23447_level0_col4\" class=\"col_heading level0 col4\" >MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_23447_row0_col0\" class=\"data row0 col0\" >RoBERTa STS Fine-tuned</td>\n",
       "      <td id=\"T_23447_row0_col1\" class=\"data row0 col1\" >Full Model</td>\n",
       "      <td id=\"T_23447_row0_col2\" class=\"data row0 col2\" >0.749553</td>\n",
       "      <td id=\"T_23447_row0_col3\" class=\"data row0 col3\" >0.324229</td>\n",
       "      <td id=\"T_23447_row0_col4\" class=\"data row0 col4\" >0.422439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x282aa39cfe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "from scipy.special import logit\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "print(\"=== AVALUANT RoBERTa STS FINE-TUNED ===\")\n",
    "\n",
    "model_name = 'projecte-aina/roberta-base-ca-v2-cased-sts'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pipe = pipeline('text-classification', model=model_name, tokenizer=tokenizer)\n",
    "\n",
    "# Prova amb un format més simple\n",
    "def get_sts_scores(sentence_pairs):\n",
    "    \"\"\"Versió simplificada sense escalat complex\"\"\"\n",
    "    inputs = []\n",
    "    for s1, s2 in sentence_pairs:\n",
    "        # Format estàndard per STS\n",
    "        inputs.append(f\"{s1} [SEP] {s2}\")\n",
    "    \n",
    "    predictions = pipe(inputs)\n",
    "    \n",
    "    scores = []\n",
    "    for pred in predictions:\n",
    "        # Usar directament el score o aplicar escalat més simple\n",
    "        score = pred['score']\n",
    "        scores.append(score)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Preparar parelles de frases del dataset de validació\n",
    "sentence_pairs = [(row['sentence_1'], row['sentence_2']) for _, row in val_df.iterrows()]\n",
    "\n",
    "# Processar en lots\n",
    "batch_size = 50\n",
    "all_predictions = []\n",
    "\n",
    "for i in range(0, len(sentence_pairs), batch_size):\n",
    "    batch_pairs = sentence_pairs[i:i+batch_size]\n",
    "    batch_predictions = get_sts_scores(batch_pairs)\n",
    "    all_predictions.extend(batch_predictions)\n",
    "\n",
    "sts_predictions = np.array(all_predictions)\n",
    "true_labels = val_df['label'].values\n",
    "\n",
    "# Verificar valors problemàtics\n",
    "if np.any(np.isnan(sts_predictions)) or np.any(np.isinf(sts_predictions)):\n",
    "    sts_predictions = np.nan_to_num(sts_predictions, nan=2.5, posinf=5.0, neginf=0.0)\n",
    "\n",
    "# Calcular mètriques\n",
    "pearson_corr, p_value = pearsonr(true_labels, sts_predictions)\n",
    "mse = mean_squared_error(true_labels, sts_predictions)\n",
    "mae = mean_absolute_error(true_labels, sts_predictions)\n",
    "\n",
    "print(f\"=== RESULTATS RoBERTa STS FINE-TUNED ===\")\n",
    "print(f\"Pearson: {pearson_corr:.3f} (p-value: {p_value:.3f})\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "\n",
    "# Afegir als resultats globals\n",
    "roberta_sts_result = {\n",
    "    'Model': 'RoBERTa STS Fine-tuned',\n",
    "    'Dimensions': 'Full Model',\n",
    "    'Pearson': pearson_corr,\n",
    "    'MSE': mse,\n",
    "    'MAE': mae,\n",
    "}\n",
    "\n",
    "# Crear DataFrame\n",
    "df_roberta_sts = pd.DataFrame([roberta_sts_result])\n",
    "df_results = pd.concat([df_results, df_roberta_sts], ignore_index=True)\n",
    "\n",
    "# Mostrar resultats\n",
    "display(df_roberta_sts.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bdeac6",
   "metadata": {},
   "source": [
    "#### Anàlisi dels Resultats RoBERTa STS Fine-tuned\n",
    "\n",
    "Els resultats de RoBERTa STS Fine-tuned mostren un **rendiment destacat** amb una correlació Pearson de 0.750, millorant substancialment respecte al millor model agregat (0.440) i a RoBERTa Base (0.485).\n",
    "\n",
    "**Impacte del fine-tuning específic**: La millora significativa respecte a RoBERTa Base demostra els beneficis del fine-tuning especialitzat per a tasques STS. L'entrenament amb dades específiques de similitud semàntica permet al model aprendre representacions més adequades per a aquesta tasca particular.\n",
    "\n",
    "**Millora en precisió**: A diferència de RoBERTa Base, el model fine-tuned presenta **errors MSE considerablement reduïts (0.324)** comparats amb el model base (5.9-6.5). Aquesta reducció indica que el fine-tuning aborda efectivament els problemes d'escalat observats anteriorment, proporcionant prediccions més precises dins del rang [0,5].\n",
    "\n",
    "**Calibratge adequat**: El MAE de 0.422 suggereix que les prediccions estan ben calibrades, amb errors promig inferiors a 0.5 punts en l'escala de similitud. Això situa RoBERTa STS Fine-tuned com una opció sòlida per a aplicacions que requereixin tant bona correlació com precisió numèrica en similitud semàntica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5a16c",
   "metadata": {},
   "source": [
    "\n",
    "### 7.4 Anàlisi Comparativa\n",
    "\n",
    "L'experimentació avançada revela una jerarquia clara de rendiment: RoBERTa STS fine-tuned > RoBERTa Base > Embeddings Word2Vec > spaCy > One-Hot encoding. Aquesta progressió demostra la importància de la contextualització, el pre-entrenament específic de domini i el fine-tuning per a tasques específiques.\n",
    "\n",
    "Els models transformer mostren una menor sensibilitat a la dimensionalitat dels embeddings, mantenint rendiment alt fins i tot amb representacions truncades, contrastant amb la dependència dimensional observada en embeddings estàtics. Això suggereix que la informació contextual compensa parcialment la reducció dimensional.\n",
    "\n",
    "La comparació estableix referències clares per avaluar el rendiment relatiu dels models implementats i confirma que les tècniques modernes de NLP superen significativament els enfocaments tradicionals per a la similitud semàntica en català."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8272f302",
   "metadata": {},
   "source": [
    "## 8. Conclusions i Observacions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b2473f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultats guardats a 'resultats_sts_practica4.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RoBERTa STS Fine-tuned</td>\n",
       "      <td>Full Model</td>\n",
       "      <td>0.749553</td>\n",
       "      <td>0.324229</td>\n",
       "      <td>0.422439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RoBERTa Base</td>\n",
       "      <td>300D</td>\n",
       "      <td>0.484706</td>\n",
       "      <td>6.267374</td>\n",
       "      <td>2.360459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RoBERTa Base</td>\n",
       "      <td>150D</td>\n",
       "      <td>0.479817</td>\n",
       "      <td>6.297709</td>\n",
       "      <td>2.366380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RoBERTa Base</td>\n",
       "      <td>768D</td>\n",
       "      <td>0.477782</td>\n",
       "      <td>6.534671</td>\n",
       "      <td>2.411201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RoBERTa Base</td>\n",
       "      <td>50D</td>\n",
       "      <td>0.469612</td>\n",
       "      <td>6.194461</td>\n",
       "      <td>2.346709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RoBERTa Base</td>\n",
       "      <td>100D</td>\n",
       "      <td>0.466663</td>\n",
       "      <td>6.307838</td>\n",
       "      <td>2.368261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Model Agregat</td>\n",
       "      <td>300D</td>\n",
       "      <td>0.460064</td>\n",
       "      <td>0.599063</td>\n",
       "      <td>0.590259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model Agregat</td>\n",
       "      <td>100D</td>\n",
       "      <td>0.438910</td>\n",
       "      <td>0.610619</td>\n",
       "      <td>0.590582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Model Agregat</td>\n",
       "      <td>150D</td>\n",
       "      <td>0.412181</td>\n",
       "      <td>0.626643</td>\n",
       "      <td>0.598671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model Agregat</td>\n",
       "      <td>50D</td>\n",
       "      <td>0.381791</td>\n",
       "      <td>0.645532</td>\n",
       "      <td>0.605375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline Cosinus TF-IDF</td>\n",
       "      <td>150D</td>\n",
       "      <td>0.356393</td>\n",
       "      <td>5.332225</td>\n",
       "      <td>2.169574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline Cosinus TF-IDF</td>\n",
       "      <td>300D</td>\n",
       "      <td>0.354348</td>\n",
       "      <td>5.084731</td>\n",
       "      <td>2.115081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Model Seqüència (Frozen)</td>\n",
       "      <td>50D</td>\n",
       "      <td>0.323218</td>\n",
       "      <td>3.210178</td>\n",
       "      <td>1.597990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline Cosinus TF-IDF</td>\n",
       "      <td>100D</td>\n",
       "      <td>0.322226</td>\n",
       "      <td>5.572608</td>\n",
       "      <td>2.219603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline Cosinus TF-IDF</td>\n",
       "      <td>50D</td>\n",
       "      <td>0.288679</td>\n",
       "      <td>5.862487</td>\n",
       "      <td>2.279328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Baseline One-Hot</td>\n",
       "      <td>300D</td>\n",
       "      <td>0.286610</td>\n",
       "      <td>1.815696</td>\n",
       "      <td>1.098128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Model Seqüència (Frozen)</td>\n",
       "      <td>100D</td>\n",
       "      <td>0.277828</td>\n",
       "      <td>3.209970</td>\n",
       "      <td>1.597909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline Cosinus Simple</td>\n",
       "      <td>300D</td>\n",
       "      <td>0.243586</td>\n",
       "      <td>5.424708</td>\n",
       "      <td>2.181605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline Cosinus Simple</td>\n",
       "      <td>150D</td>\n",
       "      <td>0.241811</td>\n",
       "      <td>5.704033</td>\n",
       "      <td>2.242433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Baseline One-Hot</td>\n",
       "      <td>150D</td>\n",
       "      <td>0.240449</td>\n",
       "      <td>2.083808</td>\n",
       "      <td>1.189351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Baseline One-Hot</td>\n",
       "      <td>100D</td>\n",
       "      <td>0.224404</td>\n",
       "      <td>2.233863</td>\n",
       "      <td>1.237489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Model Seqüència (Frozen)</td>\n",
       "      <td>150D</td>\n",
       "      <td>0.222975</td>\n",
       "      <td>3.209788</td>\n",
       "      <td>1.597837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>spaCy Embeddings</td>\n",
       "      <td>100D</td>\n",
       "      <td>0.222045</td>\n",
       "      <td>5.206132</td>\n",
       "      <td>2.129271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>spaCy Embeddings</td>\n",
       "      <td>300D</td>\n",
       "      <td>0.220473</td>\n",
       "      <td>5.222367</td>\n",
       "      <td>2.133863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Model Seqüència (Frozen)</td>\n",
       "      <td>300D</td>\n",
       "      <td>0.218723</td>\n",
       "      <td>3.209729</td>\n",
       "      <td>1.597814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>spaCy Embeddings</td>\n",
       "      <td>50D</td>\n",
       "      <td>0.213691</td>\n",
       "      <td>5.228719</td>\n",
       "      <td>2.133155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>spaCy Embeddings</td>\n",
       "      <td>150D</td>\n",
       "      <td>0.213552</td>\n",
       "      <td>5.187900</td>\n",
       "      <td>2.125197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline Cosinus Simple</td>\n",
       "      <td>100D</td>\n",
       "      <td>0.213043</td>\n",
       "      <td>5.936303</td>\n",
       "      <td>2.290625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Baseline One-Hot</td>\n",
       "      <td>50D</td>\n",
       "      <td>0.208720</td>\n",
       "      <td>2.436487</td>\n",
       "      <td>1.304387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Model Seqüència (Trainable)</td>\n",
       "      <td>100D</td>\n",
       "      <td>0.201211</td>\n",
       "      <td>3.209565</td>\n",
       "      <td>1.597750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model Seqüència (Trainable)</td>\n",
       "      <td>50D</td>\n",
       "      <td>0.194175</td>\n",
       "      <td>3.209656</td>\n",
       "      <td>1.597775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline Cosinus Simple</td>\n",
       "      <td>50D</td>\n",
       "      <td>0.175156</td>\n",
       "      <td>6.156660</td>\n",
       "      <td>2.335413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Model Seqüència (Trainable)</td>\n",
       "      <td>150D</td>\n",
       "      <td>0.137989</td>\n",
       "      <td>3.209606</td>\n",
       "      <td>1.597765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Model Seqüència (Random)</td>\n",
       "      <td>50D</td>\n",
       "      <td>0.117362</td>\n",
       "      <td>3.210318</td>\n",
       "      <td>1.597987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Model Seqüència (Trainable)</td>\n",
       "      <td>300D</td>\n",
       "      <td>0.061040</td>\n",
       "      <td>3.209675</td>\n",
       "      <td>1.597788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Model Seqüència (Random)</td>\n",
       "      <td>100D</td>\n",
       "      <td>0.034287</td>\n",
       "      <td>3.209706</td>\n",
       "      <td>1.597775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Model Seqüència (Random)</td>\n",
       "      <td>150D</td>\n",
       "      <td>0.031756</td>\n",
       "      <td>3.209671</td>\n",
       "      <td>1.597763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Model Seqüència (Random)</td>\n",
       "      <td>300D</td>\n",
       "      <td>-0.007457</td>\n",
       "      <td>3.209879</td>\n",
       "      <td>1.597802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Dimensions   Pearson       MSE       MAE\n",
       "37       RoBERTa STS Fine-tuned  Full Model  0.749553  0.324229  0.422439\n",
       "35                 RoBERTa Base        300D  0.484706  6.267374  2.360459\n",
       "34                 RoBERTa Base        150D  0.479817  6.297709  2.366380\n",
       "36                 RoBERTa Base        768D  0.477782  6.534671  2.411201\n",
       "32                 RoBERTa Base         50D  0.469612  6.194461  2.346709\n",
       "33                 RoBERTa Base        100D  0.466663  6.307838  2.368261\n",
       "11                Model Agregat        300D  0.460064  0.599063  0.590259\n",
       "9                 Model Agregat        100D  0.438910  0.610619  0.590582\n",
       "10                Model Agregat        150D  0.412181  0.626643  0.598671\n",
       "8                 Model Agregat         50D  0.381791  0.645532  0.605375\n",
       "5       Baseline Cosinus TF-IDF        150D  0.356393  5.332225  2.169574\n",
       "7       Baseline Cosinus TF-IDF        300D  0.354348  5.084731  2.115081\n",
       "12     Model Seqüència (Frozen)         50D  0.323218  3.210178  1.597990\n",
       "3       Baseline Cosinus TF-IDF        100D  0.322226  5.572608  2.219603\n",
       "1       Baseline Cosinus TF-IDF         50D  0.288679  5.862487  2.279328\n",
       "27             Baseline One-Hot        300D  0.286610  1.815696  1.098128\n",
       "15     Model Seqüència (Frozen)        100D  0.277828  3.209970  1.597909\n",
       "6       Baseline Cosinus Simple        300D  0.243586  5.424708  2.181605\n",
       "4       Baseline Cosinus Simple        150D  0.241811  5.704033  2.242433\n",
       "26             Baseline One-Hot        150D  0.240449  2.083808  1.189351\n",
       "25             Baseline One-Hot        100D  0.224404  2.233863  1.237489\n",
       "18     Model Seqüència (Frozen)        150D  0.222975  3.209788  1.597837\n",
       "29             spaCy Embeddings        100D  0.222045  5.206132  2.129271\n",
       "31             spaCy Embeddings        300D  0.220473  5.222367  2.133863\n",
       "21     Model Seqüència (Frozen)        300D  0.218723  3.209729  1.597814\n",
       "28             spaCy Embeddings         50D  0.213691  5.228719  2.133155\n",
       "30             spaCy Embeddings        150D  0.213552  5.187900  2.125197\n",
       "2       Baseline Cosinus Simple        100D  0.213043  5.936303  2.290625\n",
       "24             Baseline One-Hot         50D  0.208720  2.436487  1.304387\n",
       "16  Model Seqüència (Trainable)        100D  0.201211  3.209565  1.597750\n",
       "13  Model Seqüència (Trainable)         50D  0.194175  3.209656  1.597775\n",
       "0       Baseline Cosinus Simple         50D  0.175156  6.156660  2.335413\n",
       "19  Model Seqüència (Trainable)        150D  0.137989  3.209606  1.597765\n",
       "14     Model Seqüència (Random)         50D  0.117362  3.210318  1.597987\n",
       "22  Model Seqüència (Trainable)        300D  0.061040  3.209675  1.597788\n",
       "17     Model Seqüència (Random)        100D  0.034287  3.209706  1.597775\n",
       "20     Model Seqüència (Random)        150D  0.031756  3.209671  1.597763\n",
       "23     Model Seqüència (Random)        300D -0.007457  3.209879  1.597802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 MILLOR MODEL:\n",
      "Model: RoBERTa STS Fine-tuned\n",
      "Dimensions: Full Model\n",
      "Pearson: 0.750\n",
      "MSE: 0.324\n"
     ]
    }
   ],
   "source": [
    "# Guardar els resultats en un fitxer CSV\n",
    "df_results.to_csv('resultats_sts_practica4.csv', index=False)\n",
    "print(\"Resultats guardats a 'resultats_sts_practica4.csv'\")\n",
    "\n",
    "# Mostrar el millor model global\n",
    "best_model_idx = df_results['Pearson'].idxmax()\n",
    "best_model_info = df_results.iloc[best_model_idx]\n",
    "\n",
    "display(df_results.sort_values(by='Pearson', ascending=False))\n",
    "\n",
    "print(f\"\\n🏆 MILLOR MODEL:\")\n",
    "print(f\"Model: {best_model_info['Model']}\")\n",
    "print(f\"Dimensions: {best_model_info['Dimensions']}\")\n",
    "print(f\"Pearson: {best_model_info['Pearson']:.3f}\")\n",
    "print(f\"MSE: {best_model_info['MSE']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2dc67d",
   "metadata": {},
   "source": [
    "L'anàlisi comparativa revela una jerarquia clara de rendiment en similitud semàntica per al català. **RoBERTa STS Fine-tuned** (Pearson: 0.750) lidera els resultats, seguit de **RoBERTa Base** (0.466-0.485) i els **models agregats** (0.389-0.440). Els baselines TF-IDF (0.289-0.356) i els models de seqüència (<0.31) ofereixen rendiments inferiors.\n",
    "\n",
    "### Patrons Clau\n",
    "\n",
    "Els **models agregats** mostren el millor equilibri entre rendiment i eficiència computacional, millorant consistentment amb l'augment de dimensions fins a 300D. **RoBERTa** demostra robustesa dimensional, mantenint rendiment alt fins i tot amb embeddings truncats. Contràriament, els **models de seqüència** experimenten degradació amb major dimensionalitat, suggerint limitacions arquitectòniques.\n",
    "\n",
    "### Insights dels Embeddings\n",
    "\n",
    "Els **embeddings pre-entrenats frozen** superen les versions trainable en models de seqüència, indicant que el coneixement semàntic original és més valuós que l'adaptació específica. Això contrasta amb les expectatives teòriques i suggereix problemes d'overfitting en l'arquitectura d'atenció implementada.\n",
    "\n",
    "### Recomanacions Pràctiques\n",
    "\n",
    "Per aplicacions reals, es recomana **models agregats 300D** com a solució equilibrada, tot i que el fine-tuning específic per STS proporciona millores substancials tant en correlació com en precisió de prediccions si es disposa de recursos computacionals suficients.\n",
    "\n",
    "L'estudi estableix directrius clares per seleccionar arquitectures segons requisits específics de rendiment i recursos, confirmant la superioritat dels enfocaments moderns de processament del llenguatge humà per a similitud semàntica en català."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb42d1",
   "metadata": {},
   "source": [
    "### Avaluació del test amb RoBERTa STS Fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "968da642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AVALUACIÓ FINAL EN TEST (RoBERTa STS Fine-tuned) ===\n",
      "Pearson: 0.788\n",
      "MSE: 0.286\n",
      "MAE: 0.390\n",
      "\n",
      "Exemples de predicció:\n",
      "Frase 1: El 1921, en ser anomenat professor permanent, va fundar l'Institut d'Estadística Matemàtica de la Universitat de Göttingen.\n",
      "Frase 2: El 1949 es va convertir en professor a la Universitat de Friburg de Brisgòvia, on va crear un Institut de Matemàtica Aplicada.\n",
      "Predicció: 2.069, Etiqueta real: 2.000\n",
      "--------------------------------------------------\n",
      "Frase 1: Els preus pugen tres dècimes al novembre a Tarragona i deixen la inflació anual en l'1,8%, la més baixa de Catalunya\n",
      "Frase 2: Els preus pugen vuit dècimes a l'octubre a Tarragona i deixen una inflació anual de l'1,6%, la més baixa de Catalunya\n",
      "Predicció: 3.044, Etiqueta real: 3.000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Avaluació final en test amb RoBERTa STS fine-tuned\n",
    "print(\"=== AVALUACIÓ FINAL EN TEST (RoBERTa STS Fine-tuned) ===\")\n",
    "\n",
    "# Preparar parelles de frases del test\n",
    "sentence_pairs_test = [(row['sentence_1'], row['sentence_2']) for _, row in test_df.iterrows()]\n",
    "\n",
    "# Processar en lots\n",
    "batch_size = 50\n",
    "all_predictions_test = []\n",
    "\n",
    "for i in range(0, len(sentence_pairs_test), batch_size):\n",
    "    batch_pairs = sentence_pairs_test[i:i+batch_size]\n",
    "    batch_predictions = get_sts_scores(batch_pairs)\n",
    "    all_predictions_test.extend(batch_predictions)\n",
    "\n",
    "sts_predictions_test = np.array(all_predictions_test)\n",
    "true_labels_test = test_df['label'].values\n",
    "\n",
    "# Verificar valors problemàtics\n",
    "if np.any(np.isnan(sts_predictions_test)) or np.any(np.isinf(sts_predictions_test)):\n",
    "    sts_predictions_test = np.nan_to_num(sts_predictions_test, nan=2.5, posinf=5.0, neginf=0.0)\n",
    "\n",
    "# Calcular mètriques\n",
    "pearson_corr_test, _ = pearsonr(true_labels_test, sts_predictions_test)\n",
    "mse_test = mean_squared_error(true_labels_test, sts_predictions_test)\n",
    "mae_test = mean_absolute_error(true_labels_test, sts_predictions_test)\n",
    "\n",
    "print(f\"Pearson: {pearson_corr_test:.3f}\")\n",
    "print(f\"MSE: {mse_test:.3f}\")\n",
    "print(f\"MAE: {mae_test:.3f}\")\n",
    "\n",
    "print(\"\\nExemples de predicció:\")\n",
    "for i in range(2):\n",
    "    print(f\"Frase 1: {test_df.iloc[i]['sentence_1']}\")\n",
    "    print(f\"Frase 2: {test_df.iloc[i]['sentence_2']}\")\n",
    "    print(f\"Predicció: {sts_predictions_test[i]:.3f}, Etiqueta real: {true_labels_test[i]:.3f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35692e37",
   "metadata": {},
   "source": [
    "Comprovem que obtenim molts bons resultats tant de Pearson com d'MSE i MAE amb aquest model, reafirmant que és el més adequat per a aquesta tasca."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f806f14",
   "metadata": {},
   "source": [
    "# Extra: Entrenament d'un model de classificació amb conjunt de dades TECLA\n",
    "\n",
    "Ara que sabem quins mètodes d'embeddings ens retornen els millors resultats, els podem aplicar a un model de classificació. La base de dades que ens donen és la de Text Classification (CA). Aquesta base de dades conté 3 variables: Sentence (conté el text), label1 (categoria, que és la nostra variable objectiu) i label2 (subcategoria). \n",
    "\n",
    "El nostre model de classificació serà un KNN i farem la comparació de la seva precisió amb 3 conjunts de dades amb embeddings diferents: RoBERTa Embeddings, Baseline Cosinus TF-IDF amb 150 dimensions, i Baseline Cosinus TF-IDF amb 300 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "303a81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'train.json', 'validation': 'dev.json', 'test': 'test.json'}\n",
    "train = pd.read_json(\"hf://datasets/projecte-aina/tecla/\" + splits[\"train\"])\n",
    "val = pd.read_json(\"hf://datasets/projecte-aina/tecla/\" + splits[\"validation\"])\n",
    "test = pd.read_json(\"hf://datasets/projecte-aina/tecla/\" + splits[\"test\"])\n",
    "\n",
    "train_sample_size = len(train)\n",
    "val_sample_size = len(val)\n",
    "test_sample_size = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f67f716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L'ACA reactiva el retorn del cànon de l'aigua ...</td>\n",
       "      <td>Economia</td>\n",
       "      <td>Agroalimentació</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Presó sota fiança per a un dels acusats de vio...</td>\n",
       "      <td>Societat</td>\n",
       "      <td>Successos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forcadell convoca per dilluns una reunió dels ...</td>\n",
       "      <td>Política</td>\n",
       "      <td>Parlament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMPLIACIÓ:De la Serna es compromet a accelerar...</td>\n",
       "      <td>Economia</td>\n",
       "      <td>Infraestructures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El jutge obre judici oral contra Neymar, Barto...</td>\n",
       "      <td>Societat</td>\n",
       "      <td>Judicial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    label1  \\\n",
       "0  L'ACA reactiva el retorn del cànon de l'aigua ...  Economia   \n",
       "1  Presó sota fiança per a un dels acusats de vio...  Societat   \n",
       "2  Forcadell convoca per dilluns una reunió dels ...  Política   \n",
       "3  AMPLIACIÓ:De la Serna es compromet a accelerar...  Economia   \n",
       "4  El jutge obre judici oral contra Neymar, Barto...  Societat   \n",
       "\n",
       "             label2  \n",
       "0   Agroalimentació  \n",
       "1         Successos  \n",
       "2         Parlament  \n",
       "3  Infraestructures  \n",
       "4          Judicial  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9890e936",
   "metadata": {},
   "source": [
    "Un inconvenient que té els embeddings roberta és que té un temps de computació molt elevat. Els pocs segons que triga generar els embeddings Baseline Cosinus passen a ser desenes de minuts per generar els embeddings roberta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2c97bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tecla_roberta(df, sample_size=None, batch_size=32, target_dim=768):\n",
    "    \"\"\"\n",
    "    Preprocessa les dades TECLA utilitzant embeddings RoBERTa amb processament per lotes\n",
    "    \"\"\"\n",
    "    # Si es defineix sample_size, agafar una mostra\n",
    "    if sample_size is not None and len(df) > sample_size:\n",
    "        df_sample = df.sample(n=sample_size, random_state=42)\n",
    "    else:\n",
    "        df_sample = df\n",
    "    \n",
    "    print(f\"Processant {len(df_sample)} exemples amb RoBERTa embeddings (batch processing)...\")\n",
    "    \n",
    "    # Obtenir totes les frases\n",
    "    sentences = df_sample['sentence'].tolist()\n",
    "    labels = df_sample['label1'].tolist()\n",
    "    \n",
    "    # Processar embeddings en lots\n",
    "    X = get_roberta_embeddings_batch(sentences, target_dim=target_dim, batch_size=batch_size)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aed5c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. RoBERTa embeddings:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at projecte-aina/roberta-base-ca-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant 1000 exemples amb RoBERTa embeddings (batch processing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 32/32 [04:23<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant 200 exemples amb RoBERTa embeddings (batch processing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 7/7 [00:43<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant 200 exemples amb RoBERTa embeddings (batch processing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 7/7 [00:46<00:00,  6.67s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. RoBERTa embeddings:\")\n",
    "\n",
    "model_name = 'projecte-aina/roberta-base-ca-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "roberta_train_size = min(1000, train_sample_size)\n",
    "roberta_val_size = min(200, val_sample_size)\n",
    "roberta_test_size = min(200, test_sample_size)\n",
    "\n",
    "X_train_roberta, y_train_labels_roberta = preprocess_tecla_roberta(\n",
    "    train, roberta_train_size\n",
    ")\n",
    "X_val_roberta, y_val_labels_roberta = preprocess_tecla_roberta(\n",
    "    val, roberta_val_size\n",
    ")\n",
    "X_test_roberta, y_test_labels_roberta = preprocess_tecla_roberta(\n",
    "    test, roberta_test_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5460742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessament de dades TECLA per al model de classificació amb embeddings agregats\n",
    "def preprocess_tecla_data_w2v(df, embeddings_dict, vector_size, sample_size=None, use_tfidf=False):\n",
    "    \"\"\"\n",
    "    Preprocessa les dades TECLA utilitzant embeddings Word2Vec\n",
    "    \"\"\"\n",
    "    # Si es defineix sample_size, agafar una mostra\n",
    "    if sample_size is not None and len(df) > sample_size:\n",
    "        df_sample = df.sample(n=sample_size, random_state=42)\n",
    "    else:\n",
    "        df_sample = df\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    print(f\"Processant {len(df_sample)} exemples amb Word2Vec {vector_size}D...\")\n",
    "    \n",
    "    for i, (_, row) in enumerate(df_sample.iterrows()):\n",
    "        if i % 200 == 0:\n",
    "            print(f\"Processat {i}/{len(df_sample)} exemples\")\n",
    "        \n",
    "        # Obtenir l'embedding de la frase\n",
    "        if use_tfidf and tfidf_vectorizer is not None:\n",
    "            sentence_embedding = get_sentence_embedding_tfidf(\n",
    "                row['sentence'], embeddings_dict, tfidf_vectorizer, \n",
    "                feature_names, vector_size\n",
    "            )\n",
    "        else:\n",
    "            sentence_embedding = get_sentence_embedding_simple(\n",
    "                row['sentence'], embeddings_dict, vector_size\n",
    "            )\n",
    "        \n",
    "        X.append(sentence_embedding)\n",
    "        y.append(row['label1'])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Crear mapatge d'etiquetes TECLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a8c3cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes TECLA: ['Cultura', 'Economia', 'Política', 'Societat']\n",
      "Nombre de classes: 4\n",
      "Preprocessant dades TECLA amb embeddings Word2Vec...\n",
      "Processant 90700 exemples amb Word2Vec 300D...\n",
      "Processat 0/90700 exemples\n",
      "Processat 200/90700 exemples\n",
      "Processat 400/90700 exemples\n",
      "Processat 600/90700 exemples\n",
      "Processat 800/90700 exemples\n",
      "Processat 1000/90700 exemples\n",
      "Processat 1200/90700 exemples\n",
      "Processat 1400/90700 exemples\n",
      "Processat 1600/90700 exemples\n",
      "Processat 1800/90700 exemples\n",
      "Processat 2000/90700 exemples\n",
      "Processat 2200/90700 exemples\n",
      "Processat 2400/90700 exemples\n",
      "Processat 2600/90700 exemples\n",
      "Processat 2800/90700 exemples\n",
      "Processat 3000/90700 exemples\n",
      "Processat 3200/90700 exemples\n",
      "Processat 3400/90700 exemples\n",
      "Processat 3600/90700 exemples\n",
      "Processat 3800/90700 exemples\n",
      "Processat 4000/90700 exemples\n",
      "Processat 4200/90700 exemples\n",
      "Processat 4400/90700 exemples\n",
      "Processat 4600/90700 exemples\n",
      "Processat 4800/90700 exemples\n",
      "Processat 5000/90700 exemples\n",
      "Processat 5200/90700 exemples\n",
      "Processat 5400/90700 exemples\n",
      "Processat 5600/90700 exemples\n",
      "Processat 5800/90700 exemples\n",
      "Processat 6000/90700 exemples\n",
      "Processat 6200/90700 exemples\n",
      "Processat 6400/90700 exemples\n",
      "Processat 6600/90700 exemples\n",
      "Processat 6800/90700 exemples\n",
      "Processat 7000/90700 exemples\n",
      "Processat 7200/90700 exemples\n",
      "Processat 7400/90700 exemples\n",
      "Processat 7600/90700 exemples\n",
      "Processat 7800/90700 exemples\n",
      "Processat 8000/90700 exemples\n",
      "Processat 8200/90700 exemples\n",
      "Processat 8400/90700 exemples\n",
      "Processat 8600/90700 exemples\n",
      "Processat 8800/90700 exemples\n",
      "Processat 9000/90700 exemples\n",
      "Processat 9200/90700 exemples\n",
      "Processat 9400/90700 exemples\n",
      "Processat 9600/90700 exemples\n",
      "Processat 9800/90700 exemples\n",
      "Processat 10000/90700 exemples\n",
      "Processat 10200/90700 exemples\n",
      "Processat 10400/90700 exemples\n",
      "Processat 10600/90700 exemples\n",
      "Processat 10800/90700 exemples\n",
      "Processat 11000/90700 exemples\n",
      "Processat 11200/90700 exemples\n",
      "Processat 11400/90700 exemples\n",
      "Processat 11600/90700 exemples\n",
      "Processat 11800/90700 exemples\n",
      "Processat 12000/90700 exemples\n",
      "Processat 12200/90700 exemples\n",
      "Processat 12400/90700 exemples\n",
      "Processat 12600/90700 exemples\n",
      "Processat 12800/90700 exemples\n",
      "Processat 13000/90700 exemples\n",
      "Processat 13200/90700 exemples\n",
      "Processat 13400/90700 exemples\n",
      "Processat 13600/90700 exemples\n",
      "Processat 13800/90700 exemples\n",
      "Processat 14000/90700 exemples\n",
      "Processat 14200/90700 exemples\n",
      "Processat 14400/90700 exemples\n",
      "Processat 14600/90700 exemples\n",
      "Processat 14800/90700 exemples\n",
      "Processat 15000/90700 exemples\n",
      "Processat 15200/90700 exemples\n",
      "Processat 15400/90700 exemples\n",
      "Processat 15600/90700 exemples\n",
      "Processat 15800/90700 exemples\n",
      "Processat 16000/90700 exemples\n",
      "Processat 16200/90700 exemples\n",
      "Processat 16400/90700 exemples\n",
      "Processat 16600/90700 exemples\n",
      "Processat 16800/90700 exemples\n",
      "Processat 17000/90700 exemples\n",
      "Processat 17200/90700 exemples\n",
      "Processat 17400/90700 exemples\n",
      "Processat 17600/90700 exemples\n",
      "Processat 17800/90700 exemples\n",
      "Processat 18000/90700 exemples\n",
      "Processat 18200/90700 exemples\n",
      "Processat 18400/90700 exemples\n",
      "Processat 18600/90700 exemples\n",
      "Processat 18800/90700 exemples\n",
      "Processat 19000/90700 exemples\n",
      "Processat 19200/90700 exemples\n",
      "Processat 19400/90700 exemples\n",
      "Processat 19600/90700 exemples\n",
      "Processat 19800/90700 exemples\n",
      "Processat 20000/90700 exemples\n",
      "Processat 20200/90700 exemples\n",
      "Processat 20400/90700 exemples\n",
      "Processat 20600/90700 exemples\n",
      "Processat 20800/90700 exemples\n",
      "Processat 21000/90700 exemples\n",
      "Processat 21200/90700 exemples\n",
      "Processat 21400/90700 exemples\n",
      "Processat 21600/90700 exemples\n",
      "Processat 21800/90700 exemples\n",
      "Processat 22000/90700 exemples\n",
      "Processat 22200/90700 exemples\n",
      "Processat 22400/90700 exemples\n",
      "Processat 22600/90700 exemples\n",
      "Processat 22800/90700 exemples\n",
      "Processat 23000/90700 exemples\n",
      "Processat 23200/90700 exemples\n",
      "Processat 23400/90700 exemples\n",
      "Processat 23600/90700 exemples\n",
      "Processat 23800/90700 exemples\n",
      "Processat 24000/90700 exemples\n",
      "Processat 24200/90700 exemples\n",
      "Processat 24400/90700 exemples\n",
      "Processat 24600/90700 exemples\n",
      "Processat 24800/90700 exemples\n",
      "Processat 25000/90700 exemples\n",
      "Processat 25200/90700 exemples\n",
      "Processat 25400/90700 exemples\n",
      "Processat 25600/90700 exemples\n",
      "Processat 25800/90700 exemples\n",
      "Processat 26000/90700 exemples\n",
      "Processat 26200/90700 exemples\n",
      "Processat 26400/90700 exemples\n",
      "Processat 26600/90700 exemples\n",
      "Processat 26800/90700 exemples\n",
      "Processat 27000/90700 exemples\n",
      "Processat 27200/90700 exemples\n",
      "Processat 27400/90700 exemples\n",
      "Processat 27600/90700 exemples\n",
      "Processat 27800/90700 exemples\n",
      "Processat 28000/90700 exemples\n",
      "Processat 28200/90700 exemples\n",
      "Processat 28400/90700 exemples\n",
      "Processat 28600/90700 exemples\n",
      "Processat 28800/90700 exemples\n",
      "Processat 29000/90700 exemples\n",
      "Processat 29200/90700 exemples\n",
      "Processat 29400/90700 exemples\n",
      "Processat 29600/90700 exemples\n",
      "Processat 29800/90700 exemples\n",
      "Processat 30000/90700 exemples\n",
      "Processat 30200/90700 exemples\n",
      "Processat 30400/90700 exemples\n",
      "Processat 30600/90700 exemples\n",
      "Processat 30800/90700 exemples\n",
      "Processat 31000/90700 exemples\n",
      "Processat 31200/90700 exemples\n",
      "Processat 31400/90700 exemples\n",
      "Processat 31600/90700 exemples\n",
      "Processat 31800/90700 exemples\n",
      "Processat 32000/90700 exemples\n",
      "Processat 32200/90700 exemples\n",
      "Processat 32400/90700 exemples\n",
      "Processat 32600/90700 exemples\n",
      "Processat 32800/90700 exemples\n",
      "Processat 33000/90700 exemples\n",
      "Processat 33200/90700 exemples\n",
      "Processat 33400/90700 exemples\n",
      "Processat 33600/90700 exemples\n",
      "Processat 33800/90700 exemples\n",
      "Processat 34000/90700 exemples\n",
      "Processat 34200/90700 exemples\n",
      "Processat 34400/90700 exemples\n",
      "Processat 34600/90700 exemples\n",
      "Processat 34800/90700 exemples\n",
      "Processat 35000/90700 exemples\n",
      "Processat 35200/90700 exemples\n",
      "Processat 35400/90700 exemples\n",
      "Processat 35600/90700 exemples\n",
      "Processat 35800/90700 exemples\n",
      "Processat 36000/90700 exemples\n",
      "Processat 36200/90700 exemples\n",
      "Processat 36400/90700 exemples\n",
      "Processat 36600/90700 exemples\n",
      "Processat 36800/90700 exemples\n",
      "Processat 37000/90700 exemples\n",
      "Processat 37200/90700 exemples\n",
      "Processat 37400/90700 exemples\n",
      "Processat 37600/90700 exemples\n",
      "Processat 37800/90700 exemples\n",
      "Processat 38000/90700 exemples\n",
      "Processat 38200/90700 exemples\n",
      "Processat 38400/90700 exemples\n",
      "Processat 38600/90700 exemples\n",
      "Processat 38800/90700 exemples\n",
      "Processat 39000/90700 exemples\n",
      "Processat 39200/90700 exemples\n",
      "Processat 39400/90700 exemples\n",
      "Processat 39600/90700 exemples\n",
      "Processat 39800/90700 exemples\n",
      "Processat 40000/90700 exemples\n",
      "Processat 40200/90700 exemples\n",
      "Processat 40400/90700 exemples\n",
      "Processat 40600/90700 exemples\n",
      "Processat 40800/90700 exemples\n",
      "Processat 41000/90700 exemples\n",
      "Processat 41200/90700 exemples\n",
      "Processat 41400/90700 exemples\n",
      "Processat 41600/90700 exemples\n",
      "Processat 41800/90700 exemples\n",
      "Processat 42000/90700 exemples\n",
      "Processat 42200/90700 exemples\n",
      "Processat 42400/90700 exemples\n",
      "Processat 42600/90700 exemples\n",
      "Processat 42800/90700 exemples\n",
      "Processat 43000/90700 exemples\n",
      "Processat 43200/90700 exemples\n",
      "Processat 43400/90700 exemples\n",
      "Processat 43600/90700 exemples\n",
      "Processat 43800/90700 exemples\n",
      "Processat 44000/90700 exemples\n",
      "Processat 44200/90700 exemples\n",
      "Processat 44400/90700 exemples\n",
      "Processat 44600/90700 exemples\n",
      "Processat 44800/90700 exemples\n",
      "Processat 45000/90700 exemples\n",
      "Processat 45200/90700 exemples\n",
      "Processat 45400/90700 exemples\n",
      "Processat 45600/90700 exemples\n",
      "Processat 45800/90700 exemples\n",
      "Processat 46000/90700 exemples\n",
      "Processat 46200/90700 exemples\n",
      "Processat 46400/90700 exemples\n",
      "Processat 46600/90700 exemples\n",
      "Processat 46800/90700 exemples\n",
      "Processat 47000/90700 exemples\n",
      "Processat 47200/90700 exemples\n",
      "Processat 47400/90700 exemples\n",
      "Processat 47600/90700 exemples\n",
      "Processat 47800/90700 exemples\n",
      "Processat 48000/90700 exemples\n",
      "Processat 48200/90700 exemples\n",
      "Processat 48400/90700 exemples\n",
      "Processat 48600/90700 exemples\n",
      "Processat 48800/90700 exemples\n",
      "Processat 49000/90700 exemples\n",
      "Processat 49200/90700 exemples\n",
      "Processat 49400/90700 exemples\n",
      "Processat 49600/90700 exemples\n",
      "Processat 49800/90700 exemples\n",
      "Processat 50000/90700 exemples\n",
      "Processat 50200/90700 exemples\n",
      "Processat 50400/90700 exemples\n",
      "Processat 50600/90700 exemples\n",
      "Processat 50800/90700 exemples\n",
      "Processat 51000/90700 exemples\n",
      "Processat 51200/90700 exemples\n",
      "Processat 51400/90700 exemples\n",
      "Processat 51600/90700 exemples\n",
      "Processat 51800/90700 exemples\n",
      "Processat 52000/90700 exemples\n",
      "Processat 52200/90700 exemples\n",
      "Processat 52400/90700 exemples\n",
      "Processat 52600/90700 exemples\n",
      "Processat 52800/90700 exemples\n",
      "Processat 53000/90700 exemples\n",
      "Processat 53200/90700 exemples\n",
      "Processat 53400/90700 exemples\n",
      "Processat 53600/90700 exemples\n",
      "Processat 53800/90700 exemples\n",
      "Processat 54000/90700 exemples\n",
      "Processat 54200/90700 exemples\n",
      "Processat 54400/90700 exemples\n",
      "Processat 54600/90700 exemples\n",
      "Processat 54800/90700 exemples\n",
      "Processat 55000/90700 exemples\n",
      "Processat 55200/90700 exemples\n",
      "Processat 55400/90700 exemples\n",
      "Processat 55600/90700 exemples\n",
      "Processat 55800/90700 exemples\n",
      "Processat 56000/90700 exemples\n",
      "Processat 56200/90700 exemples\n",
      "Processat 56400/90700 exemples\n",
      "Processat 56600/90700 exemples\n",
      "Processat 56800/90700 exemples\n",
      "Processat 57000/90700 exemples\n",
      "Processat 57200/90700 exemples\n",
      "Processat 57400/90700 exemples\n",
      "Processat 57600/90700 exemples\n",
      "Processat 57800/90700 exemples\n",
      "Processat 58000/90700 exemples\n",
      "Processat 58200/90700 exemples\n",
      "Processat 58400/90700 exemples\n",
      "Processat 58600/90700 exemples\n",
      "Processat 58800/90700 exemples\n",
      "Processat 59000/90700 exemples\n",
      "Processat 59200/90700 exemples\n",
      "Processat 59400/90700 exemples\n",
      "Processat 59600/90700 exemples\n",
      "Processat 59800/90700 exemples\n",
      "Processat 60000/90700 exemples\n",
      "Processat 60200/90700 exemples\n",
      "Processat 60400/90700 exemples\n",
      "Processat 60600/90700 exemples\n",
      "Processat 60800/90700 exemples\n",
      "Processat 61000/90700 exemples\n",
      "Processat 61200/90700 exemples\n",
      "Processat 61400/90700 exemples\n",
      "Processat 61600/90700 exemples\n",
      "Processat 61800/90700 exemples\n",
      "Processat 62000/90700 exemples\n",
      "Processat 62200/90700 exemples\n",
      "Processat 62400/90700 exemples\n",
      "Processat 62600/90700 exemples\n",
      "Processat 62800/90700 exemples\n",
      "Processat 63000/90700 exemples\n",
      "Processat 63200/90700 exemples\n",
      "Processat 63400/90700 exemples\n",
      "Processat 63600/90700 exemples\n",
      "Processat 63800/90700 exemples\n",
      "Processat 64000/90700 exemples\n",
      "Processat 64200/90700 exemples\n",
      "Processat 64400/90700 exemples\n",
      "Processat 64600/90700 exemples\n",
      "Processat 64800/90700 exemples\n",
      "Processat 65000/90700 exemples\n",
      "Processat 65200/90700 exemples\n",
      "Processat 65400/90700 exemples\n",
      "Processat 65600/90700 exemples\n",
      "Processat 65800/90700 exemples\n",
      "Processat 66000/90700 exemples\n",
      "Processat 66200/90700 exemples\n",
      "Processat 66400/90700 exemples\n",
      "Processat 66600/90700 exemples\n",
      "Processat 66800/90700 exemples\n",
      "Processat 67000/90700 exemples\n",
      "Processat 67200/90700 exemples\n",
      "Processat 67400/90700 exemples\n",
      "Processat 67600/90700 exemples\n",
      "Processat 67800/90700 exemples\n",
      "Processat 68000/90700 exemples\n",
      "Processat 68200/90700 exemples\n",
      "Processat 68400/90700 exemples\n",
      "Processat 68600/90700 exemples\n",
      "Processat 68800/90700 exemples\n",
      "Processat 69000/90700 exemples\n",
      "Processat 69200/90700 exemples\n",
      "Processat 69400/90700 exemples\n",
      "Processat 69600/90700 exemples\n",
      "Processat 69800/90700 exemples\n",
      "Processat 70000/90700 exemples\n",
      "Processat 70200/90700 exemples\n",
      "Processat 70400/90700 exemples\n",
      "Processat 70600/90700 exemples\n",
      "Processat 70800/90700 exemples\n",
      "Processat 71000/90700 exemples\n",
      "Processat 71200/90700 exemples\n",
      "Processat 71400/90700 exemples\n",
      "Processat 71600/90700 exemples\n",
      "Processat 71800/90700 exemples\n",
      "Processat 72000/90700 exemples\n",
      "Processat 72200/90700 exemples\n",
      "Processat 72400/90700 exemples\n",
      "Processat 72600/90700 exemples\n",
      "Processat 72800/90700 exemples\n",
      "Processat 73000/90700 exemples\n",
      "Processat 73200/90700 exemples\n",
      "Processat 73400/90700 exemples\n",
      "Processat 73600/90700 exemples\n",
      "Processat 73800/90700 exemples\n",
      "Processat 74000/90700 exemples\n",
      "Processat 74200/90700 exemples\n",
      "Processat 74400/90700 exemples\n",
      "Processat 74600/90700 exemples\n",
      "Processat 74800/90700 exemples\n",
      "Processat 75000/90700 exemples\n",
      "Processat 75200/90700 exemples\n",
      "Processat 75400/90700 exemples\n",
      "Processat 75600/90700 exemples\n",
      "Processat 75800/90700 exemples\n",
      "Processat 76000/90700 exemples\n",
      "Processat 76200/90700 exemples\n",
      "Processat 76400/90700 exemples\n",
      "Processat 76600/90700 exemples\n",
      "Processat 76800/90700 exemples\n",
      "Processat 77000/90700 exemples\n",
      "Processat 77200/90700 exemples\n",
      "Processat 77400/90700 exemples\n",
      "Processat 77600/90700 exemples\n",
      "Processat 77800/90700 exemples\n",
      "Processat 78000/90700 exemples\n",
      "Processat 78200/90700 exemples\n",
      "Processat 78400/90700 exemples\n",
      "Processat 78600/90700 exemples\n",
      "Processat 78800/90700 exemples\n",
      "Processat 79000/90700 exemples\n",
      "Processat 79200/90700 exemples\n",
      "Processat 79400/90700 exemples\n",
      "Processat 79600/90700 exemples\n",
      "Processat 79800/90700 exemples\n",
      "Processat 80000/90700 exemples\n",
      "Processat 80200/90700 exemples\n",
      "Processat 80400/90700 exemples\n",
      "Processat 80600/90700 exemples\n",
      "Processat 80800/90700 exemples\n",
      "Processat 81000/90700 exemples\n",
      "Processat 81200/90700 exemples\n",
      "Processat 81400/90700 exemples\n",
      "Processat 81600/90700 exemples\n",
      "Processat 81800/90700 exemples\n",
      "Processat 82000/90700 exemples\n",
      "Processat 82200/90700 exemples\n",
      "Processat 82400/90700 exemples\n",
      "Processat 82600/90700 exemples\n",
      "Processat 82800/90700 exemples\n",
      "Processat 83000/90700 exemples\n",
      "Processat 83200/90700 exemples\n",
      "Processat 83400/90700 exemples\n",
      "Processat 83600/90700 exemples\n",
      "Processat 83800/90700 exemples\n",
      "Processat 84000/90700 exemples\n",
      "Processat 84200/90700 exemples\n",
      "Processat 84400/90700 exemples\n",
      "Processat 84600/90700 exemples\n",
      "Processat 84800/90700 exemples\n",
      "Processat 85000/90700 exemples\n",
      "Processat 85200/90700 exemples\n",
      "Processat 85400/90700 exemples\n",
      "Processat 85600/90700 exemples\n",
      "Processat 85800/90700 exemples\n",
      "Processat 86000/90700 exemples\n",
      "Processat 86200/90700 exemples\n",
      "Processat 86400/90700 exemples\n",
      "Processat 86600/90700 exemples\n",
      "Processat 86800/90700 exemples\n",
      "Processat 87000/90700 exemples\n",
      "Processat 87200/90700 exemples\n",
      "Processat 87400/90700 exemples\n",
      "Processat 87600/90700 exemples\n",
      "Processat 87800/90700 exemples\n",
      "Processat 88000/90700 exemples\n",
      "Processat 88200/90700 exemples\n",
      "Processat 88400/90700 exemples\n",
      "Processat 88600/90700 exemples\n",
      "Processat 88800/90700 exemples\n",
      "Processat 89000/90700 exemples\n",
      "Processat 89200/90700 exemples\n",
      "Processat 89400/90700 exemples\n",
      "Processat 89600/90700 exemples\n",
      "Processat 89800/90700 exemples\n",
      "Processat 90000/90700 exemples\n",
      "Processat 90200/90700 exemples\n",
      "Processat 90400/90700 exemples\n",
      "Processat 90600/90700 exemples\n",
      "Processant 5669 exemples amb Word2Vec 300D...\n",
      "Processat 0/5669 exemples\n",
      "Processat 200/5669 exemples\n",
      "Processat 400/5669 exemples\n",
      "Processat 600/5669 exemples\n",
      "Processat 800/5669 exemples\n",
      "Processat 1000/5669 exemples\n",
      "Processat 1200/5669 exemples\n",
      "Processat 1400/5669 exemples\n",
      "Processat 1600/5669 exemples\n",
      "Processat 1800/5669 exemples\n",
      "Processat 2000/5669 exemples\n",
      "Processat 2200/5669 exemples\n",
      "Processat 2400/5669 exemples\n",
      "Processat 2600/5669 exemples\n",
      "Processat 2800/5669 exemples\n",
      "Processat 3000/5669 exemples\n",
      "Processat 3200/5669 exemples\n",
      "Processat 3400/5669 exemples\n",
      "Processat 3600/5669 exemples\n",
      "Processat 3800/5669 exemples\n",
      "Processat 4000/5669 exemples\n",
      "Processat 4200/5669 exemples\n",
      "Processat 4400/5669 exemples\n",
      "Processat 4600/5669 exemples\n",
      "Processat 4800/5669 exemples\n",
      "Processat 5000/5669 exemples\n",
      "Processat 5200/5669 exemples\n",
      "Processat 5400/5669 exemples\n",
      "Processat 5600/5669 exemples\n",
      "Processant 17007 exemples amb Word2Vec 300D...\n",
      "Processat 0/17007 exemples\n",
      "Processat 200/17007 exemples\n",
      "Processat 400/17007 exemples\n",
      "Processat 600/17007 exemples\n",
      "Processat 800/17007 exemples\n",
      "Processat 1000/17007 exemples\n",
      "Processat 1200/17007 exemples\n",
      "Processat 1400/17007 exemples\n",
      "Processat 1600/17007 exemples\n",
      "Processat 1800/17007 exemples\n",
      "Processat 2000/17007 exemples\n",
      "Processat 2200/17007 exemples\n",
      "Processat 2400/17007 exemples\n",
      "Processat 2600/17007 exemples\n",
      "Processat 2800/17007 exemples\n",
      "Processat 3000/17007 exemples\n",
      "Processat 3200/17007 exemples\n",
      "Processat 3400/17007 exemples\n",
      "Processat 3600/17007 exemples\n",
      "Processat 3800/17007 exemples\n",
      "Processat 4000/17007 exemples\n",
      "Processat 4200/17007 exemples\n",
      "Processat 4400/17007 exemples\n",
      "Processat 4600/17007 exemples\n",
      "Processat 4800/17007 exemples\n",
      "Processat 5000/17007 exemples\n",
      "Processat 5200/17007 exemples\n",
      "Processat 5400/17007 exemples\n",
      "Processat 5600/17007 exemples\n",
      "Processat 5800/17007 exemples\n",
      "Processat 6000/17007 exemples\n",
      "Processat 6200/17007 exemples\n",
      "Processat 6400/17007 exemples\n",
      "Processat 6600/17007 exemples\n",
      "Processat 6800/17007 exemples\n",
      "Processat 7000/17007 exemples\n",
      "Processat 7200/17007 exemples\n",
      "Processat 7400/17007 exemples\n",
      "Processat 7600/17007 exemples\n",
      "Processat 7800/17007 exemples\n",
      "Processat 8000/17007 exemples\n",
      "Processat 8200/17007 exemples\n",
      "Processat 8400/17007 exemples\n",
      "Processat 8600/17007 exemples\n",
      "Processat 8800/17007 exemples\n",
      "Processat 9000/17007 exemples\n",
      "Processat 9200/17007 exemples\n",
      "Processat 9400/17007 exemples\n",
      "Processat 9600/17007 exemples\n",
      "Processat 9800/17007 exemples\n",
      "Processat 10000/17007 exemples\n",
      "Processat 10200/17007 exemples\n",
      "Processat 10400/17007 exemples\n",
      "Processat 10600/17007 exemples\n",
      "Processat 10800/17007 exemples\n",
      "Processat 11000/17007 exemples\n",
      "Processat 11200/17007 exemples\n",
      "Processat 11400/17007 exemples\n",
      "Processat 11600/17007 exemples\n",
      "Processat 11800/17007 exemples\n",
      "Processat 12000/17007 exemples\n",
      "Processat 12200/17007 exemples\n",
      "Processat 12400/17007 exemples\n",
      "Processat 12600/17007 exemples\n",
      "Processat 12800/17007 exemples\n",
      "Processat 13000/17007 exemples\n",
      "Processat 13200/17007 exemples\n",
      "Processat 13400/17007 exemples\n",
      "Processat 13600/17007 exemples\n",
      "Processat 13800/17007 exemples\n",
      "Processat 14000/17007 exemples\n",
      "Processat 14200/17007 exemples\n",
      "Processat 14400/17007 exemples\n",
      "Processat 14600/17007 exemples\n",
      "Processat 14800/17007 exemples\n",
      "Processat 15000/17007 exemples\n",
      "Processat 15200/17007 exemples\n",
      "Processat 15400/17007 exemples\n",
      "Processat 15600/17007 exemples\n",
      "Processat 15800/17007 exemples\n",
      "Processat 16000/17007 exemples\n",
      "Processat 16200/17007 exemples\n",
      "Processat 16400/17007 exemples\n",
      "Processat 16600/17007 exemples\n",
      "Processat 16800/17007 exemples\n",
      "Processat 17000/17007 exemples\n",
      "\n",
      "Dades Word2Vec preprocessades:\n",
      "X_train_tecla: (90700, 300)\n",
      "X_val_tecla: (5669, 300)\n",
      "X_test_tecla: (17007, 300)\n",
      "Dimensions d'embedding Word2Vec: 300\n"
     ]
    }
   ],
   "source": [
    "unique_labels = sorted(train['label1'].unique())\n",
    "label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "print(f\"Classes TECLA: {unique_labels}\")\n",
    "print(f\"Nombre de classes: {num_classes}\")\n",
    "\n",
    "# Preprocessar dades TECLA amb Word2Vec (usar mostres més petites per velocitat)\n",
    "if kv_model is not None:\n",
    "    print(\"Preprocessant dades TECLA amb embeddings Word2Vec...\")\n",
    "    \n",
    "    # Preparar dades d'entrenament amb Word2Vec (mitjana simple)\n",
    "    X_train_tecla150, y_train_labels150 = preprocess_tecla_data_w2v(\n",
    "        train, truncated_embeddings[embedding_dim], embedding_dim, \n",
    "        train_sample_size, use_tfidf=False\n",
    "    )\n",
    "    X_val_tecla150, y_val_labels150 = preprocess_tecla_data_w2v(\n",
    "        val, truncated_embeddings[embedding_dim], embedding_dim, \n",
    "        val_sample_size, use_tfidf=False\n",
    "    )\n",
    "    X_test_tecla150, y_test_labels150 = preprocess_tecla_data_w2v(\n",
    "        test, truncated_embeddings[embedding_dim], embedding_dim, \n",
    "        test_sample_size, use_tfidf=False\n",
    "    )\n",
    "    \n",
    "    # Convertir etiquetes a índexs\n",
    "    y_train_tecla150 = np.array([label_to_idx[label] for label in y_train_labels150])\n",
    "    y_val_tecla150 = np.array([label_to_idx[label] for label in y_val_labels150])\n",
    "    y_test_tecla150 = np.array([label_to_idx[label] for label in y_test_labels150])\n",
    "    \n",
    "    # Convertir a one-hot encoding\n",
    "    y_train_onehot150 = tf.keras.utils.to_categorical(y_train_tecla150, num_classes)\n",
    "    y_val_onehot150 = tf.keras.utils.to_categorical(y_val_tecla150, num_classes)\n",
    "    y_test_onehot150 = tf.keras.utils.to_categorical(y_test_tecla150, num_classes)\n",
    "    \n",
    "    print(f\"\\nDades Word2Vec preprocessades:\")\n",
    "    print(f\"X_train_tecla: {X_train_tecla150.shape}\")\n",
    "    print(f\"X_val_tecla: {X_val_tecla150.shape}\")\n",
    "    print(f\"X_test_tecla: {X_test_tecla150.shape}\")\n",
    "    print(f\"Dimensions d'embedding Word2Vec: {X_train_tecla150.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bdf2179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes TECLA: ['Cultura', 'Economia', 'Política', 'Societat']\n",
      "Nombre de classes: 4\n",
      "Preprocessant dades TECLA amb embeddings Word2Vec...\n",
      "Processant 1000 exemples amb Word2Vec 300D...\n",
      "Processat 0/1000 exemples\n",
      "Processat 200/1000 exemples\n",
      "Processat 400/1000 exemples\n",
      "Processat 600/1000 exemples\n",
      "Processat 800/1000 exemples\n",
      "Processant 200 exemples amb Word2Vec 300D...\n",
      "Processat 0/200 exemples\n",
      "Processant 200 exemples amb Word2Vec 300D...\n",
      "Processat 0/200 exemples\n",
      "\n",
      "Dades Word2Vec preprocessades:\n",
      "X_train_tecla: (1000, 300)\n",
      "X_val_tecla: (200, 300)\n",
      "X_test_tecla: (200, 300)\n",
      "Dimensions d'embedding Word2Vec: 300\n"
     ]
    }
   ],
   "source": [
    "unique_labels = sorted(train['label1'].unique())\n",
    "label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "print(f\"Classes TECLA: {unique_labels}\")\n",
    "print(f\"Nombre de classes: {num_classes}\")\n",
    "\n",
    "# Preprocessar dades TECLA amb Word2Vec (usar mostres més petites per velocitat)\n",
    "if kv_model is not None:\n",
    "    print(\"Preprocessant dades TECLA amb embeddings Word2Vec...\")\n",
    "    \n",
    "    train_sample_size = 1000\n",
    "    val_sample_size = 200\n",
    "    test_sample_size = 200\n",
    "    embedding_dim = 300  \n",
    "    \n",
    "    # Preparar dades d'entrenament amb Word2Vec (mitjana simple)\n",
    "    X_train_tecla300, y_train_labels300 = preprocess_tecla_data_w2v(\n",
    "        train, truncated_embeddings[embedding_dim], embedding_dim, \n",
    "        train_sample_size, use_tfidf=False\n",
    "    )\n",
    "    X_val_tecla300, y_val_labels300 = preprocess_tecla_data_w2v(\n",
    "        val, truncated_embeddings[embedding_dim], embedding_dim, \n",
    "        val_sample_size, use_tfidf=False\n",
    "    )\n",
    "    X_test_tecla300, y_test_labels300 = preprocess_tecla_data_w2v(\n",
    "        test, truncated_embeddings[embedding_dim], embedding_dim, \n",
    "        test_sample_size, use_tfidf=False\n",
    "    )\n",
    "    \n",
    "    # Convertir etiquetes a índexs\n",
    "    y_train_tecla300 = np.array([label_to_idx[label] for label in y_train_labels300])\n",
    "    y_val_tecla300 = np.array([label_to_idx[label] for label in y_val_labels300])\n",
    "    y_test_tecla300 = np.array([label_to_idx[label] for label in y_test_labels300])\n",
    "    \n",
    "    # Convertir a one-hot encoding\n",
    "    y_train_onehot300 = tf.keras.utils.to_categorical(y_train_tecla300, num_classes)\n",
    "    y_val_onehot300 = tf.keras.utils.to_categorical(y_val_tecla300, num_classes)\n",
    "    y_test_onehot300 = tf.keras.utils.to_categorical(y_test_tecla300, num_classes)\n",
    "    \n",
    "    print(f\"\\nDades Word2Vec preprocessades:\")\n",
    "    print(f\"X_train_tecla: {X_train_tecla300.shape}\")\n",
    "    print(f\"X_val_tecla: {X_val_tecla300.shape}\")\n",
    "    print(f\"X_test_tecla: {X_test_tecla300.shape}\")\n",
    "    print(f\"Dimensions d'embedding Word2Vec: {X_train_tecla300.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212e0330",
   "metadata": {},
   "source": [
    "Com ja s'ha explicat, el classificador és un model de KNN, provarem diferents valors per observar quin valor de K és el millor per a cada conjunt de dades, i compararem el millor resultat de cadascún."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b00ed32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DATASET: 150D\n",
      "==================================================\n",
      "\n",
      "Entrenant KNN amb k=1 per 150D...\n",
      "k=1 - Validació: 0.864, Test: 0.862\n",
      "\n",
      "Entrenant KNN amb k=3 per 150D...\n",
      "k=3 - Validació: 0.866, Test: 0.864\n",
      "\n",
      "Entrenant KNN amb k=5 per 150D...\n",
      "k=5 - Validació: 0.870, Test: 0.869\n",
      "\n",
      "Entrenant KNN amb k=7 per 150D...\n",
      "k=7 - Validació: 0.876, Test: 0.874\n",
      "\n",
      "Entrenant KNN amb k=9 per 150D...\n",
      "k=9 - Validació: 0.876, Test: 0.872\n",
      "\n",
      "Entrenant KNN amb k=12 per 150D...\n",
      "k=12 - Validació: 0.876, Test: 0.875\n",
      "\n",
      "Entrenant KNN amb k=15 per 150D...\n",
      "k=15 - Validació: 0.875, Test: 0.876\n",
      "\n",
      "==================================================\n",
      "DATASET: 300D\n",
      "==================================================\n",
      "\n",
      "Entrenant KNN amb k=1 per 300D...\n",
      "k=1 - Validació: 0.655, Test: 0.710\n",
      "\n",
      "Entrenant KNN amb k=3 per 300D...\n",
      "k=3 - Validació: 0.710, Test: 0.745\n",
      "\n",
      "Entrenant KNN amb k=5 per 300D...\n",
      "k=5 - Validació: 0.710, Test: 0.700\n",
      "\n",
      "Entrenant KNN amb k=7 per 300D...\n",
      "k=7 - Validació: 0.710, Test: 0.720\n",
      "\n",
      "Entrenant KNN amb k=9 per 300D...\n",
      "k=9 - Validació: 0.715, Test: 0.710\n",
      "\n",
      "Entrenant KNN amb k=12 per 300D...\n",
      "k=12 - Validació: 0.700, Test: 0.745\n",
      "\n",
      "Entrenant KNN amb k=15 per 300D...\n",
      "k=15 - Validació: 0.705, Test: 0.745\n",
      "\n",
      "==================================================\n",
      "DATASET: RoBERTa\n",
      "==================================================\n",
      "\n",
      "Entrenant KNN amb k=1 per RoBERTa...\n",
      "k=1 - Validació: 0.880, Test: 0.910\n",
      "\n",
      "Entrenant KNN amb k=3 per RoBERTa...\n",
      "k=3 - Validació: 0.880, Test: 0.905\n",
      "\n",
      "Entrenant KNN amb k=5 per RoBERTa...\n",
      "k=5 - Validació: 0.905, Test: 0.920\n",
      "\n",
      "Entrenant KNN amb k=7 per RoBERTa...\n",
      "k=7 - Validació: 0.900, Test: 0.910\n",
      "\n",
      "Entrenant KNN amb k=9 per RoBERTa...\n",
      "k=9 - Validació: 0.890, Test: 0.925\n",
      "\n",
      "Entrenant KNN amb k=12 per RoBERTa...\n",
      "k=12 - Validació: 0.890, Test: 0.930\n",
      "\n",
      "Entrenant KNN amb k=15 per RoBERTa...\n",
      "k=15 - Validació: 0.890, Test: 0.920\n",
      "\n",
      "============================================================\n",
      "RESUM DE RESULTATS KNN\n",
      "============================================================\n",
      "\n",
      "🏆 Millor model per 150D: k=7\n",
      "Accuracy de validació: 0.876\n",
      "Accuracy de test: 0.874\n",
      "\n",
      "🏆 Millor model per 300D: k=9\n",
      "Accuracy de validació: 0.715\n",
      "Accuracy de test: 0.710\n",
      "\n",
      "🏆 Millor model per RoBERTa: k=5\n",
      "Accuracy de validació: 0.905\n",
      "Accuracy de test: 0.920\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "COMPARACIÓ FINAL\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Millor k</th>\n",
       "      <th>Accuracy Validació</th>\n",
       "      <th>Accuracy Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150D</td>\n",
       "      <td>7</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300D</td>\n",
       "      <td>9</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RoBERTa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Millor k Accuracy Validació Accuracy Test\n",
       "0     150D         7              0.876         0.874\n",
       "1     300D         9              0.715         0.710\n",
       "2  RoBERTa         5              0.905         0.920"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Executar KNN amb les tres versions diferents de dades TECLA\n",
    "\n",
    "# Primer, definir les variables de dades per a les tres versions\n",
    "datasets = {\n",
    "    '150D': {\n",
    "        'X_train': X_train_tecla150,\n",
    "        'X_val': X_val_tecla150, \n",
    "        'X_test': X_test_tecla150,\n",
    "        'y_train': y_train_tecla150,\n",
    "        'y_val': y_val_tecla150,\n",
    "        'y_test': y_test_tecla150\n",
    "    },\n",
    "    '300D': {\n",
    "        'X_train': X_train_tecla300,\n",
    "        'X_val': X_val_tecla300,\n",
    "        'X_test': X_test_tecla300,\n",
    "        'y_train': y_train_tecla300,\n",
    "        'y_val': y_val_tecla300,\n",
    "        'y_test': y_test_tecla300\n",
    "    },\n",
    "    'RoBERTa': {\n",
    "        'X_train': X_train_roberta,\n",
    "        'X_val': X_val_roberta,\n",
    "        'X_test': X_test_roberta,\n",
    "        'y_train': y_train_labels_roberta,\n",
    "        'y_val': y_val_labels_roberta,\n",
    "        'y_test': y_test_labels_roberta\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convertir etiquetes RoBERTa a índexs si són strings\n",
    "if isinstance(datasets['RoBERTa']['y_train'][0], str):\n",
    "    datasets['RoBERTa']['y_train'] = np.array([label_to_idx[label] for label in datasets['RoBERTa']['y_train']])\n",
    "    datasets['RoBERTa']['y_val'] = np.array([label_to_idx[label] for label in datasets['RoBERTa']['y_val']])\n",
    "    datasets['RoBERTa']['y_test'] = np.array([label_to_idx[label] for label in datasets['RoBERTa']['y_test']])\n",
    "\n",
    "# Provar diferents valors de k per a cada dataset\n",
    "k_values = [1,3,5, 7,9,12, 15]\n",
    "all_knn_results = {}\n",
    "\n",
    "for dataset_name, data in datasets.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"DATASET: {dataset_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    knn_results = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        print(f\"\\nEntrenant KNN amb k={k} per {dataset_name}...\")\n",
    "        \n",
    "        # Crear model KNN\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
    "        \n",
    "        # Entrenar amb dades corresponents\n",
    "        knn_model.fit(data['X_train'], data['y_train'])\n",
    "        \n",
    "        # Prediccions\n",
    "        y_pred_val = knn_model.predict(data['X_val'])\n",
    "        y_pred_test = knn_model.predict(data['X_test'])\n",
    "        \n",
    "        # Avaluació\n",
    "        val_accuracy = accuracy_score(data['y_val'], y_pred_val)\n",
    "        test_accuracy = accuracy_score(data['y_test'], y_pred_test)\n",
    "        \n",
    "        knn_results[k] = {\n",
    "            'model': knn_model,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'val_predictions': y_pred_val,\n",
    "            'test_predictions': y_pred_test\n",
    "        }\n",
    "        \n",
    "        print(f\"k={k} - Validació: {val_accuracy:.3f}, Test: {test_accuracy:.3f}\")\n",
    "    \n",
    "    all_knn_results[dataset_name] = knn_results\n",
    "\n",
    "# Trobar el millor model per cada dataset\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESUM DE RESULTATS KNN\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "best_models = {}\n",
    "for dataset_name, results in all_knn_results.items():\n",
    "    best_k = max(results.keys(), key=lambda k: results[k]['val_accuracy'])\n",
    "    best_models[dataset_name] = {\n",
    "        'k': best_k,\n",
    "        'val_accuracy': results[best_k]['val_accuracy'],\n",
    "        'test_accuracy': results[best_k]['test_accuracy']\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n🏆 Millor model per {dataset_name}: k={best_k}\")\n",
    "    print(f\"Accuracy de validació: {results[best_k]['val_accuracy']:.3f}\")\n",
    "    print(f\"Accuracy de test: {results[best_k]['test_accuracy']:.3f}\")\n",
    "\n",
    "# Comparació visual dels resultats\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, (dataset_name, results) in enumerate(all_knn_results.items()):\n",
    "    k_vals = list(results.keys())\n",
    "    val_accs = [results[k]['val_accuracy'] for k in k_vals]\n",
    "    test_accs = [results[k]['test_accuracy'] for k in k_vals]\n",
    "    \n",
    "    axes[idx].plot(k_vals, val_accs, 'o-', label='Validació', linewidth=2, markersize=8)\n",
    "    axes[idx].plot(k_vals, test_accs, 's-', label='Test', linewidth=2, markersize=8)\n",
    "    axes[idx].set_xlabel('Valor de k')\n",
    "    axes[idx].set_ylabel('Accuracy')\n",
    "    axes[idx].set_title(f'Rendiment KNN - {dataset_name}')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].set_xticks(k_vals)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Taula comparativa final\n",
    "comparison_data = []\n",
    "for dataset_name, best_info in best_models.items():\n",
    "    comparison_data.append({\n",
    "        'Dataset': dataset_name,\n",
    "        'Millor k': best_info['k'],\n",
    "        'Accuracy Validació': f\"{best_info['val_accuracy']:.3f}\",\n",
    "        'Accuracy Test': f\"{best_info['test_accuracy']:.3f}\"\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"COMPARACIÓ FINAL\")\n",
    "print(f\"{'='*40}\")\n",
    "display(df_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "070fef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant 5000 exemples amb RoBERTa embeddings (batch processing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 157/157 [20:53<00:00,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant 1000 exemples amb RoBERTa embeddings (batch processing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 32/32 [03:57<00:00,  7.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant 1000 exemples amb RoBERTa embeddings (batch processing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processant batches: 100%|██████████| 32/32 [03:54<00:00,  7.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (k=3) - Accuracy validació: 0.915, Accuracy test: 0.913\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFAAAAHqCAYAAAAj7rqIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACABUlEQVR4nOzdd3xN9x/H8fdNInuHiBEJEiH2KEVRq2bRqlUUtYoaLR3aGh1oqU212hrVaq1W1aiaLWlrFS1C7b2DiJB5fn/4uXUl3KRN3IzX8/HI4+Gec+45n3vPvcnH+3zPOSbDMAwBAAAAAADgvuxsXQAAAAAAAEBWR4ACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoADAv3TkyBGNHDlSBw4csHUpOZphGJo4caIWLFhg61IAAMBDRr+FrIQABcgCRo4cKZPJlOnb2bhxo0wmkzZu3Jjp28ps27ZtU40aNeTm5iaTyaRdu3Zl6PqtvVdxcXFq06aNDh48qBIlSmTotjNDcHCwunbtan6cns/C448/rscff/yh1XavDz/8UGPHjtWjjz6aaTUAAHI++q30o98CLBGgIFeZM2eOTCaTTCaTNm/enGK+YRgKDAyUyWRS8+bN/9U2Ro8eraVLl/7HSvEgCQkJatOmjaKiojRx4kTNmzdPQUFBD7WGQYMGycvLS7Nnz87QZmzChAkymUxau3btfZf59NNPZTKZtGzZsgzbblYVERGhMWPGaOXKlQ99HwMA/h36rZwhJ/dbjz/+uPkz+qCfkSNHZsj2PvroI82ZMydD1gXbcrB1AYAtODs7a/78+Xrssccspv/88886deqUnJyc/vW6R48erWeeeUatWrVK83Peeustvf766/96m7nN4cOHdfz4cX366afq0aNHpmyjdu3aunnzphwdHVPMu3TpkgoUKKD3338/1fn/Rfv27fXKK69o/vz5atCgQarLzJ8/X35+fmrSpMm/3s6DXt/DduDAAdnZpZ7nR0ZGaunSpapYseJDrgoA8F/Rb2VvObnfevPNNy1e07Zt2zRlyhS98cYbKlWqlHl6uXLlMmR7H330kfLmzfvAEbfIHghQkCs1bdpUixYt0pQpU+Tg8M/XYP78+apcubIuXbr0UOq4ceOG3Nzc5ODgYFEHHuzChQuSJG9v70zbhp2dnZydnVOdlzdvXg0fPjxTtluwYEHVrVtX3377rWbMmJGiuTx9+rR++eUX9erVS3ny5PnX23nQ63vYHtRAZ1bDBgDIfPRb2VtO7rcaNmxo8djZ2VlTpkxRw4YNM/W0ZWR/nMKDXKlDhw66fPmy1qxZY54WHx+vxYsX69lnn031OR9++KFq1KghPz8/ubi4qHLlylq8eLHFMiaTSTdu3NDcuXPNQ//uJM13zrvdt2+fnn32Wfn4+JiPyNx7Tu6xY8dkMplSHeqX1uGEp06dUqtWreTm5iZ/f3+99NJLiouLS3XZLVu2qHHjxvLy8pKrq6vq1KmjiIgIq9uQpFu3bmnkyJEqUaKEnJ2dVaBAAT399NM6fPiweZkbN25o8ODBCgwMlJOTk8LCwvThhx/KMIwUr+3FF1/U0qVLVaZMGTk5Oal06dL68ccfzct07dpVderUkSS1adNGJpPJ/Ifuftfq6Nq1q4KDgy2mffPNN6pcubI8PDzk6empsmXLavLkyeb59zsnd9GiRapcubJcXFyUN29ederUSadPn07Te5VWnTp10rVr17RixYoU87755hslJyerY8eOktL2uUzN/V7fzJkzVbx4cbm4uKhq1aratGlTiufGx8dr+PDhqly5sry8vOTm5qZatWppw4YNKZZNTk7W5MmTVbZsWTk7Oytfvnxq3Lixtm/fbl4mtWugHDlyRG3atJGvr69cXV316KOPpvp+AACyLvotS/RbWavfSotVq1apVq1acnNzk4eHh5o1a6a9e/daLHPu3Dl169ZNhQsXlpOTkwoUKKCWLVvq2LFjkm73OXv37tXPP/9s/rwS0mRfRLDIlYKDg1W9enV9/fXX5tMgVq1apWvXrql9+/aaMmVKiudMnjxZLVq0UMeOHRUfH69vvvlGbdq00fLly9WsWTNJ0rx589SjRw9VrVpVvXr1kiQVL17cYj1t2rRRaGioRo8eneIPWka5efOm6tevrxMnTmjAgAEqWLCg5s2bp/Xr16dYdv369WrSpIkqV66sESNGyM7OTrNnz1a9evW0adMmVa1a9b7bSUpKUvPmzbVu3Tq1b99eAwcO1PXr17VmzRrt2bNHxYsXl2EYatGihTZs2KDu3burQoUKWr16tV555RWdPn1aEydOtFjn5s2b9e2336pv377y8PDQlClT1Lp1a504cUJ+fn7q3bu3ChUqpNGjR2vAgAF65JFHlD9//nS9P2vWrFGHDh1Uv359ffDBB5JunyoSERGhgQMH3vd5c+bMUbdu3fTII49ozJgxOn/+vCZPnqyIiAjt3Lkzw47QPP300+rTp4/mz5+vp59+2mLe/PnzFRQUpJo1a0pK2+cyrT7//HP17t1bNWrU0KBBg3TkyBG1aNFCvr6+CgwMNC8XHR2tzz77TB06dFDPnj11/fp1ff7552rUqJG2bt2qChUqmJft3r275syZoyZNmqhHjx5KTEzUpk2b9Pvvv6tKlSqp1nH+/HnVqFFDsbGxGjBggPz8/DR37ly1aNFCixcv1lNPPZWu1wUAsA36rX/Qb2W9fsuaefPmqUuXLmrUqJE++OADxcbGasaMGXrssce0c+dOc1jUunVr7d27V/3791dwcLAuXLigNWvW6MSJEwoODtakSZPUv39/ubu7680335SkdL+XyEIMIBeZPXu2IcnYtm2bMW3aNMPDw8OIjY01DMMw2rRpY9StW9cwDMMICgoymjVrZvHcO8vdER8fb5QpU8aoV6+exXQ3NzejS5cuKbY9YsQIQ5LRoUOH+8674+jRo4YkY/bs2SmWlWSMGDHiga9z0qRJhiRj4cKF5mk3btwwQkJCDEnGhg0bDMMwjOTkZCM0NNRo1KiRkZycbPFaixYtajRs2PCB25k1a5YhyZgwYUKKeXfWt3TpUkOS8d5771nMf+aZZwyTyWQcOnTI4rU5OjpaTNu9e7chyZg6dap52oYNGwxJxqJFiyzWWadOHaNOnTopaunSpYsRFBRkfjxw4EDD09PTSExMvO9ru7ONO+9VfHy84e/vb5QpU8a4efOmebnly5cbkozhw4ffd13/Rps2bQxnZ2fj2rVr5mn79+83JBlDhw41T0vr5zIoKMjic3m/11ehQgUjLi7OvNzMmTMNSRbva2JiosUyhmEYV65cMfLnz288//zz5mnr1683JBkDBgxI8fru/rzdW9ugQYMMScamTZvM065fv24ULVrUCA4ONpKSklKsDwCQddBv0W8ZRvbot+5YtGiRRR3Xr183vL29jZ49e1osd+7cOcPLy8s8/cqVK4YkY9y4cQ9cf+nSpVN9z5D9cAoPcq22bdvq5s2bWr58ua5fv67ly5ffdzipJLm4uJj/feXKFV27dk21atXSH3/8ka7tvvDCC/+65rRauXKlChQooGeeecY8zdXV1XyU5o5du3bp4MGDevbZZ3X58mVdunRJly5d0o0bN1S/fn398ssvSk5Ovu92lixZorx586p///4p5t0ZIrty5UrZ29trwIABFvMHDx4swzC0atUqi+kNGjSwOIpUrlw5eXp66siRI2l/A6zw9vbWjRs3LIYUW7N9+3ZduHBBffv2tThXt1mzZipZsmSGn17SqVMn3bp1S99++6152vz58yXJfPqOlHGfyzuv74UXXrC4UFvXrl3l5eVlsay9vb15meTkZEVFRSkxMVFVqlSx2O6SJUtkMpk0YsSIFNt70JX0V65cqapVq1pcdNDd3V29evXSsWPHtG/fvnS9NgCA7dBv0W9l5X7rftasWaOrV6+qQ4cO5v116dIl2dvbq1q1aubTll1cXOTo6KiNGzfqypUrD6U22Ban8CDXypcvnxo0aKD58+crNjZWSUlJFn8A77V8+XK999572rVrl8W5rem9pVrRokX/dc1pdfz4cYWEhKSoLSwszOLxwYMHJUldunS577quXbsmHx+fVOcdPnxYYWFhD7wg2/Hjx1WwYEF5eHhYTL9zhfPjx49bTC9SpEiKdfj4+GToH6W+fftq4cKFatKkiQoVKqQnnnhCbdu2VePGje/7nDt13vseSlLJkiVTvU3jHUlJSbp48aLFNF9f3wdeUb5Jkyby9fXV/Pnzzed1f/311ypfvrxKly5tXi6jPpd3Xl9oaKjF9Dx58qhYsWIplp87d67Gjx+v/fv3KyEhwTz97s/34cOHVbBgQfn6+qa7lmrVqqWYfvdnpkyZMulaJwDANui36Leycr91P3f2Wb169VKd7+npKen2hfA/+OADDR48WPnz59ejjz6q5s2b67nnnlNAQEC6t4usjwAFudqzzz6rnj176ty5c2rSpMl9z6nctGmTWrRoodq1a+ujjz5SgQIFlCdPHs2ePds8KiCt7j6ycj/3axKSkpLStS1r7hztGDdunMV1K+7m7u6eodu0xt7ePtXpRhrOXzaZTKkud+/75u/vr127dmn16tVatWqVVq1apdmzZ+u5557T3Llz/13hD3Dy5MkUjdyGDRseeAGxPHnyqG3btvr00091/vx5nThxQgcPHtTYsWPNy2Tk5zI9vvzyS3Xt2lWtWrXSK6+8In9/f9nb22vMmDEWF7MDAECi36Lfyrr91v3c2Wfz5s1LNQi5O8waNGiQnnzySS1dulSrV6/WsGHDNGbMGK1fv14VK1ZM97aRtRGgIFd76qmn1Lt3b/3+++9asGDBfZdbsmSJnJ2dtXr1aotbrs6ePTvFsuk9QpKaO0cgrl69ajH93qMH9xMUFKQ9e/bIMAyLeg4cOGCx3J2hm56enmrQoEG66yxevLi2bNmihISE+95SNygoSGvXrtX169ctjors37/fPD+j+Pj4pDr0NLX3zdHRUU8++aSefPJJJScnq2/fvvrkk080bNgwhYSEpPo6pNvv4b1HIw4cOPDA1xEQEJBi+Gr58uWtvp6OHTvq448/1oIFC3T06FGZTCZ16NDBPD89n0tr7tR/8OBBi9eXkJCgo0ePWtS7ePFiFStWTN9++63F5+veU3WKFy+u1atXKyoqKl2jUIKCglJ8VqXM+cwAADIf/Rb9Vlbut1JzZ5/5+/unaZ8VL15cgwcP1uDBg3Xw4EFVqFBB48eP15dffikpYz6vyBq4BgpyNXd3d82YMUMjR47Uk08+ed/l7O3tZTKZLJL1Y8eOaenSpSmWdXNzS/GHOL08PT2VN29e/fLLLxbTP/roozQ9v2nTpjpz5ozFbf9iY2M1c+ZMi+UqV66s4sWL68MPP1RMTEyK9dw7DPJerVu31qVLlzRt2rQU8+4cmWjatKmSkpJSLDNx4kSZTCbzVfkzQvHixbV//36Lunfv3p3iFoGXL1+2eGxnZ6dy5cpJ0n1vPVilShX5+/vr448/tlhm1apVioyMfOAdb5ydndWgQQOLn/sN071bzZo1FRwcrC+//FILFixQnTp1VLhwYfP89HwuralSpYry5cunjz/+WPHx8ebpc+bMSfF5vnPU6u6jT1u2bNFvv/1msVzr1q1lGIbefvvtFNt70BGupk2bauvWrRbru3HjhmbOnKng4GCFh4en67UBAGyLfot+S8q6/VZqGjVqJE9PT40ePdriVOU77rz22NhY3bp1y2Je8eLF5eHhYVF/RnxekTUwAgW53oPOR72jWbNmmjBhgho3bqxnn31WFy5c0PTp0xUSEqI///zTYtnKlStr7dq1mjBhggoWLKiiRYumej0Ha3r06KH3339fPXr0UJUqVfTLL7/o77//TtNze/bsqWnTpum5557Tjh07VKBAAc2bN0+urq4Wy9nZ2emzzz5TkyZNVLp0aXXr1k2FChXS6dOntWHDBnl6euqHH36473aee+45ffHFF3r55Ze1detW1apVSzdu3NDatWvVt29ftWzZUk8++aTq1q2rN998U8eOHVP58uX1008/6fvvv9egQYNS3Hbwv3j++ec1YcIENWrUSN27d9eFCxf08ccfq3Tp0oqOjjYv16NHD0VFRalevXoqXLiwjh8/rqlTp6pChQrmc4XvlSdPHn3wwQfq1q2b6tSpow4dOphvqxccHKyXXnopw17HHSaTSc8++6xGjx4tSXrnnXcs5qfnc2lNnjx59N5776l3796qV6+e2rVrp6NHj2r27NkproHSvHlzffvtt3rqqafUrFkzHT16VB9//LHCw8MtGsO6deuqc+fOmjJlig4ePKjGjRsrOTlZmzZtUt26dfXiiy+mWsvrr79uvuXlgAED5Ovrq7lz5+ro0aNasmSJ7OzI/gEgu6Hfot/Kqv1Wajw9PTVjxgx17txZlSpVUvv27ZUvXz6dOHFCK1asUM2aNTVt2jT9/fffql+/vtq2bavw8HA5ODjou+++0/nz59W+fXvz+ipXrqwZM2bovffeU0hIiPz9/e97fRVkcTa59w9gI3ffVu9BUrut3ueff26EhoYaTk5ORsmSJY3Zs2enuB2eYdy+1Wzt2rUNFxcXQ5L5Fnt3lr148WKK7aW2ntjYWKN79+6Gl5eX4eHhYbRt29a4cOFCmm6rZxiGcfz4caNFixaGq6urkTdvXmPgwIHGjz/+aHGLtjt27txpPP3004afn5/h5ORkBAUFGW3btjXWrVtndTuxsbHGm2++aRQtWtTIkyePERAQYDzzzDPG4cOHzctcv37deOmll4yCBQsaefLkMUJDQ41x48ZZ3MrPMG7fVq9fv34ptnG/W/Dee1s9wzCML7/80ihWrJjh6OhoVKhQwVi9enWK2+otXrzYeOKJJwx/f3/D0dHRKFKkiNG7d2/j7NmzKbZx73u1YMECo2LFioaTk5Ph6+trdOzY0Th16pTV9+nf2rt3ryHJcHJyMq5cuZJiflo/l9ZuY3zHRx99ZBQtWtRwcnIyqlSpYvzyyy8pbleYnJxsjB492ggKCjKcnJyMihUrGsuXL0/xPhvG7Vsejxs3zihZsqTh6Oho5MuXz2jSpImxY8eO+9ZmGIZx+PBh45lnnjG8vb0NZ2dno2rVqsby5cvT89YBAGyEfot+yzCyV791722M766vUaNGhpeXl+Hs7GwUL17c6Nq1q7F9+3bDMAzj0qVLRr9+/YySJUsabm5uhpeXl1GtWjWLW1sbxu3bHzdr1szw8PAwJHFL42zMZBhpuFIQAAAAAABALsY4aAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACscLB1AUib5ORknTlzRh4eHjKZTLYuBwCQjRmGoevXr6tgwYKys+NYCrIneiMAQEZJa29EgJJNnDlzRoGBgbYuAwCQg5w8eVKFCxe2dRnAv0JvBADIaNZ6IwKUbMLDw0OS9PGP2+Xi5m7janBHo1IBti4BANLt+vVohRYtYv7bAmRHdz6/S37+S27ufJaziorBPrYuAcgWDMOwdQm4S1p7IwKUbOLO0FQXN3e50iRkGZ6enrYuAQD+NU57QHZ25/Pr5u4hN3f+HmcV9EZA2hCgZE3WeiNOfAYAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgIUAAAAAAAAKwhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgIUAAAAAAAAKwhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgIUAAAAAAAAKwhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgdbF5AVbNy4UXXr1tWVK1fk7e1t63Kypf0HTmjFqt917Pg5Xb0ao4H9W6tKpTBJUmJikhZ/+7N2/3lYFy5elaurk0qHB6vdM3Xl4+NhXsfZc5f1zYL1+vvQKSUmJqlIoL9aP1Vb4aWCbfSqcr6Jc37S8g27dfD4eTk75VHVskU1on9LhQblt3VpuRb7JOthnyA3ojf67/7cd0yLftisv4+eUdSV6xo5pINqPhJunm8YhuYuWq9V67Yr5sYtlQ4rogE9WqhwAb8U64pPSFT/Nz/RkePnNOODvgoJLvAwX0quNXHOT3pn+jK90P5xjRn8jK3LybU+X7xJs5Zs0smzUZKkksUC9Er3JmpYs7SNK8u93p+5UmM/W2UxLTTIX1sWDbNRRQ9PjhiBcu7cOfXv31/FihWTk5OTAgMD9eSTT2rdunX/an1z5syhWUinuLgEFQn0V5dOjVLMi49P0LHj59SqRU29N/J5DXyxtc6ei9LEKYsslpswaZGSkpM19NWOenfE8woM9Nf4SYt09VrMw3oZuU7EH4fUvU0trf58sL6d2k8JSUlq3X+6btyMs3VpuRb7JOthnyA7ojeyvVtx8SoWFKD+zzdPdf6CZZu0dNXvGtijhaaO6i1nZ0cNHT1X8fEJKZb99KvV8rvroBMy3x97j2vOdxEqHVrI1qXkegX9vTXixZba8MWrWj/3FdWqUkIdh8xU5OGzti4tVytZrIAiV44y/6z89CVbl/RQZPsRKMeOHVPNmjXl7e2tcePGqWzZskpISNDq1avVr18/7d+/36b1JSQkKE+ePDat4WEoX664ypcrnuo8V1dnvf7KsxbTunR8QiPenaNLl68pr5+Xrl+P1bnzUerxfFMVCfSXJLV7pq7Wrf9Dp05dlLeXe6a/htxo8ZS+Fo+nD++kEo3e0O7Ik6pRKcRGVeVu7JOsh32C7IbeKGuoWrGEqlYskeo8wzD03crf1PHpOqrxSClJ0mv9WqtNrw8UsS1SdWuWMy+7deff2rH7kEYM7qBtuw4+lNpzu5jYOPUaPkeT3+igD2f9aOtycr0mtctaPB7Wt4VmLdms7XuOqlRxRmPZioO9nfLn9bR1GQ9dth+B0rdvX5lMJm3dulWtW7dWiRIlVLp0ab388sv6/fffdezYMZlMJu3atcv8nKtXr8pkMmnjxo0p1rdx40Z169ZN165dk8lkkslk0siRIyVJJpNJS5cutVje29tbc+bMkSTzthYsWKA6derI2dlZX331lS5fvqwOHTqoUKFCcnV1VdmyZfX1119nzhuSTcTejJPJJLm5OkuS3N1dVCDAV5sj9uhWXLySkpK1fuNOeXq6qmhwgI2rzT2iY25Jkry9XG1cCe5gn2Q97BNkdfRGWd+5C1cUdTVGFcv+c/DJzdVZJUMKa9/Bk+ZpV67GaOLM7/Xai8/IyTHnh05ZxStjF+iJmmX0eLWSti4F90hKStaSn7Yr9ma8Hilb1Nbl5GpHTl5UeNM3VbHVSPUaNlenzkXZuqSHIluPQImKitKPP/6oUaNGyc3NLcV8b29vXb16NV3rrFGjhiZNmqThw4frwIEDkiR39/SNfnj99dc1fvx4VaxYUc7Ozrp165YqV66s1157TZ6enlqxYoU6d+6s4sWLq2rVqulad04Qn5CoBYs26NFqpeXi4iTpdgP2+ivPatLUxerV50OZTCZ5errplZfby83NxcYV5w7Jycl6Y8ISVStfTOHFC9q6HIh9khWxT5DV0RtlD1FXb5+e7HPPCFsfLzdd+f88wzA0bsa3at7gEYUVL6RzF6489DpzoyU/bdfu/Se1fu6rti4Fd9l76LQaPT9et+IT5ebipHnjeqpkMUaf2ErlMkGaNryTQoP8de5StMZ+tkpNe01SxNdvyMPN2dblZapsHaAcOnRIhmGoZMmMS4cdHR3l5eUlk8mkgIB/N/Jh0KBBevrppy2mDRkyxPzv/v37a/Xq1Vq4cOF9m4S4uDjFxf1zfn10dPS/qiWrSUxM0rSPvpNhGOr2XGPzdMMwNHfeanl4uOmtoZ3lmCePNv6ySxMmL9I7w7vJ25tTeDLbK2MXKfLIWa2cOcjWpeD/2CdZD/sEWR29Uc6x9MffFXszTu2fqm3rUnKNU+euaOj4Jfp22otydmLET1YSGpRfv3w1VNExN/X9up3qO3Keln8ykBDFRhrW+OcCvqVDC6lKmSCVazFCS9fuVOeW1W1YWebL1gGKYRi2LiFVVapUsXiclJSk0aNHa+HChTp9+rTi4+MVFxcnV9f7D/8eM2aM3n777cwu9aFKTEzStBnf6dLlaxr66rPm0SeStC/ymHbuPqRPpr9snt41uLH27D2qTRF/6slmNWxVdq7w6riFWr15j1Z8MlCF8vvYuhyIfZIVsU+QHdAbZQ++/z8wdOVajMXFYa9cu6Hi/z91edeeI4r8+6SadrR8zf2Gfqz6j5XTq/1aP7yCc4nd+0/oYtR1Pd75A/O0pKRk/brzsD5d9IvOR0ySvX22vwJCtuSYx0HFAvNJkiqUKqKd+07o4282atIbHWxcGSTJy8NVIUX8dfTURVuXkumydYASGhoqk8n0wIuh2dnd/iV3d0ORkJDy6uZpYTKZUjQmqa3r3iGz48aN0+TJkzVp0iSVLVtWbm5uGjRokOLj4++7raFDh+rll182P46OjlZgYOC/qjsruBOenDsfpTde7SgPd8sGKS4+UdLt9/huJruU7zkyjmEYeu3DRVqx8U8tmzFAQYXy2rqkXI99kvWwT5Cd0BtlDwH+PvL1dtfOv46Yb0l8I/aW9h86pScbPiJJ6tetmbq2a2B+zuUr1zV09Fy9NaitSoYUtkndOV3tR8IU8fUbFtNefOdLhQbn18DnGhKeZCHJhqH4////AbYXExuno6cvqW3eR2xdSqbL1gGKr6+vGjVqpOnTp2vAgAEp/jhfvXpV+fLdTirPnj2rihUrSpLFRdNS4+joqKSkpBTT8+XLp7Nn/7ld1sGDBxUbG2u1zoiICLVs2VKdOnWSdPsc+r///lvh4eH3fY6Tk5OcnJzuOz+ruXUrXufvOjf34sVrOn7ivNzcnOXt5a6p07/VsePn9PKgtko2DPOtid3dXOTgYK/Q4oXk5uasTz77Qa1aPCZHRwdt/HmXLl68qvLluMtFZnll7EItXr1DX33YU+6uzjp/6fZwaE93Z7k4O9q4utyJfZL1sE+QndAbZR03b8Xp9F0XVTx34aoOHTsrT3cX+ef11lNNq2v+dxtVqICvCvj7aM6CdfLz8VDN/9+Vxz+vt8X67vy+KZDfV/n8vB7a68hNPNycFR5ieX0rVxdH+Xq5pZiOh+ftad+rQY3SCgzw0fXYW1r843Zt3nFQS6b2tf5kZIphk79T41plFBjgq7OXrun9mStlb2en1k9UtnVpmS5bByiSNH36dNWsWVNVq1bVO++8o3LlyikxMVFr1qzRjBkzFBkZqUcffVTvv/++ihYtqgsXLuitt9564DqDg4MVExOjdevWqXz58nJ1dZWrq6vq1aunadOmqXr16kpKStJrr72WptvwhYaGavHixfr111/l4+OjCRMm6Pz58w9sErKbo8fOavQHX5kfz/9mrSTpsZpl9XSrWvrj/7fde2vE5xbPe+O1jipVMkgeHq565eX2Wrxko94fO1+JSUkqXCifXhrQRkFF8j+8F5LLzFqyWZL05AtTLKZPG95RzzZ/1BYl5Xrsk6yHfYLsht4oa/j78BkNeWeW+fHHX6ySJDWsU1Gv9n1a7VrU0q24BE2auUwxsbdUJqyIxgx9To7cbQewcOlKjPqM/ELnL0XL091ZpUMKacnUvqpbrZStS8u1zly4qp5vzVHUtVj5+bjr0fLF9NOsl5X3rlMSc6psH6AUK1ZMf/zxh0aNGqXBgwfr7NmzypcvnypXrqwZM2ZIkmbNmqXu3burcuXKCgsL09ixY/XEE0/cd501atTQCy+8oHbt2uny5csaMWKERo4cqfHjx6tbt26qVauWChYsqMmTJ2vHjh1Wa3zrrbd05MgRNWrUSK6ururVq5datWqla9euZdj7YGulSgZp3uw37jv/QfPuKFa0gF4dwnmMD1PU1qm2LgH3YJ9kPewTZDf0RllD+dJFtWbBu/edbzKZ1LVtfXVtWz9N6wvw93ng+pA5ln8yyNYl5HpTh3W0dQm4x+ejutm6BJsxGVxgIluIjo6Wl5eX5m7aL1f3nJ/sZRfNSnPlbwDZT3R0tALyeuvatWvy9PS0dTnAv3KnN/pxxzG5ufM5ziqqFOMi20Ba8N/wrCWtvRFXQgIAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgIUAAAAAAAAKwhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgIUAAAAAAAAKwhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgIUAAAAAAAAKwhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgIUAAAAAAAAKwhQAAAAAAAArHCwdQFInydKBsjT09PWZeD/pmw+YusScI8BjxWzdQlIRWKSYesScBf2B3KSCkHe9EZZyCe/HbV1CbhHr0eDbV0CUpGUzN/irCSt+4MRKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGAFAQoAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGAFAQoAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGAFAQoAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGAFAQoAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQ62LiAnOnbsmIoWLaqdO3eqQoUKti4nS5o09ye9+9EP6t3ucY1+ubWty8mRjh0+pV83bNeZUxcUE31D7bo9qVJlQyyWuXj+stYs36zjh08pOTlZ+fL7qW3X5vL28bRYzjAMffXpUh3afyzV9SDjTJzzk5Zv2K2Dx8/L2SmPqpYtqhH9Wyo0KL+tS8vVYm7c0vszV2jlL3/qUlSMypQopFEvtVbF8CBblwZkC/RG93fmwlW9Pe17rf11n27GJaho4byaNqyTKoYXsXVpOc6RQ6f0y7ptOn3yvK5H31DnHi1UulyoxTIXzl3WqmW/6Mih271R/gA/dXq+hbx9b/dGCQmJWvHdRv35xwElJiYptFSwWrWpLw9PN1u8pFyD74lt/brzkKZ/uU67D5zU+UvRmvtBDzWtU06SlJCYpDEfL9fa3/bp+OnL8nB3Vp1HwjSsbwsF5POyceUZz6YjULp27SqTyZTip3HjxrYs6z8LDAzU2bNnVaZMGVuXkiX9se+45n4XodIhBW1dSo6WEJ+g/AXzqdnT9VKdH3XpqmZNXai8/j7q2reN+gzprNoNq8nBIWWu+vsvOzO7XPxfxB+H1L1NLa3+fLC+ndpPCUlJat1/um7cjLN1abnaS2O+1s/bDmj68M7a+OXrerxaST0zYLrOXrhq69KQw9Ab5S5Xo2PVpOdEOTjYa+HkPvrtmzf07sCn5O3pYuvScqSE+AQVKJRPLdvUT3X+5YtX9fGkb5Qvv6969W+rQa91Ub1Gj8ohzz+90fJvNypy7xE9+/yT6jWgna5fi9GXny97WC8hV+J7YnuxN+NVOrSQPhjSJsW8m7fi9eeBU3q5WyOtm/uK5rzfXYeOX1CnV2baoNLMZ/MRKI0bN9bs2bMtpjk5Odmomoxhb2+vgIAAW5eRJcXExumF4XM18Y0OmjB7ta3LydFCSxVVaKmi952/bmWEQksF64kna5un+eb1TrHc2dMX9OvGHer10rMaPzJn/iLMShZP6WvxePrwTirR6A3tjjypGpUY+WMLN2/Fa/nG3frig56qXvH2Pni1R1P9tHmP5ny3WUN7N7dxhchp6I1yj8lfrFEhf29NH97JPC2oUF4bVpSzhYUXVVj4/Xuj1Ss2Kyy8qJq2rGOe5pfP2/zvWzfjtP33v9T+uWYKKXF75MMzHRtpwqg5OnH0jIoU5eBgZuB7YnsNaoSrQY3wVOd5urto8dR+FtPeH/KMnnh+vE6di1LhAN+HUeJDY/NroDg5OSkgIMDix8fHR5J09epV9e7dW/nz55ezs7PKlCmj5cuXm5+7ZMkSlS5dWk5OTgoODtb48eMt1h0cHKzRo0fr+eefl4eHh4oUKaKZMy3/A/jXX3+pXr16cnFxkZ+fn3r16qWYmBjz/K5du6pVq1YaPXq08ufPL29vb73zzjtKTEzUK6+8Il9fXxUuXNii0Tl27JhMJpN27dolSUpKSlL37t1VtGhRubi4KCwsTJMnT87otzJbeHXcQjWsWVqPVy1p61JyteRkQwcjj8ovn4/mffKtxg7/WJ9O+lqRfx2yWC4+PkFLvlylZq3rMTTVRqJjbkmSvL1cbVxJ7pWUlKykpGQ5OVoec3B2ctSW3UdsVBVyMnqj3GPVpj2qUKqIur7+uUo0Gqo6nT7Q3KURti4rV0pONrR/7xHl9ffR5x8t1rtvfKTp47/S3j8Pmpc5dfK8kpKSFRL2z2kj/vn95O3joePHztqi7FyB70n2Ex1zSyaTSV4eOW+UkM0DlPtJTk5WkyZNFBERoS+//FL79u3T+++/L3t7e0nSjh071LZtW7Vv315//fWXRo4cqWHDhmnOnDkW6xk/fryqVKminTt3qm/fvurTp48OHDggSbpx44YaNWokHx8fbdu2TYsWLdLatWv14osvWqxj/fr1OnPmjH755RdNmDBBI0aMUPPmzeXj46MtW7bohRdeUO/evXXq1Kn7vpbChQtr0aJF2rdvn4YPH6433nhDCxcuzPg3Lgv79qcd+vPASQ3r28LWpeR6N2JiFR+XoM3rtymkZLA6935aJcsW14I5P+jYoX8+x6uX/qzA4IIqWaa4DavNvZKTk/XGhCWqVr6YwotzVMtW3N2cVaVMsCbMXq1zF68pKSlZi37cpu17jur85Whbl4dchN4o5zl++pJmf7tZxYvk0+IpfdWt9WMaOn6Jvl6+xdal5Tp3eqONa7eqRKmi6t73GZUuF6IvP1+mIwdPSpJiom/I3t5eLq7OFs9193BTTPQNW5SdK/A9yV5uxSXonenf6+mGleThlvMCFJufwrN8+XK5u7tbTHvjjTdUpUoVbd26VZGRkSpRooQkqVixYuZlJkyYoPr162vYsGGSpBIlSmjfvn0aN26cunbtal6uadOm6tv39pD41157TRMnTtSGDRsUFham+fPn69atW/riiy/k5nb76Pq0adP05JNP6oMPPlD+/Lcv2ujr66spU6bIzs5OYWFhGjt2rGJjY/XGG29IkoYOHar3339fmzdvVvv27VO8xjx58ujtt982Py5atKh+++03LVy4UG3btk31fYmLi1Nc3D/XPIiOzt5N+unzV/TGhCVaMrWfnJ3y2LqcXM8wDElSWOniql6nkiSpQCF/nTx2Vtt/+1PBIYW1f89hHT10Ur0Hd7RlqbnaK2MXKfLIWa2cOcjWpeR600d01qBR81WuxTDZ29upXInCeqphZf25/6StS0MORG+UO3oj6faohwqlipgPLpULC9T+w2c1+9vN6tC8mo2ry13u9EbhZUNUq25lSVLBwv46fvSMtkTsVrHQQFuWl6vxPck+EhKT1OPN2TIMadxrqf8uz+5sHqDUrVtXM2bMsJjm6+urzz77TIULFzY3CPeKjIxUy5YtLabVrFlTkyZNUlJSkvloTLly5czzTSaTAgICdOHCBfM6ypcvb24Q7qwjOTlZBw4cMDcJpUuXlp3dP4N18ufPb3ERNHt7e/n5+ZnXm5rp06dr1qxZOnHihG7evKn4+PgHXoV+zJgxFo1Fdrdr/wldvHJddbuMNU9LSkrWrzsP67PFv+jspomyt8+yA6JyHFc3F9nZ2SlfgJ/F9Hz+vjpx9LQk6ejBk4q6fFXvv/mRxTIL5yxXkWKF1K1fyotIIeO8Om6hVm/eoxWfDFSh/D62LifXK1o4n76fMVA3bsYp5sYt5c/rpZ5vzVZQIT/rTwbSid4odTmtN5Kk/Hk9FVbU8towJYLz64cNu2xTUC52pzfyv6c38s/vp2NHbvdG7p5uSkpK0s3YWxajUGKu35A7pzpnGr4n2cOd8OTUuSh9O71/jhx9ImWBAMXNzU0hISkvjOjikjFveJ48lqMdTCaTkpOT//M60rPeb775RkOGDNH48eNVvXp1eXh4aNy4cdqy5f7DzoYOHaqXX37Z/Dg6OlqBgdk3+a5dJUyb5w+1mPbiu18pNCi/Bj7XgPDkIXNwsFfBIvl1+UKUxfTLF6/I6/+3MH6s/iOq9Kjl3RJmjJunRi3rKKx0MSFzGIah1z5cpBUb/9SyGQO4SFoW4+biJDcXJ12NjtWGLfs1vB+nJCLj0RulLqf1RpJUrVwxHTp+3mLaoRMXctxFF7MDBwd7FS6SX5fOW/ZGFy9eMd/CuHBgftnb2+nQ3ydUtsLtIPPi+ShdvXJdQcEFHnrNuQXfk6zvTnhy5ORFfTf9Rfl65dxA0eYByv2UK1dOp06d0t9//53qkZZSpUopIsLy4kEREREqUaKE+QiLNaVKldKcOXN048YN85GWiIgI83DUjBIREaEaNWqYh8tK0uHDhx/4HCcnp2x/xf27ebg5q9Q913Bwc3GUr5dbiunIGHFx8Yq6dNX8+GpUtM6eviAXV2d5+3iq5uNVtGjeCgUVK6zgkEAd2n9MB/YdUde+t0eWeHi6pXrhWC8fD/n45bx7umcVr4xdqMWrd+irD3vK3dVZ5y/dHqLu6e4sF2dHG1eXe63/PVIyDBUPyq+jpy7q7WnfKzTIXx2aP2rr0pCL0BvlrN5Ikvo8W1eNu0/QhNmr1apBJf2x97i+WPqrJr6R8rQn/HdxcfG6fPGq+XHU5WidOXVBrq7O8vb1VO36j+jrOctVNKSwioUG6u/IY9q/57B69b99KoKzi5OqPFpWK77bKFdXZzk5O2nZ4nUqElyAO/BkIr4nthcTG6ejpy6aH584c1l//X1KPp6uyp/XS88P/Vx/Hjilr8b3VlKyYb5GnI+nqxzzZNnI4V+x+auJi4vTuXPnLKY5ODioTp06ql27tlq3bq0JEyYoJCRE+/fvl8lkUuPGjTV48GA98sgjevfdd9WuXTv99ttvmjZtmj766KP7bCmljh07asSIEerSpYtGjhypixcvqn///urcubN5iGpGCA0N1RdffKHVq1eraNGimjdvnrZt26aiRe9/GzXgvzpz8rzmfrTY/Hj19z9Lkso/Eq6nOjRSqXIhav5MfW1et02rvtsgP39ftev6pIKKFbJVyZA0a8lmSdKTL0yxmD5teEc9y3/WbeZ6zE299/EPOnvhqrw93dT88fJ644XmyuOQtv+UAulBb5R7VAoP0ryxPfXOR8s07vMfVaSgn0a9/LTaNH7E1qXlSKdOnNenU/+5UPGK7zZKkipVLa22nRqrTPlQtWrbQBvXbtWyJRuUz99HHZ9voeDihc3Paf704zKZpC9n/aDExESVKBmsVm0bPOyXkqvwPbG93ZEn1KrfVPPjYZO/kyS1a1pVr/Zooh837ZEk1e38gcXzlk7vr5qVQx9eoQ+BzQOUH3/8UQUKWA55CwsL0/79+7VkyRINGTJEHTp00I0bNxQSEqL3339fklSpUiUtXLhQw4cP17vvvqsCBQronXfesbhImjWurq5avXq1Bg4cqEceeUSurq7mpiQj9e7dWzt37lS7du1kMpnUoUMH9e3bV6tWrcrQ7WQ3y2YMtHUJOVrRkECNnPDSA5epVK2MKlUr88Bl7mZtffjvorZOtb4QHrqWDSqpZYNKti4DuQS9Ue7SqFYZNaqV9r/F+PeKhwbq/SmDH7jMI9XL6pHqZe87P08eB7Vq24DQ5CHje2JbNSuH6uLvU+47/0HzchqTceeS08jSoqOj5eXlpbMXr8rT09PW5eD/pkYcsXUJuMeAx7g+S1aUmMSfmqwkOjpahfP76Nq1a/xNQbZ1pzc6d4neKCuZ+fsxW5eAe/R6NNjWJSAVScn0RllJdHS0Cvlb7424cicAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGCFQ1oWWrZsWZpX2KJFi39dDAAAQHZAbwQAQO6TpgClVatWaVqZyWRSUlLSf6kHAAAgy6M3AgAg90lTgJKcnJzZdQAAAGQb9EYAAOQ+/+kaKLdu3cqoOgAAALI9eiMAAHKudAcoSUlJevfdd1WoUCG5u7vryJEjkqRhw4bp888/z/ACAQAAsjJ6IwAAcod0ByijRo3SnDlzNHbsWDk6OpqnlylTRp999lmGFgcAAJDV0RsBAJA7pDtA+eKLLzRz5kx17NhR9vb25unly5fX/v37M7Q4AACArI7eCACA3CHdAcrp06cVEhKSYnpycrISEhIypCgAAIDsgt4IAIDcId0BSnh4uDZt2pRi+uLFi1WxYsUMKQoAACC7oDcCACB3SNNtjO82fPhwdenSRadPn1ZycrK+/fZbHThwQF988YWWL1+eGTUCAABkWfRGAADkDukegdKyZUv98MMPWrt2rdzc3DR8+HBFRkbqhx9+UMOGDTOjRgAAgCyL3ggAgNwh3SNQJKlWrVpas2ZNRtcCAACQLdEbAQCQ8/2rAEWStm/frsjISEm3z/2tXLlyhhUFAACQ3dAbAQCQs6U7QDl16pQ6dOigiIgIeXt7S5KuXr2qGjVq6JtvvlHhwoUzukYAAIAsi94IAIDcId3XQOnRo4cSEhIUGRmpqKgoRUVFKTIyUsnJyerRo0dm1AgAAJBl0RsBAJA7pHsEys8//6xff/1VYWFh5mlhYWGaOnWqatWqlaHFAQAAZHX0RgAA5A7pHoESGBiohISEFNOTkpJUsGDBDCkKAAAgu6A3AgAgd0h3gDJu3Dj1799f27dvN0/bvn27Bg4cqA8//DBDiwMAAMjq6I0AAMgd0nQKj4+Pj0wmk/nxjRs3VK1aNTk43H56YmKiHBwc9Pzzz6tVq1aZUigAAEBWQW8EAEDuk6YAZdKkSZlcBgAAQPZBbwQAQO6TpgClS5cumV0HAABAtkFvBABA7pPuu/Dc7datW4qPj7eY5unp+Z8KAgAAyK7ojQAAyLnSfRHZGzdu6MUXX5S/v7/c3Nzk4+Nj8QMAAJCb0BsBAJA7pDtAefXVV7V+/XrNmDFDTk5O+uyzz/T222+rYMGC+uKLLzKjRgAAgCyL3ggAgNwh3afw/PDDD/riiy/0+OOPq1u3bqpVq5ZCQkIUFBSkr776Sh07dsyMOgEAALIkeiMAAHKHdI9AiYqKUrFixSTdPqc3KipKkvTYY4/pl19+ydjqAAAAsjh6IwAAcod0ByjFihXT0aNHJUklS5bUwoULJd0++uLt7Z2hxQEAAGR19EYAAOQO6Q5QunXrpt27d0uSXn/9dU2fPl3Ozs566aWX9Morr2R4gQAAAFkZvREAALlDuq+B8tJLL5n/3aBBA+3fv187duxQSEiIypUrl6HFAQAAZHX0RgAA5A7pDlDuFRQUpKCgoIyoBQAAINujNwIAIGdKU4AyZcqUNK9wwIAB/7oYAACA7IDeCACA3CdNAcrEiRPTtDKTyUSTAAAAcjx6IwAAcp80BSh3riwP27OzM8nOzmTrMvB//WoUtXUJuEezGb/ZugSkYkmParYuAXdJTDZsXUK2R2+UdZhMJplM9EZZRa9Hg21dAu5Rdzy3U8+Kfhz4mK1LwF3S2hul+y48AAAAAAAAuQ0BCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGDFvwpQNm3apE6dOql69eo6ffq0JGnevHnavHlzhhYHAACQHdAbAQCQ86U7QFmyZIkaNWokFxcX7dy5U3FxcZKka9euafTo0RleIAAAQFZGbwQAQO6Q7gDlvffe08cff6xPP/1UefLkMU+vWbOm/vjjjwwtDgAAIKujNwIAIHdId4By4MAB1a5dO8V0Ly8vXb16NSNqAgAAyDbojQAAyB3SHaAEBATo0KFDKaZv3rxZxYoVy5CiAAAAsgt6IwAAcod0Byg9e/bUwIEDtWXLFplMJp05c0ZfffWVhgwZoj59+mRGjQAAAFkWvREAALmDQ3qf8Prrrys5OVn169dXbGysateuLScnJw0ZMkT9+/fPjBoBAACyLHojAAByh3QHKCaTSW+++aZeeeUVHTp0SDExMQoPD5e7u3tm1AcAAJCl0RsBAJA7pDtAucPR0VHh4eEZWQsAAEC2RW8EAEDOlu4ApW7dujKZTPedv379+v9UEAAAQHZCbwQAQO6Q7gClQoUKFo8TEhK0a9cu7dmzR126dMmougAAALIFeiMAAHKHdAcoEydOTHX6yJEjFRMT858LAgAAyE7ojQAAyB3SfRvj++nUqZNmzZqVUasDAADI1uiNAADIWTIsQPntt9/k7OycUasDAADI1uiNAADIWdJ9Cs/TTz9t8dgwDJ09e1bbt2/XsGHDMqwwAACA7IDeCACA3CHdAYqXl5fFYzs7O4WFhemdd97RE088kWGFAQAAZAf0RgAA5A7pClCSkpLUrVs3lS1bVj4+PplVEwAAQLZAbwQAQO6Rrmug2Nvb64knntDVq1czqRwAAIDsg94IAIDcI90XkS1TpoyOHDmSGbUAAABkO/RGAADkDukOUN577z0NGTJEy5cv19mzZxUdHW3xAwAAkJvQGwEAkDuk+Roo77zzjgYPHqymTZtKklq0aCGTyWSebxiGTCaTkpKSMr5KAACALIbeCACA3CXNAcrbb7+tF154QRs2bMjMegAAALIFeiMAAHKXNAcohmFIkurUqZNpxQAAAGQX9EYAAOQu6boGyt3DUgEAAHI7eiMAAHKPNI9AkaQSJUpYbRSioqL+U0EAAADZBb0RAAC5R7oClLffflteXl6ZVQsAAEC2Qm8EAEDuka4ApX379vL398+sWgAAALIVeiMAAHKPNF8DhXN8AQAA/kFvBABA7pLmAOXOleYBAABAbwQAQG6T5lN4kpOTM7MOAACAbIXeCACA3CVdtzEGAAAAAADIjQhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArHGxdQFYUGxurCRMmqGPHjipatKity8lRPl34s6Z+uU4XLkerTGghffBKG1UuHWzrsnKtpKRkjf1slRb/uE0Xoq4rIK+n2jerppe7NZLJZLJ1eTlO20qFVKOYnwp7uyg+MVmR56I16/fjOn31VqrLv9OslKoE+ejdVfv129Eo8/R87o7qV6e4yhX01K2EZK09cEFzfj+uZONhvZKc7fddh/TR/PX6a/9Jnb8crc/HdFeT2uXM8wvWHJjq897q20J9O9Z/WGUCDxW9Ueb4fPEmzVqySSfP3v4dX7JYgF7p3kQNa5a2cWW51/szV2rsZ6sspoUG+WvLomE2qihne7ZqoGqXyKsivq6KS0zW3tPR+uSXIzp55abFcuEFPNWjVrBKFfBUcrKhQxdi9MqSvxSfmCxJ8nB20IB6IapR3E+GIf188KKmrT+kmwnJtnhZOc5vOw9pxvz1+vPASZ2/FK1ZY7qrSZ1/eqMbsXEaNeMH/fjLn7pyLVaBBX3VvU1tdXnqMRtWnTlyfYAyZ84cDRo0SFevXjVP69mzp7y8vO7bIBw7dkxFixbVzp07VaFChYdTaA7w7U879Nak7zTh9XaqXCZYH3+9Qa37T9e2xcOVz9fD1uXlSlPmrdWcbzdr6vBOKlk0QLv2n9CA9+bLw81FvdrVsXV5OU6Zgp5a/tdZ/X0hRvZ2JnV5NEijniyt3l/vVFyi5R/4VuUKKLU8xM4kvd2slK7EJmjIt3/J181Rg+uHKinZ0NwtJx7OC8nhYm/Gq3RIIXVoVk3d35iVYv6uZe9aPF7/+z4NHvONmj1e/mGVCGQqeqOHp6C/t0a82FLFA/PJMAx9vWKLOg6ZqZ+/fF2lihewdXm5VsliBfTdtBfNjx0cGLSfWSoEemvpzjPaf+667O1M6lGrqMa1Kaeus7fp1v/Dj/ACnhr7TFnN33JCU9YdUlKyoeL+7jKMfzqlt5qVkp+bo4Ys+lMO9ia91jhMg58oofdW7LfVS8tRYm/FKzykkNo3r6buQ1P2RiOmfKeIHQc1bURnBRbw1cYtBzR0/CIF5PVSo1plbVBx5skRvw26du0qk8kkk8kkR0dHhYSE6J133lFiYmK61zV58mTFxsZq2rRp5nW3atXKYpnAwECdPXtWZcqUyYjyc42P5q/Xc61qqGOL6ipZrIAmDG0vV2dHfbnsN1uXlmtt++uoGtcuqydqllaRgn5qUa+iHq9aUjv3Hbd1aTnS8OWRWnvgok5cuamjl2M1Yd1B+Xs4KTSfu8Vyxfxc9XSFgpq0/lCKdVQK9Fagj6vGrT2oI5djtf3EVc3bekLNywTIwY5RQxmhXvVwvdarmZrUST0Q8ffztPhZvWmPalYKUVChvA+5UuD+6I2yhyb//xtcvIi/QoLya1jfFnJzddL2PUdtXVqu5mBvp/x5Pc0/ft7u1p+Ef+XVJX/px73ndexyrA5fvKH3Vx1QgKezSuT/5+Dqi3WL69s/Tmv+1pM6djlWJ6/c1MYDF5WQdDtAKeLrqmpFfTVu9QFFnruuv05Ha8q6Q6pX0l9+bo62emk5Sv3q4Xq9dzM1vU9vtP2vo2rTtKpqVApVYAE/dW5VQ+EhBbVzX847uJcjAhRJaty4sc6ePauDBw9q8ODBGjlypMaNG5fu9QwcOFDfffed7Ozu/9bY29srICBADg65fgBPmsUnJGrX/pN6vGqYeZqdnZ3qVA3Ttr9oEmzlkbJFtWnb3zp84oIkac/B09q6+4jqVy9l48pyBzfH279Drsf98x8aJwc7vdqwhD765Yiu3ExI8ZyS+T10LCpWV++at+PEVbk5OaiIr2vmFw0LF6Oite7XvWrf/FFblwKkQG+UvSQlJWvJT9sVezNej5TlNClbOnLyosKbvqmKrUaq17C5OnUuyvqTkCHcnewlSddv3e5zvF3zKLygp67Exmtahwr6tk91TWpXXmULeZqfU7qgp67fStCB8zHmaTuOX5FhSKUKMMr9YahStqh+2vSXzl68KsMwFLHjoI6cvKg6d/3fL6fIMQGKk5OTAgICFBQUpD59+qhBgwZatmyZrly5oueee04+Pj5ydXVVkyZNdPDgwfuuZ+TIkeahpyNHjtTcuXP1/fffm4/ibNy4UceOHZPJZNKuXbvMz9u7d6+aN28uT09PeXh4qFatWjp8+LAkadu2bWrYsKHy5s0rLy8v1alTR3/88Udmvh1ZzuWrMUpKSk5xqk4+X09duBxto6ow8LkGatWwkqq3G6UCNQep3nNj1at9HT3T+BFbl5bjmST1fixYe89G63hUrHl6z5rBijx3Xb8fu5Lq83xc8+hqbLzFtDthiq9rnkyrF6lbuGqb3F2d73tEBrAleqPsYe+h0ypc+2XlrzlIL49ZoHnjeqpkMU7fsZXKZYI0bXgnLZrcVx++1k7Hz1xW016TdP1G6tcrQ8YxSXqxboj+OnVNRy/d7o0KejlLkrrWCNbyv87q1SV/6eD5GI1vU16FvF0kSb5ujroSa3nQKcmQom8lyJcRKA/FqJefUYmiAarUcoSK1H5Zz748Q6MHP6PqFUNsXVqGy7GHCVxcXHT58mV17dpVBw8e1LJly+Tp6anXXntNTZs21b59+5Qnz4P/szFkyBBFRkYqOjpas2fPliT5+vrqzJkzFsudPn1atWvX1uOPP67169fL09NTERER5mGy169fV5cuXTR16lQZhqHx48eradOmOnjwoDw8Uk9F4+LiFBcXZ34cHU3IgIz3/bqdWrJ6uz555zmFFS2gPQdP6a2J3yogr5faN6tm6/JytL61iynI11VDvttjnlYt2EflC3mp/8LdNqwM6fHN8t/11BOV5exEeIWsj94oawoNyq9fvhqq6Jib+n7dTvUdOU/LPxlIiGIjDWv8cwHf0qGFVKVMkMq1GKGla3eqc8vqNqws5xvUIFRF87qp/9c7zdPu3NTgh91n9eOe85KkQxdiVCnIW03LBujTTYxkzwpmLf5Ff+w9rrlje6pwgI9+33VYb4xfrIC8Xqr9SM4ahZLjAhTDMLRu3TqtXr1aTZo00dKlSxUREaEaNWpIkr766isFBgZq6dKlatOmzQPX5e7uLhcXF8XFxSkgIOC+y02fPl1eXl765ptvzI1HiRIlzPPr1atnsfzMmTPl7e2tn3/+Wc2bN091nWPGjNHbb7+dptecHfh5u8ve3k4Xo65bTL8YFS1/P8/7PAuZbeTU7zXguQZ6qmFlSVJ4SEGdPHtFk79YQ4CSifrUKqqqwT569bs9unzjn9Ek5Qt5qYCXsxb1sHzv32gUpr1no/X693t1JTbB4rxgSfJ2uf17Jyo25Sk/yDxbdh3W4RMX9PE7XW1dCvBA9EZZm2MeBxULzCdJqlCqiHbuO6GPv9moSW90sHFlkCQvD1eFFPHX0VMXbV1KjjawfoiqF/PVgAW7dTHmn97oTp90/PINi+WPX46Vv4eTJCnqRrx87hmFa2+SPJ3zKOqG5ahdZLybcfEa8/FyzRrTXQ3+fwex8JBC2nvwtGbMX5/jApQccwrP8uXL5e7uLmdnZzVp0kTt2rVT165d5eDgoGrV/vnPiJ+fn8LCwhQZGZlh2961a5dq1ap136M258+fV8+ePRUaGiovLy95enoqJiZGJ07c/6I6Q4cO1bVr18w/J0+ezLB6bcExj4MqlAzUz9sOmKclJyfrl21/c56vDd28FS+7e25XbG9vUjL3w800fWoVVfWivhr6/V6dvx5nMW/RH6fVb8Fuvbjwnx9J+jTiqCb+/4Ky+89fV7Cvq7xc/vl9UzHQWzfiEnXirlOBkPm+Xv67yoUFqnRoIVuXAqSK3ih7SjYMxcen/2K/yBwxsXE6evqS8uflgF9mGVg/RI+F5NVLC//UuWuWp0qdu3ZLF6/HKfCe67wF+rjofPTtPmrvmWh5OOdRifz/XOy3YhEfmUxS5FnLg7fIeImJyUpITJLpnpsZ2NnZ5cj/U+SYESh169bVjBkz5OjoqIIFC8rBwUHLli17KNt2cXF54PwuXbro8uXLmjx5soKCguTk5KTq1asrPv7+iaiTk5OcnJwyulSb6vtsPfV9e54qliqiSqWDNePrDbpxM04dn+Tii7byxGNlNHHOTyoU4KuSRQP019+n9PHXG/QsF8TMFH1rF9PjoXn1zqr9uhmfJJ//hyA34pMUn5SsKzcTUr1w7MWYeHPY8sfJqzp5JVZD6odo1m/H5ePqqOeqFtHyPeeUmAP/SNnCjdg4iyONJ89c1p6/T8nb01WFA3wlSddv3NIPG3ZpxIstbVUmYBW9Udb39rTv1aBGaQUG+Oh67C0t/nG7Nu84qCVT+9q6tFxr2OTv1LhWGQUG+OrspWt6f+ZK2dvZqfUTlW1dWo40qEGIGpTMrzeX7tHN+ETz9dxi4pMUn3j7NsYLtp1U15rBOnwxRocuxKhR6QAV8XXViGX7JEknomK15WiUhjxRQhPWHJSDnUkD64do/f4LFiN98e/d2xudOGvZG1WvGKJ3p30vF6c8Khzgq992HtLiVds0ckAr2xWdSXJMgOLm5qaQEMuL1JQqVUqJiYnasmWLeZjq5cuXdeDAAYWHh6dpvY6OjkpKSnrgMuXKldPcuXOVkJCQ6pGWiIgIffTRR2ratKkk6eTJk7p06VKatp+TPP1EZV26GqPRn6zQhcvXVbZEIS2e0o9TeGzo/cHPaMzMFXpt3EJduhKjgLyeeq5VTQ3p3tjWpeVIzcvcHu4+tpXlbT4nrDuotQfSNjQ42ZBGrtivfnWKafzTZRWXmKy1By5o3tacd5s4W9m9/4Se6T/N/Hjk1KWSpLZNqmrSWx0lSd+v/UOGYahVQxpqZF30RlnfpSsx6jPyC52/FC1Pd2eVDimkJVP7qm417oZnK2cuXFXPt+Yo6lqs/Hzc9Wj5Yvpp1svK68PdXDJDqwq3R3FObl/BYvr7q/brx723r3my+I/TcnSwU7/Hi8vDJY8OX4jRkMV/6sxdo1XeWxGpgfVDNKFtOSUb0i9/X9TU/4/exX+3e/8JtX7xrt5oylJJUtumVTX5rY76+J0uGj3jB/UbOU9Xo2NVKMBHr/VupueeqmmjijNPjglQUhMaGqqWLVuqZ8+e+uSTT+Th4aHXX39dhQoVUsuWaTtqGBwcrNWrV+vAgQPy8/OTl5dXimVefPFFTZ06Ve3bt9fQoUPl5eWl33//XVWrVlVYWJhCQ0M1b948ValSRdHR0XrllVesHpnJqXq1raNebevYugz8n7ubs0a91FqjXmpt61JyhaYf/Zohz7kQE6cRKzJuqD0s1agUqjMRkx+4TKeWNdSpZY2HVBGQceiNspapwzraugTc4/NR3WxdQq7y+Ic/p2m5+VtPav7W+5+2d/1Wot5bsT+jysI9alQK1dlf798b+ft5mg8y5XQ55hoo9zN79mxVrlxZzZs3V/Xq1WUYhlauXGn1KvN39OzZU2FhYapSpYry5cuniIiIFMv4+flp/fr1iomJUZ06dVS5cmV9+umn5m18/vnnunLliipVqqTOnTtrwIAB8vf3z9DXCQAAkBb0RgAA/DsmwzA4aT4biI6OlpeXl85fviZPT055ySoSk5JtXQLu0eKT321dAlKxpAd3dcpKoqOjFVzAV9eu8TcF2Re9UdbEfy2ynrrjf7F1CUjFjwMfs3UJuEt0dLSCAqz3Rjl+BAoAAAAAAMB/RYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGAFAQoAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGAFAQoAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGAFAQoAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFY42LoApE9ysqHkZMPWZeD/EpPYF1nNou5VbV0CUlGw5kBbl4C7GEnxti4ByDCGYcgw+HucVSTQG2U5GwbXtnUJSIVv1f62LgF3SWtvxAgUAAAAAAAAKwhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgIUAAAAAAAAKwhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgIUAAAAAAAAKwhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALCCAAUAAAAAAMAKAhQAAAAAAAArCFAAAAAAAACsIEABAAAAAACwggAFAAAAAADACgIUAAAAAAAAKwhQAAAAAAAArCBAAQAAAAAAsIIABQAAAAAAwAoCFAAAAAAAACsIUAAAAAAAAKwgQAEAAAAAALDCwdYFIPeYtWSTZn+7WSfOREmSShYL0CvdG6tBjdI2riz3+G3XIc2Yv15/7j+p85ejNWtMdzWpXc5imb+PndOoj37Qb7sOKTEpWSWC8+uzUc+rcICvjarOuabNW6NVP/+pQ8cvyNkpj6qUDdYbfZ5U8SL5zcvcikvQu9O+1/fr/lB8QqLqVC2p0YPbKJ+vhw0rzzmeb/2Ynm9dS4EFbn++9x85p3Gfr9LaX/dJkvz9PPTOgKf0eLWScnd10qHjFzR+1mr9sGGXeR3zx/dW2RKFlNfHQ1evx+rnrQc0cur3Onfpmi1eEoBs5P2ZKzX2s1UW00KD/LVl0TAbVZT7/LbzkKZ/tU5/Hjip85eiNfv9Hmpa55/eaMC7X2rByq0Wz6lbraS+mdT3YZeaa/E9ebgyojcqF1ZYI/u3UqXwIkpKMrRswy69NXGJbtyMt8VLylAEKHcJDg7WoEGDNGjQIFuXkiMV9PfW8L4tVCwwnwxJ36zYok6vfKqN815TyWIFbF1erhB7M17hIYXUvlk1dX9jVor5x05dUqs+k9Wh+aMa0qOJPFyddeDoWTk75bFBtTnfbzsPq8vTj6l8ySJKSkrW+zNX6NmXPtaGL1+Xq4uTJOntqd9p3a/79Mm7XeXh5qK3Ji5WzzdnaemMgTauPmc4c+Gq3p72vQ6fvCiTyaQOzarpqw97qU6n97X/yDnNGPmcvDxc9OzLn+jytRg906iKZo95XnWfG6u//j4lSdq0/W9NmL1a5y9dUwF/b7078CnN/aC7GnWfYONXB/x39EaZr2SxAvpu2ovmxw4ODBB/mGJvxat0aCE92/xRdRv6earL1Hu0lCa/1dH82DEP/4V62PiePDz/tTcKyOulpdP767s1f+jVcQvl4easMS+31vQRndX19dS/Y9lJtvrkXbx4UX369FGRIkXk5OSkgIAANWrUSBERERmy/m3btqlXr15pXn7kyJGqUKFCurczZ84ceXt7p/t52V3jWmXVsGZpFS/ir5Ai/nqrz5Nyc3XS9j3HbF1arlG/erhe79VMTeuUT3X++zOXq171cA3r11JlSxRWcOG8alSrrPL6MNohM3w14QW1bVpNYcUKKDy0kCa+8axOn7+iPw/c/o95dMxNfbN8i4b3b6WalUuoXMlATXjjWW3/66h28L3JED9u2qM1v+7TkZMXdfjEBb034wfdiI1TlTJFJUlVyxXTpwt+1h/7juv46csaP2u1rl2/qQqlAs3rmPH1Bm3fc0wnz13R1j+PatLcNapSJlgO9tnqTyyyKXqj7M/B3k7583qaf/y83W1dUq5Sv3q4hvZurqaPp94bSZKjo4P8/TzNP96erg+xQkh8Tx6m/9obNapVRgmJSRoydqEOHb+gnftO6OUxC9SyfkUVLZzXli8tQ2Sr+LR169aKj4/X3LlzVaxYMZ0/f17r1q3T5cuXM2T9+fLly5D1wLqkpGR9v26nYm/Gq0qZYFuXA0nJycla++s+9e1YX+1fmqE9f59SkYJ+6t+5QYrTfJA5om/clCRzY/bXgZNKSExSrSolzMuEBOVXofw++mPvMVXmu5Oh7OxMalW/klxdHLXtr6OSpK1/HtFTDStrdcReXbt+U081qCQnJwdt3nEw1XV4e7rqmcZVtPXPo0pMSn6Y5SOXojfK/o6cvKjwpm/KyTGPHilbVMP7Pclps1nMr38cUnjTN+Tt4arHKofq9d7N5evlZuuychW+J7bxb3ojxzwOSkhMkmEY5vXcjLt96s6jFYrr6KlLD/+FZKBsc3js6tWr2rRpkz744APVrVtXQUFBqlq1qoYOHaoWLVpIkk6cOKGWLVvK3d1dnp6eatu2rc6fP2+xnh9++EGPPPKInJ2dlTdvXj311FPmecHBwZo0aZLFNnv06KF8+fLJ09NT9erV0+7duyXdPlLy9ttva/fu3TKZTDKZTJozZ44kacKECSpbtqzc3NwUGBiovn37KiYmRpK0ceNGdevWTdeuXTM/b+TIkZn3xmUx+w6dUZHHB6tArZc0+IMF+uKDHpy+k0VcuhKjGzfjNO3LtbfP7Z3YR01ql1X3N2bp152HbF1ejpecnKyRU77TI2WLmr8TFy5fl2Mee3l5WB7pyuvroQuXo21RZo4UXrygTv48XucjJmnC0Hbq/MqnOnD0nCSp29BZcnCw19F1Y3X+10ma+EZ7dX7l0xR//Ee+2FKnfhmvo+vGqnB+Xz07ZKYtXgpyGXqj7K9ymSBNG95Jiyb31YevtdPxM5fVtNckXb9xy9al4f/qPlpKU4d30uIpL+qtvi30285D6vDSDCURkj80fE8evv/SG23afkD+fp7q36m+8jjYy8vDRSNebClJCsjrZbPXlFGyTYDi7u4ud3d3LV26VHFxcSnmJycnq2XLloqKitLPP/+sNWvW6MiRI2rXrp15mRUrVuipp55S06ZNtXPnTq1bt05Vq1a97zbbtGmjCxcuaNWqVdqxY4cqVaqk+vXrKyoqSu3atdPgwYNVunRpnT17VmfPnjVvy87OTlOmTNHevXs1d+5crV+/Xq+++qokqUaNGpo0aZI8PT3NzxsyZEiKbcfFxSk6OtriJycICfLXxnmv66fPB6vb04+p3ztfav+Rs7YuC5KSk2+nxI1rlVHv9nVVpkRh9e/cUA1rlNa8pRkzFBz39+aExTpw5Kymv93F1qXkOgePn1ftjmPUoNuHmrVksz4a2VlhRQMkSW++0FxeHi5q2XeK6j03VtO/Wq/ZY55XePGCFuuYMm+t6nT6QE/1m6bk5GR9PLKzLV4Kchl6o+zfGzWsUVqtGlRU6dBCql+9lBZOekHXrt/U0rU7bV0a/u+phpXVuFZZhYcUVNM65TTvw97aFXlCEX+kPhIRGY/vycP3X3qj/UfOqe/IeerXqb7ObJqgAz+O1okzl3X+crSSk7N/8JhtTuFxcHDQnDlz1LNnT3388ceqVKmS6tSpo/bt26tcuXJat26d/vrrLx09elSBgbfPv/riiy9UunRpbdu2TY888ohGjRql9u3b6+233zavt3z51M933Lx5s7Zu3aoLFy7Iyen2xRw//PBDLV26VIsXL1avXr3k7u4uBwcHBQQEWDz37gutBQcH67333tMLL7ygjz76SI6OjvLy8pLJZErxvLuNGTPGos6cwjGPg4oF3h4OXKFUEe2MPK6ZC37WhKHtbVwZfL3d5GBvp9Bgy89laHB+bf3ziI2qyh3enLBYa3/dpyXT+qugv7d5ur+fh+ITknTteqzFKJRLUdfl7+dpg0pzpoTEJPNRk937T6pieBG90P5xTf5irXq1q6Pq7d7T/iO3j7rsOXha1SsWV482tfXy+9+Y1xF17Yairt3Q4RMX9Pexc9q74j09UraoebgrkBnojXIeLw9XhRTx19FTF21dCu4juFBe+Xm76dipS6r9SJity8mV+J5kvv/aGy1evV2LV29XPl8Pxd6Mk2FIfZ+tp2OnM+b0UlvKNiNQpNvn+Z45c0bLli1T48aNtXHjRlWqVElz5sxRZGSkAgMDzQ2CJIWHh8vb21uRkZGSpF27dql+/fpp2tbu3bsVExMjPz8/8xEed3d3HT16VIcPH37gc9euXav69eurUKFC8vDwUOfOnXX58mXFxsam+bUOHTpU165dM/+cPHkyzc/NTpKTDcUlJNi6DOh2uFWhVBEdPnHBYvrhkxdUOMDHRlXlbIZh6M0Ji/XjL39pweR+KlLQz2J+2bBA5XGwt7jexuET53X6/BVVKh38kKvNPexMJjk6OsjV2VHSP6Oz7khKMmSyMz3w+RJ3acDDQW+Us8TExuno6UvKn5eQPKs6c+GKoq7Fyp99ZDN8Tx6+f9sbXYy6rhs34/VUw0q6FZ+gDVv2P5R6M1O26+6cnZ3VsGFDNWzYUMOGDVOPHj00YsQIDR482OpzXVxc0rydmJgYFShQQBs3bkwx70FXiT927JiaN2+uPn36aNSoUfL19dXmzZvVvXt3xcfHy9U1bVftdnJyMh/dySnemb5MDWqEq3B+H8XExmnx6u2K+OOQFk3ua+vSco0bsXEWaf2JM5e15+9T8vZ0VeEAX/V5tp5eGD5Xj1YorpqVQrXh90itidirJVNffMBa8W+9OX6xlq7doc/H9JC7q5P5uiYe7s5ycXKUp7uL2jevpnemLpW3p6s8XJ01bNISVS4TzAVkM8jwfi209te9OnnuijxcnfVM4yp6rHKoWvf/SH8fO6fDJy5o4tAOGjb5O0Vdu6Fmj5dT3Wphav/Sx5KkyqWDVCk8SL/tPqxr0bEKLpxPb77QTEdOXmT0CR4aeqPsa9jk79S4VhkFBvjq7KVren/mStnb2an1E5VtXVqu8aDeyMfTTR9+vkrN6paXv5+njp26pHenf6+ihfOqbrWSNqw6d+F78nD9195Iknq2qa0tfx7RjZvxqlutpN4e0EpvT/te0TE3bfjKMka2C1DuFR4erqVLl6pUqVI6efKkTp48aT7Ssm/fPl29elXh4eGSZB7O2q1bN6vrrVSpks6dOycHBwcFBwenuoyjo6OSkpIspu3YsUPJyckaP3687OxuD/BZuHCh1eflBpeuXFfft+fp/KVoebo7KzykoBZN7ssfoIdo9/4Tat1/mvnxyKlLJUltm1TV5Lc6qmmd8vrglbaaOm+Nhk38VsWL+OuzUc+rWvniNqo4Z/vi/9eWaXPXPpGkCW90UNum1SRJI/o/JTuTnXq9OVvxCYmqU7WkRg9+5qHXmlPl9XHXjJHPKX9eT0XH3NLeQ6fVuv9H2rj19hGStoNmaMSLLfX1hN5yc3XS0ZMX1XfkPK35dZ8k6eatBDWvW16v92omVxdHnb90Tet+i9SHs2YpPiHRli8NuRi9UfZx5sJV9XxrjqKuxcrPx12Pli+mn2a9rLw+HrYuLdfYtf+Enu431fx4xJTvJEntmlbVB6+01b7DZ7Rg1VZFX7+pgLxeqlOtpF7r1VROjnlsVXKuw/fk4fqvvZEkVSodpNd7NZObq6MOHjuvl0d/rQWrttnqJWUok3H3/YWysMuXL6tNmzZ6/vnnVa5cOXl4eGj79u3q37+/mjVrps8++0yVKlWSh4eHJk2apMTERPXt21fu7u7mIyUbN25U/fr19dZbb6l9+/ZKTEzUypUr9dprr0m6fU7uoEGDNGjQIBmGodq1a+v69esaO3asSpQooTNnzpgvtlalShXNnz9fvXr10ubNm1W4cGF5eHho//79qlChgiZNmqQnn3xSERERGjp0qE6fPq0rV67I29tbv/76q2rWrKm1a9eqfPnycnV1tXr0JTo6Wl5eXjp78ao8PRmullXEJ2b/CyHlNEnZ41darlP4sUG2LgF3MZLiFffXp7p27Rp/U7IxeqPbvdG5S/RGWUlCEn+Hs5o89vc/7RS241u1v61LwF3S2htlm2uguLu7q1q1apo4caJq166tMmXKaNiwYerZs6emTZsmk8mk77//Xj4+Pqpdu7YaNGigYsWKacGCBeZ1PP7441q0aJGWLVumChUqqF69etq6dWuq2zOZTFq5cqVq166tbt26qUSJEmrfvr2OHz+u/PnzS7p93nHjxo1Vt25d5cuXT19//bXKly+vCRMm6IMPPlCZMmX01VdfacyYMRbrrlGjhl544QW1a9dO+fLl09ixYzPvjQMAADkSvREAAA9XthmBktsxAiVrYgRK1sMIlKyJEShZCyNQkBMwAiVrYgRK1sMIlKyJEShZS44bgQIAAAAAAGArBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGAFAQoAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGAFAQoAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAAAAAAAAFhBgAIAAAAAAGAFAQoAAAAAAIAVBCgAAAAAAABWEKAAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWOFg6wKQNoZhSJKuX4+2cSW4W3xisq1LwD2S//9dQdZiJMXbugTc5c7+MPi+IBujN8qaEpL4vZLV5LE32boEpILeKGtJa29EgJJNXL9+XZJUolgRG1cCAMgprl+/Li8vL1uXAfwrd3qj0KL0RgCAjGGtNzIZHH7KFpKTk3XmzBl5eHjIZMreKXJ0dLQCAwN18uRJeXp62rociH2SFbFPsp6ctE8Mw9D169dVsGBB2dlxNi+yJ3ojZCb2SdbDPsl6ctI+SWtvxAiUbMLOzk6FCxe2dRkZytPTM9t/0XIa9knWwz7JenLKPmHkCbI7eiM8DOyTrId9kvXklH2Slt6Iw04AAAAAAABWEKAAAAAAAABYQYCCh87JyUkjRoyQk5OTrUvB/7FPsh72SdbDPgGQWfj9kvWwT7Ie9knWkxv3CReRBQAAAAAAsIIRKAAAAAAAAFYQoABAFhIbG6v33ntPR48etXUpAAAANkdvhKyEAAWZZuPGjTKZTLp69aqtS4GNHDt2TCaTSbt27bJ1KVnSnDlz5O3tbTGtZ8+eOnPmjIoWLZrqc3hPbSM4OFiTJk2ydRkAsjl6I/B3/MHojbKP3NobEaDgvs6dO6f+/furWLFicnJyUmBgoJ588kmtW7fuX60vtV+IuK1r164ymUwpfho3bmzr0v6TwMBAnT17VmXKlLF1KZnm7n3n6OiokJAQvfPOO0pMTEz3uiZPnqzY2FhNmzbNvO5WrVpZLJMb3tN/4+LFi+rTp4+KFCkiJycnBQQEqFGjRoqIiMiQ9W/btk29evVK8/IjR45UhQoV0r0dfk8CWRu90cNDb5R90RtlDfRGmcPB1gUgazp27Jhq1qwpb29vjRs3TmXLllVCQoJWr16tfv36af/+/TatLyEhQXny5LFpDRmtcePGmj17tsW07H5Fa3t7ewUEBNi6jEx3Z9/FxcVp5cqV6tevn/LkyaOhQ4emaz0DBw7UwIEDH7hMbnlP06t169aKj4/X3LlzVaxYMZ0/f17r1q3T5cuXM2T9+fLly5D1AMi+6I0ePnqj7IveyPbojTKJAaSiSZMmRqFChYyYmJgU865cuWIcPXrUkGTs3LnTYrokY8OGDYZhGMaGDRsMScaVK1fM/777Z8SIEYZhGIYk47vvvrPYhpeXlzF79mzDMAzztr755hujdu3ahpOTkzF79mzj0qVLRvv27Y2CBQsaLi4uRpkyZYz58+dnwruR+bp06WK0bNnyvvOvXLli9OrVy/D39zecnJyM0qVLGz/88IN5/uLFi43w8HDD0dHRCAoKMj788EOL5wcFBRmjRo0yunXrZri7uxuBgYHGJ598YrHMn3/+adStW9dwdnY2fH19jZ49exrXr19PUeOoUaMMf39/w8vLy3j77beNhIQEY8iQIYaPj49RqFAhY9asWebn3Ps5SUxMNJ5//nkjODjYcHZ2NkqUKGFMmjTpP7xztpfavmvYsKHx6KOPGlFRUUbnzp0Nb29vw8XFxWjcuLHx999/m5ebPXu24eXlZX48YsQIo3z58uZ/3/ud2bBhQ6rfvT179hjNmjUzPDw8DHd3d+Oxxx4zDh06ZBiGYWzdutVo0KCB4efnZ3h6ehq1a9c2duzYkVlvh03c+d2zcePG+y5z/Phxo0WLFoabm5vh4eFhtGnTxjh37pzFMsuWLTOqVKliODk5GX5+fkarVq3M84KCgoyJEydabLN79+5G3rx5DQ8PD6Nu3brGrl27DMO4vV/v3Xd3fp+NHz/eKFOmjOHq6moULlzY6NOnj/l79qDfkwBsj97o4aI3yr7ojWyP3ijzcAoPUoiKitKPP/6ofv36yc3NLcX8fzOEqkaNGpo0aZI8PT119uxZnT17VkOGDEnXOl5//XUNHDhQkZGRatSokW7duqXKlStrxYoV2rNnj3r16qXOnTtr69at6a4vK0tOTlaTJk0UERGhL7/8Uvv27dP7778ve3t7SdKOHTvUtm1btW/fXn/99ZdGjhypYcOGac6cORbrGT9+vKpUqaKdO3eqb9++6tOnjw4cOCBJunHjhho1aiQfHx9t27ZNixYt0tq1a/Xiiy9arGP9+vU6c+aMfvnlF02YMEEjRoxQ8+bN5ePjoy1btuiFF15Q7969derUqfu+lsKFC2vRokXat2+fhg8frjfeeEMLFy7M+DfOhlxcXBQfH6+uXbtq+/btWrZsmX777TcZhqGmTZsqISHB6jqGDBmitm3bqnHjxubvTI0aNVIsd/r0adWuXVtOTk5av369duzYoeeff948TPb69evq0qWLNm/erN9//12hoaFq2rSprl+/nuGv21bc3d3l7u6upUuXKi4uLsX85ORktWzZUlFRUfr555+1Zs0aHTlyRO3atTMvs2LFCj311FNq2rSpdu7cqXXr1qlq1ar33WabNm104cIFrVq1Sjt27FClSpVUv359RUVFqV27dho8eLBKly5t3nd3tmVnZ6cpU6Zo7969mjt3rtavX69XX31VUsb8ngSQOeiNshZ6o+yH3ujhojfKRDaNb5AlbdmyxZBkfPvtt/ddJr1HWQwjZaJ8h9J4lCUtaXyzZs2MwYMHW10uq+nSpYthb29vuLm5WfyMGjXKWL16tWFnZ2ccOHAg1ec+++yzRsOGDS2mvfLKK0Z4eLj5cVBQkNGpUyfz4+TkZMPf39+YMWOGYRiGMXPmTMPHx8fiqNqKFSsMOzs7cxLdpUsXIygoyEhKSjIvExYWZtSqVcv8ODEx0XBzczO+/vprwzBS/5zcq1+/fkbr1q2tvUVZ1t1HWZKTk401a9YYTk5ORqtWrQxJRkREhHnZS5cuGS4uLsbChQsNw3jwUZZ7133Hve/p0KFDjaJFixrx8fFpqjcpKcnw8PCwOEqXEyxevNjw8fExnJ2djRo1ahhDhw41du/ebRiGYfz000+Gvb29ceLECfPye/fuNSQZW7duNQzDMKpXr2507Njxvuu/+yjLpk2bDE9PT+PWrVsWyxQvXtx89PLefXk/ixYtMvz8/MyP7/d7EoBt0Rs9fPRG9EaGQW/0X9AbZQ5GoCAFwzBsXUKqqlSpYvE4KSlJ7777rsqWLStfX1+5u7tr9erVOnHihI0q/G/q1q2rXbt2Wfy88MIL2rVrlwoXLqwSJUqk+rzIyEjVrFnTYlrNmjV18OBBJSUlmaeVK1fO/G+TyaSAgABduHDBvI7y5ctbHFWrWbOmkpOTzUdiJKl06dKys/vn10b+/PlVtmxZ82N7e3v5+fmZ15ua6dOnq3LlysqXL5/c3d01c+bMbLvP7li+fLnc3d3l7OysJk2aqF27duratascHBxUrVo183J+fn4KCwtTZGRkhm17165dqlWr1n3Pez9//rx69uyp0NBQeXl5ydPTUzExMdn+Pb9X69atdebMGS1btkyNGzfWxo0bValSJc2ZM0eRkZEKDAxUYGCgefnw8HB5e3ub98WuXbtUv379NG1r9+7diomJkZ+fn/kIj7u7u44eParDhw8/8Llr165V/fr1VahQIXl4eKhz5866fPmyYmNj//2LB5Dp6I1sg94o+6I3sj16o8zBRWSRQmhoqEwm0wMvhnbnD8XdDUVaht6lxmQypWhMUlvXvUNmx40bp8mTJ2vSpEkqW7as3NzcNGjQIMXHx/+rOmzNzc1NISEhKaa7uLhkyPrv/SNiMpmUnJz8n9eRnvV+8803GjJkiMaPH6/q1avLw8ND48aN05YtW9JVR1ZTt25dzZgxQ46OjipYsKAcHBy0bNmyh7Jta5+PLl266PLly5o8ebKCgoLk5OSk6tWrZ9vvyYM4OzurYcOGatiwoYYNG6YePXpoxIgRGjx4sNXnpud7FhMTowIFCmjjxo0p5j1oGP+xY8fUvHlz9enTR6NGjZKvr682b96s7t27Kz4+Xq6urmmuAcDDRW9kG/RG2Re9UdZAb5TxGIGCFHx9fdWoUSNNnz5dN27cSDH/6tWr5qsunz171jzd2r3XHR0dLVL/O/Lly2exnoMHD6YpcYyIiFDLli3VqVMnlS9fXsWKFdPff/9t9XnZTbly5XTq1Kn7vrZSpUqluB1ZRESESpQoYT4X2JpSpUpp9+7dFvs7IiJCdnZ2CgsL+/fF3yMiIkI1atRQ3759VbFiRYWEhFhNpbODOw1ekSJF5OBwO5cuVaqUEhMTLRqgy5cv68CBAwoPD0/Teu/3nblbuXLltGnTpvs26RERERowYICaNm2q0qVLy8nJSZcuXUrjK8vewsPDdePGDZUqVUonT57UyZMnzfP27dunq1evmvdFuXLl0nwb0kqVKuncuXNycHBQSEiIxU/evHklpb7vduzYoeTkZI0fP16PPvqoSpQooTNnzlgsk5Z9DuDhozfKWuiNsj56o6yJ3ui/I0BBqqZPn66kpCRVrVpVS5Ys0cGDBxUZGakpU6aoevXqcnFx0aOPPqr3339fkZGR+vnnn/XWW289cJ3BwcGKiYnRunXrdOnSJXMjUK9ePU2bNk07d+7U9u3b9cILL6TpNnyhoaFas2aNfv31V0VGRqp37946f/58hrx+W4iLi9O5c+csfi5duqQ6deqodu3aat26tdasWaOjR49q1apV+vHHHyVJgwcP1rp16/Tuu+/q77//1ty5czVt2rR0XWCpY8eOcnZ2VpcuXbRnzx5t2LBB/fv3V+fOnZU/f/4Me42hoaHavn27Vq9erb///lvDhg3Ttm3bMmz9WUloaKhatmypnj17avPmzdq9e7c6deqkQoUKqWXLlmlaR3BwsP78808dOHBAly5dSrURePHFFxUdHa327dtr+/btOnjwoObNm2ceXhwaGqp58+YpMjJSW7ZsUceOHTPsyF1WcfnyZdWrV09ffvml/vzzTx09elSLFi3S2LFj1bJlSzVo0EBly5ZVx44d9ccff2jr1q167rnnVKdOHfPw9xEjRujrr7/WiBEjFBkZqb/++ksffPBBqttr0KCBqlevrlatWumnn37SsWPH9Ouvv+rNN9/U9u3bJd3ed0ePHtWuXbt06dIlxcXFKSQkRAkJCZo6daqOHDmiefPm6eOPP7ZY9/1+TwKwPXqjh4/eKGehN3p46I0ykS0vwIKs7cyZM0a/fv2MoKAgw9HR0ShUqJDRokUL84XQ9u3bZ1SvXt1wcXExKlSoYPz0008PvFCaYRjGCy+8YPj5+Vncgur06dPGE088Ybi5uRmhoaHGypUrU71Q2r0X27p8+bLRsmVLw93d3fD39zfeeust47nnnnvgLe+yqi5duqS4RZckIywszDCM26+1W7duhp+fn+Hs7GyUKVPGWL58ufn5d27VlydPHqNIkSLGuHHjLNZ/723GDMMwypcvb3EbsLTequ9uderUMQYOHHjfbd27727dumV07drV8PLyMry9vY0+ffoYr7/+epouKJVVPeg2i3du1efl5WW4uLgYjRo1SvOt+gzDMC5cuGA0bNjQcHd3f+Ct+nbv3m088cQThqurq+Hh4WHUqlXLOHz4sGEYhvHHH38YVapUMZydnY3Q0FBj0aJFqX4esrNbt24Zr7/+ulGpUiXDy8vLcHV1NcLCwoy33nrLiI2NNQwjbbfqW7JkiVGhQgXD0dHRyJs3r/H000+b5937nkVHRxv9+/c3ChYsaOTJk8cIDAw0OnbsaL4Y261bt4zWrVsb3t7eFrfqmzBhglGgQAHz5+GLL75I0+9JAFkDvdHDQ29UPt3vWVZBb2R79EaZx2QYWfSqWAAAAAAAAFkEp/AAAAAAAABYQYACAAAAAABgBQEKAAAAAACAFQQoAAAAAAAAVhCgAAAAAAAAWEGAAgAAAAAAYAUBCgAAAAAAgBUEKAAAAAAAAFYQoAB46Lp27apWrVqZHz/++OMaNGjQQ69j48aNMplMunr16n2XMZlMWrp0aZrXOXLkSFWoUOE/1XXs2DGZTCbt2rXrP60HAABkD/RGD0ZvhKyCAAWApNt/uE0mk0wmkxwdHRUSEqJ33nlHiYmJmb7tb7/9Vu+++26alk3LH3YAAID/it4IwL0cbF0AgKyjcePGmj17tuLi4rRy5Ur169dPefLk0dChQ1MsGx8fL0dHxwzZrq+vb4asBwAAICPRGwG4GyNQAJg5OTkpICBAQUFB6tOnjxo0aKBly5ZJ+mdo6ahRo1SwYEGFhYVJkk6ePKm2bdvK29tbvr6+atmypY4dO2ZeZ1JSkl5++WV5e3vLz89Pr776qgzDsNjuvcNU4+Li9NprrykwMFBOTk4KCQnR559/rmPHjqlu3bqSJB8fH5lMJnXt2lWSlJycrDFjxqho0aJycXFR+fLltXjxYovtrFy5UiVKlJCLi4vq1q1rUWdavfbaaypRooRcXV1VrFgxDRs2TAkJCSmW++STTxQYGChXV1e1bdtW165ds5j/2WefqVSpUnJ2dlbJkiX10UcfpbsWAACQueiNrKM3Qm5CgALgvlxcXBQfH29+vG7dOh04cEBr1qzR8uXLlZCQoEaNGsnDw0ObNm1SRESE3N3d1bhxY/Pzxo8frzlz5mjWrFnavHmzoqKi9N133z1wu88995y+/vprTZkyRZGRkfrkk0/k7u6uwMBALVmyRJJ04MABnT17VpMnT5YkjRkzRl988YU+/vhj7d27Vy+99JI6deqkn3/+WdLtZubpp5/Wk08+qV27dqlHjx56/fXX0/2eeHh4aM6cOdq3b58mT56sTz/9VBMnTrRY5tChQ1q4cKF++OEH/fjjj9q5c6f69u1rnv/VV19p+PDhGjVqlCIjIzV69GgNGzZMc+fOTXc9AADg4aE3SoneCLmKAQCGYXTp0sVo2bKlYRiGkZycbKxZs8ZwcnIyhgwZYp6fP39+Iy4uzvycefPmGWFhYUZycrJ5WlxcnOHi4mKsXr3aMAzDKFCggDF27Fjz/ISEBKNw4cLmbRmGYdSpU8cYOHCgYRiGceDAAUOSsWbNmlTr3LBhgyHJuHLlinnarVu3DFdXV+PXX3+1WLZ79+5Ghw4dDMMwjKFDhxrh4eEW81977bUU67qXJOO777677/xx48YZlStXNj8eMWKEYW9vb5w6dco8bdWqVYadnZ1x9uxZwzAMo3jx4sb8+fMt1vPuu+8a1atXNwzDMI4ePWpIMnbu3Hnf7QIAgMxFb5Q6eiPkZlwDBYDZ8uXL5e7uroSEBCUnJ+vZZ5/VyJEjzfPLli1rcW7v7t27dejQIXl4eFis59atWzp8+LCuXbums2fPqlq1auZ5Dg4OqlKlSoqhqnfs2rVL9vb2qlOnTprrPnTokGJjY9WwYUOL6fHx8apYsaIkKTIy0qIOSapevXqat3HHggULNGXKFB0+fFgxMTFKTEyUp6enxTJFihRRoUKFLLaTnJysAwcOyMPDQ4cPH1b37t3Vs2dP8zKJiYny8vJKdz0AACDz0BtZR2+E3IQABYBZ3bp1NWPGDDk6OqpgwYJycLD8FeHm5mbxOCYmRpUrV9ZXX32VYl358uX7VzW4uLik+zkxMTGSpBUrVlj8cZZun7ucUX777Td17NhRb7/9tho1aiQvLy998803Gj9+fLpr/fTTT1M0Lfb29hlWKwAA+O/ojR6M3gi5DQEKADM3NzeFhISkeflKlSppwYIF8vf3T3Gk4Y4CBQpoy5Ytql27tqTbRxN27NihSpUqpbp82bJllZycrJ9//lkNGjRIMf/OUZ6kpCTztPDwcDk5OenEiRP3PTpTqlQp80Xf7vj999+tv8i7/PrrrwoKCtKbb75pnnb8+PEUy504cUJnzpxRwYIFzduxs7NTWNj/2rt3kEbWOAzjj50I6YSIghdQ1hReWis7EQvFIDZBBryAhBAJKtikCIKxsoiFFkJiIyIIU2gvBiwFsfFCFMTOxkLBbrc4IBzOWQctlj17nl89fPN93cs7M//5Rjwep7m5mbu7O1Kp1KfuL0mSfi2z0cfMRvq/cYispC9LpVI0NjYyNjZGtVrl/v6ek5MTstksj4+PACwsLLC+vk4YhlxdXZFOp3l+fv7pmu3t7QRBwPT0NGEYvq95cHAAQFtbG3V1dRwdHfH09MTLywuxWIylpSVyuRy7u7vUajXOz8/Z3Nx8Hz42Pz/P7e0ty8vLXF9fs7e3R6VS+dR5u7q6eHh4YH9/n1qtRqlU+tehb/X19QRBwMXFBdVqlWw2y+TkJE1NTQAUCgWKxSKlUombmxsuLy8pl8tsbGx8aj+SJOn3YjYyG+nPZoEi6csaGho4PT2ltbWVZDJJIpFgZmaGt7e396cui4uLTE1NEQQBAwMDxGIxxsfHP1x3a2uLiYkJ0uk03d3dzM3N8fr6CkBLSwuFQoGVlRXi8TiZTAaA1dVV8vk8xWKRRCLB8PAwx8fHdHR0AH99e3t4eEgYhvT19bG9vc3a2tqnzjs6OkoulyOTydDf38/Z2Rn5fP4f13V2dpJMJhkZGWFoaIje3t6//YpvdnaWnZ0dyuUyPT09DA4OUqlU3vcqSZL+m8xGZiP92eq+/2xakSRJkiRJkgDfQJEkSZIkSYpkgSJJkiRJkhTBAkWSJEmSJCmCBYokSZIkSVIECxRJkiRJkqQIFiiSJEmSJEkRLFAkSZIkSZIiWKBIkiRJkiRFsECRJEmSJEmKYIEiSZIkSZIUwQJFkiRJkiQpggWKJEmSJElShB+qMnz+kFELiAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_roberta, y_train_labels_roberta = preprocess_tecla_roberta(\n",
    "    train, 5000\n",
    ")\n",
    "X_val_roberta, y_val_labels_roberta = preprocess_tecla_roberta(\n",
    "    val, 1000\n",
    ")\n",
    "X_test_roberta, y_test_labels_roberta = preprocess_tecla_roberta(\n",
    "    test, 1000\n",
    ")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='cosine')\n",
    "\n",
    "# Entrenar amb dades corresponents\n",
    "knn_model.fit(X_train_roberta, y_train_labels_roberta)\n",
    "\n",
    "# Prediccions\n",
    "y_pred_val = knn_model.predict(X_val_roberta)\n",
    "y_pred_test = knn_model.predict(X_test_roberta)\n",
    "\n",
    "# Avaluació\n",
    "val_accuracy = accuracy_score(y_val_labels_roberta, y_pred_val)\n",
    "test_accuracy = accuracy_score(y_test_labels_roberta, y_pred_test)\n",
    "\n",
    "print(f\"KNN (k=3) - Accuracy validació: {val_accuracy:.3f}, Accuracy test: {test_accuracy:.3f}\")\n",
    "\n",
    "# Gràfic de matriu de confusió per validació i test\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "cm_val = confusion_matrix(y_val_labels_roberta, y_pred_val, labels=unique_labels)\n",
    "disp_val = ConfusionMatrixDisplay(confusion_matrix=cm_val, display_labels=unique_labels)\n",
    "disp_val.plot(ax=axes[0], cmap='Blues', colorbar=False)\n",
    "axes[0].set_title(\"Matriu de confusió - Validació\")\n",
    "\n",
    "cm_test = confusion_matrix(y_test_labels_roberta, y_pred_test, labels=unique_labels)\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=unique_labels)\n",
    "disp_test.plot(ax=axes[1], cmap='Blues', colorbar=False)\n",
    "axes[1].set_title(\"Matriu de confusió - Test\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
