{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a1ac5a",
   "metadata": {
    "vscode": {
     "languageId": "xml"
    }
   },
   "source": [
    "# Pràctica 4: Similitud de Text Semàntic (STS) per al Català amb Anàlisi Detallada\n",
    "\n",
    "**Objectiu**: Aquest notebook té com a objectiu entrenar i avaluar diversos models de Similitud de Text Semàntic (STS) per al català. S'exploraran diferents tècniques d'embeddings (Word2Vec, spaCy, RoBERTa) i arquitectures de models, des de baselines simples fins a xarxes neuronals més complexes amb mecanismes d'atenció i models Transformer pre-entrenats. Addicionalment, s'inclou una secció per a la classificació de text utilitzant el dataset TECLA.\n",
    "\n",
    "## Estructura de la Pràctica:\n",
    "1.  **Preparació de l'Entorn i Llibreries**: Importació de les llibreries necessàries i configuració inicial.\n",
    "2.  **Càrrega del Dataset STS-ca**: Obtenció i exploració del dataset principal per a la tasca de STS.\n",
    "3.  **Preparació d'Embeddings Word2Vec**: Càrrega d'embeddings pre-entrenats i creació de versions truncades.\n",
    "4.  **Funcions d'Utilitat per a Processament de Text**: Definició de funcions per preprocessar text i generar embeddings de frases.\n",
    "5.  **Models Baseline (Similitud Cosinus)**: Implementació i avaluació de models bàsics basats en la similitud cosinus.\n",
    "6.  **Model 1: Regressió amb Embeddings Agregats**: Desenvolupament d'un model de regressió neuronal utilitzant embeddings de frases concatenats.\n",
    "7.  **Model 2: Seqüència d'Embeddings amb Atenció**: Implementació d'un model seqüencial amb un mecanisme d'atenció per capturar millor les relacions semàntiques.\n",
    "8.  **Anàlisi Comparativa i Visualització de Resultats (STS)**: Resum i visualització dels resultats dels models STS.\n",
    "9.  **Experimentació Avançada amb Embeddings**:\n",
    "    *   Baseline One-Hot Encoding.\n",
    "    *   Ajustament d'Hiperparàmetres.\n",
    "    *   Ús d'Embeddings de spaCy.\n",
    "    *   Ús d'Embeddings de RoBERTa (base).\n",
    "    *   Ús d'un model RoBERTa fine-tuned per STS.\n",
    "10. **Classificació de Text amb el Dataset TECLA**:\n",
    "    *   Càrrega i preparació del dataset TECLA.\n",
    "    *   Model de classificació amb embeddings agregats.\n",
    "    *   Model de classificació amb seqüències d'embeddings.\n",
    "11. **Conclusions Generals i Avaluació Final**: Resum de les troballes clau i avaluació del millor model en el conjunt de test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b3075b",
   "metadata": {},
   "source": [
    "## 1. Preparació de l'Entorn i Llibreries\n",
    "\n",
    "En aquesta secció, importem totes les llibreries necessàries per a la pràctica. Aquestes inclouen:\n",
    "\n",
    "També es configura l'ús de la GPU si està disponible per accelerar l'entrenament dels models i s'imprimeixen les versions de TensorFlow i la disponibilitat de GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e65497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessaris\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Optional, Dict, Union\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Configuració de GPU (opcional)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d1aa7",
   "metadata": {},
   "source": [
    "## 2. Càrrega del Dataset STS-ca\n",
    "\n",
    "Aquí carreguem el dataset \"STS-ca\" (Semantic Textual Similarity for Catalan) del projecte AINA, utilitzant la llibreria `datasets` de Hugging Face. Aquest dataset conté parells de frases en català i una etiqueta numèrica que indica el seu grau de similitud semàntica (normalment en una escala de 0 a 5).\n",
    "\n",
    "El dataset es divideix en tres parts:\n",
    "- `train`: conjunt d'entrenament, utilitzat per ajustar els paràmetres dels models.\n",
    "- `test`: conjunt de prova, utilitzat per a l'avaluació final del model seleccionat.\n",
    "- `validation`: conjunt de validació, utilitzat per monitorar el rendiment durant l'entrenament i per a l'ajust d'hiperparàmetres.\n",
    "\n",
    "Després de carregar les dades, les convertim a DataFrames de Pandas per facilitar-ne la manipulació i l'anàlisi. S'imprimeix el nombre de mostres en cada conjunt, el rang de les etiquetes de similitud i alguns exemples per entendre millor l'estructura de les dades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe9149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Carregar el dataset STS-ca\n",
    "print(\"Carregant dataset STS-ca...\")\n",
    "train_data = load_dataset(\"projecte-aina/sts-ca\", split=\"train\")\n",
    "test_data = load_dataset(\"projecte-aina/sts-ca\", split=\"test\") \n",
    "val_data = load_dataset(\"projecte-aina/sts-ca\", split=\"validation\")\n",
    "\n",
    "# Convertir a DataFrame per facilitar la manipulació\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "val_df = pd.DataFrame(val_data)\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Label range: {train_df['label'].min():.2f} - {train_df['label'].max():.2f}\")\n",
    "\n",
    "# Mostrar alguns exemples\n",
    "print(\"\\nExemples del dataset:\")\n",
    "for i in range(3):\n",
    "    print(f\"Frase 1: {train_df.iloc[i]['sentence_1']}\")\n",
    "    print(f\"Frase 2: {train_df.iloc[i]['sentence_2']}\")\n",
    "    print(f\"Similitud: {train_df.iloc[i]['label']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b9fbf3",
   "metadata": {},
   "source": [
    "## 3. Preparació d'Embeddings Word2Vec\n",
    "\n",
    "En aquesta secció, carreguem embeddings de paraules pre-entrenats. Utilitzarem el model Word2Vec `cc.ca.300.vec`, que conté vectors de 300 dimensions per a paraules en català.\n",
    "\n",
    "**Passos:**\n",
    "1.  **Càrrega del Model Word2Vec**: S'utilitza `KeyedVectors.load_word2vec_format` de la llibreria `gensim` per carregar els embeddings des d'un fitxer. S'especifica `binary=False` ja que el format `.vec` és textual.\n",
    "2.  **Informació del Model**: Es mostra el nombre de paraules en el vocabulari del model i la dimensió dels vectors d'embedding.\n",
    "3.  **Exemple d'Ús**: Es demostra com accedir al vector d'embedding d'una paraula específica i es mostren les primeres components del vector.\n",
    "4.  **Truncament d'Embeddings**: Es defineix la funció `create_truncated_embeddings` per generar versions dels embeddings amb dimensions més petites (50, 100, 150). Això permetrà experimentar com la dimensionalitat dels embeddings afecta el rendiment dels models. El truncament es fa simplement seleccionant les primeres `N` dimensions del vector original.\n",
    "5.  **Exemple d'Embeddings Truncats**: Es mostra com es veuen els embeddings truncats per a una paraula d'exemple.\n",
    "\n",
    "Aquesta preparació és crucial, ja que aquests embeddings serviran com a base per representar les frases en els primers models que desenvoluparem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Carregar el model Word2Vec pre-entrenat\n",
    "WV_MODEL_PATH = '../cc.ca.300.vec'\n",
    "\n",
    "print(\"Carregant model Word2Vec...\")\n",
    "\n",
    "kv_model = KeyedVectors.load_word2vec_format(WV_MODEL_PATH, binary=False)\n",
    "print(f\"Model carregat amb èxit. Vocabulari: {len(kv_model.key_to_index)} paraules\")\n",
    "print(f\"Dimensió dels vectors: {kv_model.vector_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ee480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'ús\n",
    "test_words = [\"casa\", \"gat\", \"aigua\", \"carbassot\"]\n",
    "for word in test_words:\n",
    "    if word in kv_model:\n",
    "        print(f\"Vector per '{word}': {kv_model[word][:5]}... (dim={kv_model.vector_size})\")\n",
    "    else:\n",
    "        print(f\"Paraula '{word}' no trobada al vocabulari\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funció per truncar embeddings a dimensions més petites\n",
    "def create_truncated_embeddings(kv_model, dimensions: List[int]) -> Dict[int, Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Crea versions truncades dels embeddings amb diferents dimensions\n",
    "    \"\"\"\n",
    "    if kv_model is None:\n",
    "        return {}\n",
    "    \n",
    "    truncated_models = {}\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        print(f\"Creant embeddings de {dim} dimensions...\")\n",
    "        truncated_dict = {}\n",
    "        \n",
    "        for word in kv_model.key_to_index:\n",
    "            original_vector = kv_model[word]\n",
    "            truncated_vector = original_vector[:dim]\n",
    "            truncated_dict[word] = truncated_vector\n",
    "            \n",
    "        truncated_models[dim] = truncated_dict\n",
    "        print(f\"  Completat: {len(truncated_dict)} paraules truncades a {dim}D\")\n",
    "    \n",
    "    return truncated_models\n",
    "\n",
    "# Crear versions truncades\n",
    "dimensions = [50, 100, 150, 300]  # Incloem 300 per consistència\n",
    "if kv_model is not None:\n",
    "    truncated_embeddings = create_truncated_embeddings(kv_model, dimensions)\n",
    "    print(f\"\\nVersions d'embeddings disponibles: {list(truncated_embeddings.keys())}\")\n",
    "else:\n",
    "    truncated_embeddings = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model truncat a 50 dimensions:\")\n",
    "print(truncated_embeddings[50]['casa'])\n",
    "print(\"Model truncat a 100 dimensions:\")\n",
    "print(truncated_embeddings[100]['casa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c549dd6",
   "metadata": {},
   "source": [
    "## 4. Funcions d'Utilitat per a Processament de Text\n",
    "\n",
    "Aquesta secció defineix funcions auxiliars clau per al processament de text i la generació d'embeddings de frases, que seran utilitzades pels diferents models.\n",
    "\n",
    "**Funcions Definides:**\n",
    "\n",
    "1.  `preprocess_sentence(sentence: str) -> List[str]`:\n",
    "    *   **Propòsit**: Realitza una tokenització bàsica de la frase.\n",
    "    *   **Funcionament**: Converteix la frase a minúscules i la divideix en paraules (tokens) utilitzant `simple_preprocess` de `gensim`.\n",
    "\n",
    "2.  `get_sentence_embedding_simple(sentence: str, embeddings_dict: Dict[str, np.ndarray], vector_size: int) -> np.ndarray`:\n",
    "    *   **Propòsit**: Calcula l'embedding d'una frase fent la mitjana dels embeddings de les seves paraules.\n",
    "    *   **Funcionament**:\n",
    "        1.  Preprocessa la frase utilitzant `preprocess_sentence`.\n",
    "        2.  Per a cada paraula, si existeix en el diccionari d'embeddings proporcionat (`embeddings_dict`), recupera el seu vector.\n",
    "        3.  Calcula la mitjana de tots els vectors de paraules trobats.\n",
    "        4.  Si cap paraula de la frase té un embedding, retorna un vector de zeros de la mida especificada (`vector_size`).\n",
    "\n",
    "3.  `get_sentence_embedding_tfidf(sentence: str, embeddings_dict: Dict[str, np.ndarray], tfidf_vectorizer: TfidfVectorizer, feature_names: List[str], vector_size: int) -> np.ndarray`:\n",
    "    *   **Propòsit**: Calcula l'embedding d'una frase fent una mitjana ponderada dels embeddings de les seves paraules, utilitzant els pesos TF-IDF.\n",
    "    *   **Funcionament**:\n",
    "        1.  Preprocessa la frase.\n",
    "        2.  Calcula el vector TF-IDF per a la frase.\n",
    "        3.  Per a cada paraula amb embedding i present en el vocabulari TF-IDF:\n",
    "            *   Obté el seu pes TF-IDF.\n",
    "            *   Multiplica l'embedding de la paraula pel seu pes TF-IDF.\n",
    "        4.  Calcula la suma ponderada dels vectors d'embedding i la divideix per la suma dels pesos.\n",
    "        5.  Si no es poden obtenir vectors ponderats, retorna un vector de zeros.\n",
    "\n",
    "**Preparació del Vocabulari per TF-IDF:**\n",
    "*   Es recullen totes les frases dels conjunts d'entrenament, validació i prova.\n",
    "*   Es preprocessen per extreure totes les paraules i construir un vocabulari global. Aquest vocabulari serà utilitzat per entrenar el `TfidfVectorizer` més endavant.\n",
    "\n",
    "Aquestes funcions són fonamentals per convertir el text en representacions numèriques que els models puguin processar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98123255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Preprocessa una frase: tokenització simple\n",
    "    \"\"\"\n",
    "    return simple_preprocess(sentence.lower())\n",
    "\n",
    "def get_sentence_embedding_simple(sentence: str, embeddings_dict: Dict[str, np.ndarray], \n",
    "                                vector_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Obté l'embedding d'una frase fent la mitjana dels embeddings de les paraules\n",
    "    \"\"\"\n",
    "    words = preprocess_sentence(sentence)\n",
    "    vectors = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in embeddings_dict:\n",
    "            vectors.append(embeddings_dict[word])\n",
    "    \n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "def get_sentence_embedding_tfidf(sentence: str, embeddings_dict: Dict[str, np.ndarray], \n",
    "                               tfidf_vectorizer: TfidfVectorizer, \n",
    "                               feature_names: List[str], vector_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Obté l'embedding d'una frase fent la mitjana ponderada amb TF-IDF\n",
    "    \"\"\"\n",
    "    words = preprocess_sentence(sentence)\n",
    "    \n",
    "    # Calcular TF-IDF per a la frase\n",
    "    tfidf_vector = tfidf_vectorizer.transform([' '.join(words)])\n",
    "    tfidf_scores = tfidf_vector.toarray()[0]\n",
    "    \n",
    "    weighted_vectors = []\n",
    "    weights = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in embeddings_dict and word in feature_names:\n",
    "            word_idx = feature_names.index(word)\n",
    "            weight = tfidf_scores[word_idx]\n",
    "            if weight > 0:\n",
    "                weighted_vectors.append(embeddings_dict[word] * weight)\n",
    "                weights.append(weight)\n",
    "    \n",
    "    if weighted_vectors and sum(weights) > 0:\n",
    "        return np.sum(weighted_vectors, axis=0) / sum(weights)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Preprocessar totes les frases del dataset\n",
    "print(\"Preprocessant frases del dataset...\")\n",
    "all_sentences = (train_df['sentence_1'].tolist() + train_df['sentence_2'].tolist() + \n",
    "                test_df['sentence_1'].tolist() + test_df['sentence_2'].tolist() + \n",
    "                val_df['sentence_1'].tolist() + val_df['sentence_2'].tolist())\n",
    "\n",
    "# Crear vocabulari per TF-IDF\n",
    "all_words = []\n",
    "for sentence in all_sentences:\n",
    "    all_words.extend(preprocess_sentence(sentence))\n",
    "\n",
    "print(f\"Total de frases processades: {len(all_sentences)}\")\n",
    "print(f\"Vocabulari únic: {len(set(all_words))} paraules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a3bd6d",
   "metadata": {},
   "source": [
    "## 5. Baseline: Similitud Cosinus\n",
    "\n",
    "Aquesta secció implementa i avalua un model baseline per a la tasca de STS. El baseline es basa en calcular la similitud cosinus entre els embeddings de les frases.\n",
    "\n",
    "**Funcionament:**\n",
    "\n",
    "1.  **`evaluate_cosine_baseline` Funció**:\n",
    "    *   **Entrada**: Un DataFrame amb parells de frases i les seves etiquetes de similitud, un diccionari d'embeddings de paraules, la mida del vector, i opcionalment, un vectoritzador TF-IDF.\n",
    "    *   **Procés**:\n",
    "        *   Per a cada parell de frases:\n",
    "            *   Obté l'embedding de cada frase utilitzant `get_sentence_embedding_simple` (mitjana simple) o `get_sentence_embedding_tfidf` (mitjana ponderada amb TF-IDF).\n",
    "            *   Calcula la similitud cosinus entre els dos vectors de frase. La similitud cosinus varia entre -1 (totalment oposats) i 1 (idèntics). Si algun vector és zero, la similitud es considera 0.\n",
    "            *   Escala la similitud cosinus (originalment en `[-1, 1]`) a l'interval `[0, 5]` per coincidir amb el rang de les etiquetes del dataset STS-ca, mitjançant la fórmula `(sim + 1) * 2.5`.\n",
    "    *   **Sortida**: Un diccionari amb les mètriques d'avaluació:\n",
    "        *   `pearson`: Correlació de Pearson entre les similituds predites i les reals. És la mètrica principal per a STS.\n",
    "        *   `mse`: Error Quadràtic Mig (Mean Squared Error).\n",
    "        *   `mae`: Error Absolut Mig (Mean Absolute Error).\n",
    "        *   `predictions`: Les similituds predites.\n",
    "\n",
    "2.  **Preparació del Vectoritzador TF-IDF**:\n",
    "    *   S'utilitza `TfidfVectorizer` de `sklearn` per calcular els pesos TF-IDF.\n",
    "    *   S'entrena (`fit`) amb un corpus format per totes les frases preprocessades del dataset.\n",
    "    *   Es limita el nombre de característiques (paraules) a `max_features=10000`.\n",
    "\n",
    "3.  **Avaluació dels Baselines**:\n",
    "    *   S'avalua el baseline en el conjunt de validació (`val_df`).\n",
    "    *   Es fa per a cada dimensió d'embedding truncada (50, 100, 150, 300).\n",
    "    *   Per a cada dimensió, s'avaluen dues variants:\n",
    "        *   Utilitzant la mitjana simple d'embeddings de paraules.\n",
    "        *   Utilitzant la mitjana ponderada amb TF-IDF.\n",
    "    *   Els resultats (Pearson, MSE, MAE) es guarden per a la seva posterior comparació.\n",
    "\n",
    "L'objectiu d'aquest baseline és establir un punt de referència. Models més sofisticats haurien de superar aquests resultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b87af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cosine_baseline(df: pd.DataFrame, embeddings_dict: Dict[str, np.ndarray], \n",
    "                           vector_size: int, use_tfidf: bool = False, \n",
    "                           tfidf_vectorizer=None, feature_names=None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Avalua el baseline de similitud cosinus\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    true_scores = df['label'].values\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        sent1, sent2 = row['sentence_1'], row['sentence_2']\n",
    "        \n",
    "        if use_tfidf and tfidf_vectorizer is not None:\n",
    "            vec1 = get_sentence_embedding_tfidf(sent1, embeddings_dict, tfidf_vectorizer, \n",
    "                                              feature_names, vector_size)\n",
    "            vec2 = get_sentence_embedding_tfidf(sent2, embeddings_dict, tfidf_vectorizer, \n",
    "                                              feature_names, vector_size)\n",
    "        else:\n",
    "            vec1 = get_sentence_embedding_simple(sent1, embeddings_dict, vector_size)\n",
    "            vec2 = get_sentence_embedding_simple(sent2, embeddings_dict, vector_size)\n",
    "        \n",
    "        # Calcular similitud cosinus\n",
    "        if np.all(vec1 == 0) or np.all(vec2 == 0):\n",
    "            sim = 0.0\n",
    "        else:\n",
    "            sim = 1 - cosine(vec1, vec2)\n",
    "        \n",
    "        # Escalar de [-1,1] a [0,5] per coincidir amb les etiquetes\n",
    "        sim_scaled = (sim + 1) * 2.5\n",
    "        similarities.append(sim_scaled)\n",
    "    \n",
    "    # Calcular mètriques\n",
    "    similarities = np.array(similarities)\n",
    "    pearson_corr, _ = pearsonr(true_scores, similarities)\n",
    "    mse = mean_squared_error(true_scores, similarities)\n",
    "    mae = mean_absolute_error(true_scores, similarities)\n",
    "    \n",
    "    return {\n",
    "        'pearson': pearson_corr,\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'predictions': similarities\n",
    "    }\n",
    "\n",
    "# Preparar TF-IDF\n",
    "if kv_model is not None:\n",
    "    print(\"Preparant TF-IDF vectorizer...\")\n",
    "    corpus_for_tfidf = [' '.join(preprocess_sentence(sent)) for sent in all_sentences]\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=10000, lowercase=True)\n",
    "    tfidf_vectorizer.fit(corpus_for_tfidf)\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out().tolist()\n",
    "    \n",
    "    print(\"Avaluant baselines de similitud cosinus...\")\n",
    "    \n",
    "    # Avaluar per diferents dimensions\n",
    "    baseline_results = {}\n",
    "    results_list = []\n",
    "    for dim in [50, 100, 150, 300]:\n",
    "        if dim in truncated_embeddings:\n",
    "            # Mitjana simple\n",
    "            results_simple = evaluate_cosine_baseline(\n",
    "                val_df, truncated_embeddings[dim], dim, use_tfidf=False\n",
    "            )\n",
    "\n",
    "            # Mitjana ponderada TF-IDF\n",
    "            results_tfidf = evaluate_cosine_baseline(\n",
    "                val_df, truncated_embeddings[dim], dim, use_tfidf=True,\n",
    "                tfidf_vectorizer=tfidf_vectorizer, feature_names=feature_names\n",
    "            )\n",
    "\n",
    "            baseline_results[dim] = {\n",
    "                'simple': results_simple,\n",
    "                'tfidf': results_tfidf\n",
    "            }\n",
    "\n",
    "            results_list.append({\n",
    "                'Model': 'Baseline Cosinus Simple',\n",
    "                'Dimensions': f'{dim}D',\n",
    "                'Pearson': results_simple['pearson'],\n",
    "                'MSE': results_simple['mse'],\n",
    "                'MAE': results_simple['mae']\n",
    "            })\n",
    "            results_list.append({\n",
    "                'Model': 'Baseline Cosinus TF-IDF',\n",
    "                'Dimensions': f'{dim}D',\n",
    "                'Pearson': results_tfidf['pearson'],\n",
    "                'MSE': results_tfidf['mse'],\n",
    "                'MAE': results_tfidf['mae']\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b761f",
   "metadata": {},
   "source": [
    "**Anàlisi dels Resultats del Baseline Cosinus**\n",
    "\n",
    "La taula següent mostra els resultats dels models baseline de similitud cosinus, tant amb mitjana simple d'embeddings com amb mitjana ponderada per TF-IDF, per a diferents dimensions dels embeddings Word2Vec.\n",
    "\n",
    "**Observacions Clau:**\n",
    "*   **Impacte de TF-IDF**: Generalment, l'ús de TF-IDF per ponderar els embeddings de paraules tendeix a millorar la correlació de Pearson en comparació amb la mitjana simple. Això suggereix que donar més importància a paraules més discriminatives (segons TF-IDF) és beneficiós.\n",
    "*   **Impacte de la Dimensió**: S'observa una tendència a millorar el rendiment (major Pearson, menor MSE/MAE) a mesura que augmenta la dimensió dels embeddings, tot i que els guanys poden disminuir a partir d'una certa dimensió. Els embeddings de 300D solen oferir els millors resultats dins d'aquest baseline.\n",
    "*   **Correlació de Pearson**: Aquesta és la mètrica principal. Valors més alts indiquen una millor concordança entre les prediccions del model i les etiquetes humanes.\n",
    "*   **MSE i MAE**: Mesuren l'error de predicció. Valors més baixos són millors.\n",
    "\n",
    "Aquests resultats serveixen com a punt de partida per avaluar la millora aportada pels models neuronals més complexos que es desenvoluparan a continuació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== COMPARACIÓ MODELS BASELINE COSINUS ===\")\n",
    "df_baseline_results = pd.DataFrame(results_list)\n",
    "display(df_baseline_results.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea51846a",
   "metadata": {},
   "source": [
    "## 6. Model 1: Regressió amb Embeddings Agregats\n",
    "\n",
    "Aquesta secció desenvolupa un model de xarxa neuronal per a la tasca de regressió de STS. El model pren com a entrada els embeddings de les dues frases (obtinguts mitjançant mitjana simple dels embeddings de paraules) i aprèn a predir la seva similitud.\n",
    "\n",
    "**Components Clau:**\n",
    "\n",
    "1.  **`build_model_aggregated` Funció**:\n",
    "    *   **Arquitectura del Model**:\n",
    "        *   **Entrades**: Dos vectors d'entrada, un per a l'embedding de cada frase (`input_vector_1`, `input_vector_2`). La dimensió d'aquests vectors (`embedding_dim`) correspon a la dimensió dels embeddings de frase utilitzats.\n",
    "        *   **Concatenació**: Els dos vectors d'entrada es concatenen per formar un únic vector que representa el parell de frases.\n",
    "        *   **Capes de Processament**:\n",
    "            *   `BatchNormalization`: Normalitza les activacions de la capa anterior, ajudant a estabilitzar i accelerar l'entrenament.\n",
    "            *   `Dense`: Capes totalment connectades amb funcions d'activació ReLU. S'utilitzen per aprendre transformacions no lineals de les dades.\n",
    "            *   `Dropout`: Tècnica de regularització que desactiva aleatòriament un percentatge de neurones durant l'entrenament per prevenir el sobreajustament (overfitting).\n",
    "        *   **Capa de Sortida**: Una única neurona `Dense` amb activació lineal, ja que es tracta d'un problema de regressió (predir un valor continu entre 0 i 5).\n",
    "    *   **Compilació del Model**:\n",
    "        *   `loss`: `mean_squared_error` (Error Quadràtic Mig), una funció de pèrdua comuna per a problemes de regressió.\n",
    "        *   `optimizer`: `Adam`, un optimitzador popular i eficient. S'estableix una taxa d'aprenentatge inicial.\n",
    "        *   `metrics`: `mae` (Error Absolut Mig) i `RootMeanSquaredError` per monitorar el rendiment durant l'entrenament i l'avaluació.\n",
    "\n",
    "2.  **`prepare_aggregated_data` Funció**:\n",
    "    *   **Propòsit**: Prepara les dades d'entrada i sortida per al model.\n",
    "    *   **Funcionament**:\n",
    "        *   Itera sobre el DataFrame proporcionat.\n",
    "        *   Per a cada parell de frases, obté els seus embeddings (utilitzant `get_sentence_embedding_simple` o `get_sentence_embedding_tfidf`).\n",
    "        *   Emmagatzema els embeddings de la primera frase a `X1`, els de la segona a `X2`, i les etiquetes de similitud a `Y`.\n",
    "        *   Retorna `X1`, `X2`, i `Y` com a arrays NumPy.\n",
    "\n",
    "3.  **Entrenament i Avaluació del Model**:\n",
    "    *   S'itera sobre les diferents dimensions d'embeddings (50, 100, 150, 300).\n",
    "    *   Per a cada dimensió:\n",
    "        *   Es preparen les dades d'entrenament i validació utilitzant `prepare_aggregated_data`.\n",
    "        *   Es construeix el model utilitzant `build_model_aggregated`.\n",
    "        *   **Callbacks**:\n",
    "            *   `EarlyStopping`: Atura l'entrenament si la pèrdua en el conjunt de validació (`val_loss`) no millora durant un nombre determinat d'èpoques (`patience`), restaurant els pesos del millor model.\n",
    "            *   `ReduceLROnPlateau`: Redueix la taxa d'aprenentatge si la `val_loss` s'estanca.\n",
    "        *   S'entrena el model (`model.fit`) amb les dades d'entrenament, validant en cada època amb les dades de validació.\n",
    "        *   Després de l'entrenament, es prediuen les similituds per al conjunt de validació.\n",
    "        *   Es calculen les mètriques (Pearson, MSE, MAE) comparant les prediccions amb els valors reals.\n",
    "        *   Els resultats i el model entrenat es guarden.\n",
    "\n",
    "Aquest model representa un pas més enllà dels baselines, ja que la xarxa neuronal pot aprendre relacions més complexes entre els embeddings de les frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84750f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_aggregated(embedding_dim: int, hidden_size: int = 128, \n",
    "                         dropout_rate: float = 0.3) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Construeix el model de regressió amb embeddings agregats\n",
    "    \"\"\"\n",
    "    input_1 = tf.keras.Input(shape=(embedding_dim,), name=\"input_vector_1\")\n",
    "    input_2 = tf.keras.Input(shape=(embedding_dim,), name=\"input_vector_2\")\n",
    "    \n",
    "    # Concatenar els dos vectors\n",
    "    concatenated = tf.keras.layers.Concatenate(axis=-1)([input_1, input_2])\n",
    "    \n",
    "    # Capes de processament\n",
    "    x = tf.keras.layers.BatchNormalization()(concatenated)\n",
    "    x = tf.keras.layers.Dense(hidden_size, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(hidden_size // 2, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Capa de sortida (regressió)\n",
    "    output = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['mae', tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def prepare_aggregated_data(df: pd.DataFrame, embeddings_dict: Dict[str, np.ndarray], \n",
    "                          vector_size: int, use_tfidf: bool = False,\n",
    "                          tfidf_vectorizer=None, feature_names=None) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Prepara les dades per al model d'embeddings agregats\n",
    "    \"\"\"\n",
    "    X1, X2, Y = [], [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        sent1, sent2, label = row['sentence_1'], row['sentence_2'], row['label']\n",
    "        \n",
    "        if use_tfidf and tfidf_vectorizer is not None:\n",
    "            vec1 = get_sentence_embedding_tfidf(sent1, embeddings_dict, tfidf_vectorizer, \n",
    "                                              feature_names, vector_size)\n",
    "            vec2 = get_sentence_embedding_tfidf(sent2, embeddings_dict, tfidf_vectorizer, \n",
    "                                              feature_names, vector_size)\n",
    "        else:\n",
    "            vec1 = get_sentence_embedding_simple(sent1, embeddings_dict, vector_size)\n",
    "            vec2 = get_sentence_embedding_simple(sent2, embeddings_dict, vector_size)\n",
    "        \n",
    "        X1.append(vec1)\n",
    "        X2.append(vec2)\n",
    "        Y.append(label)\n",
    "    \n",
    "    return np.array(X1), np.array(X2), np.array(Y)\n",
    "\n",
    "# Entrenar models agregats per diferents dimensions\n",
    "if kv_model is not None:\n",
    "    aggregated_results = {}\n",
    "    \n",
    "    for dim in [50, 100, 150, 300]:\n",
    "        if dim in truncated_embeddings:\n",
    "            print(f\"\\n=== Entrenant Model Agregat {dim}D ===\")\n",
    "            \n",
    "            # Preparar dades\n",
    "            X1_train, X2_train, Y_train = prepare_aggregated_data(\n",
    "                train_df, truncated_embeddings[dim], dim\n",
    "            )\n",
    "            X1_val, X2_val, Y_val = prepare_aggregated_data(\n",
    "                val_df, truncated_embeddings[dim], dim\n",
    "            )\n",
    "            \n",
    "            print(f\"Forma de les dades: X1_train={X1_train.shape}, Y_train={Y_train.shape}\")\n",
    "            \n",
    "            # Construir i entrenar model\n",
    "            model = build_model_aggregated(embedding_dim=dim)\n",
    "            \n",
    "            # Callbacks\n",
    "            early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss', patience=10, restore_best_weights=True, verbose=1\n",
    "            )\n",
    "            \n",
    "            reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1\n",
    "            )\n",
    "            \n",
    "            # Entrenament\n",
    "            history = model.fit(\n",
    "                [X1_train, X2_train], Y_train,\n",
    "                validation_data=([X1_val, X2_val], Y_val),\n",
    "                epochs=50,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stopping, reduce_lr],\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # Avaluació\n",
    "            Y_pred = model.predict([X1_val, X2_val]).flatten()\n",
    "            pearson_corr, _ = pearsonr(Y_val, Y_pred)\n",
    "            mse = mean_squared_error(Y_val, Y_pred)\n",
    "            mae = mean_absolute_error(Y_val, Y_pred)\n",
    "            \n",
    "            aggregated_results[dim] = {\n",
    "                'model': model,\n",
    "                'history': history,\n",
    "                'pearson': pearson_corr,\n",
    "                'mse': mse,\n",
    "                'mae': mae,\n",
    "                'predictions': Y_pred\n",
    "            }\n",
    "            \n",
    "            print(f\"Resultats {dim}D - Pearson: {pearson_corr:.3f}, MSE: {mse:.3f}, MAE: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cbc4ce",
   "metadata": {},
   "source": [
    "**Anàlisi dels Resultats del Model d'Embeddings Agregats**\n",
    "\n",
    "La taula següent resumeix el rendiment del model de regressió amb embeddings agregats per a les diferents dimensions d'embeddings utilitzades.\n",
    "\n",
    "**Observacions Clau:**\n",
    "*   **Millora sobre Baselines**: S'espera que aquest model neuronal superi els resultats dels baselines de similitud cosinus, especialment en termes de correlació de Pearson. La capacitat d'aprenentatge de la xarxa hauria de capturar relacions més complexes que una simple similitud cosinus.\n",
    "*   **Impacte de la Dimensió**: Similar als baselines, és probable que dimensions més altes dels embeddings (fins a un cert punt) portin a millors resultats, ja que contenen més informació semàntica.\n",
    "*   **Mètriques**:\n",
    "    *   `Pearson`: Valors més alts indiquen un millor rendiment.\n",
    "    *   `MSE` i `MAE`: Valors més baixos són preferibles.\n",
    "*   **Comparació**: Aquests resultats es compararan amb els del Model 2 (amb atenció) i altres models més avançats per determinar l'eficàcia relativa d'aquesta arquitectura.\n",
    "\n",
    "La taula `df_aggregated` mostra una visió clara de com la dimensionalitat afecta el rendiment d'aquest model específic. Aquests resultats s'afegiran a `df_results` per a una comparació global posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8817681",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== COMPARACIÓ MODELS AGREGATS ===\")\n",
    "# Crear un DataFrame amb els resultats dels models agregats\n",
    "aggr_data = []\n",
    "for dim in [50, 100, 150, 300]:\n",
    "    if dim in aggregated_results:\n",
    "        aggr_data.append({\n",
    "            'Model': 'Model Agregat',\n",
    "            'Dimensions': f'{dim}D',\n",
    "            'Pearson': aggregated_results[dim]['pearson'],\n",
    "            'MSE': aggregated_results[dim]['mse'],\n",
    "            'MAE': aggregated_results[dim]['mae']\n",
    "        })\n",
    "\n",
    "df_aggregated = pd.DataFrame(aggr_data)\n",
    "df_results = pd.concat([df_baseline_results, df_aggregated], ignore_index=True)\n",
    "display(df_aggregated.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d313a2a",
   "metadata": {},
   "source": [
    "## 7. Model 2: Seqüència d'Embeddings amb Atenció\n",
    "\n",
    "Aquesta secció introdueix un model més sofisticat que processa les frases com a seqüències d'embeddings de paraules i utilitza un mecanisme d'atenció per ponderar la importància de cada paraula en la representació de la frase. Aquest enfocament pot capturar millor les nuances semàntiques que la simple mitjana d'embeddings.\n",
    "\n",
    "**Components Clau:**\n",
    "\n",
    "1.  **`SimpleAttention` Capa Personalitzada**:\n",
    "    *   **Propòsit**: Implementa un mecanisme d'atenció simple. Donada una seqüència d'embeddings de paraules, calcula un vector de context que representa la frase, ponderant cada paraula segons la seva rellevància.\n",
    "    *   **Funcionament**:\n",
    "        1.  Transforma els embeddings d'entrada (`inputs`) mitjançant una capa densa (`W_s1`) amb activació `tanh` per obtenir estats ocults.\n",
    "        2.  Calcula puntuacions d'atenció (`scores`) per a cada estat ocult utilitzant una altra capa densa (`W_s2`).\n",
    "        3.  Si s'aplica màscara (`mask`, per ignorar posicions de padding), s'ajusten les puntuacions.\n",
    "        4.  Normalitza les puntuacions utilitzant `softmax` per obtenir els pesos d'atenció (`attention_weights`).\n",
    "        5.  Calcula el vector de context (`context_vector`) com una suma ponderada dels embeddings d'entrada originals, utilitzant els pesos d'atenció.\n",
    "    *   **Suport de Màscara**: La capa indica que suporta màscares (`supports_masking = True`), la qual cosa és important quan es treballa amb seqüències de longitud variable i padding.\n",
    "\n",
    "2.  **`build_model_sequence` Funció**:\n",
    "    *   **Arquitectura del Model (Siamesa Modificada)**:\n",
    "        *   **Entrades**: Dues seqüències d'enters (`input_1`, `input_2`), on cada enter representa l'índex d'una paraula en un vocabulari. La longitud de les seqüències és fixa (`sequence_length`).\n",
    "        *   **Capa d'Embedding Compartida (`embedding_layer`)**:\n",
    "            *   Converteix les seqüències d'índexs en seqüències de vectors densos (embeddings).\n",
    "            *   Pot utilitzar embeddings pre-entrenats (`pretrained_weights`) o aprendre'ls des de zero.\n",
    "            *   Pot ser entrenable (`trainable_embeddings=True`) o congelada (`trainable_embeddings=False`).\n",
    "            *   `mask_zero=True`: Indica que l'índex 0 (reservat per al padding) s'ha d'ignorar en les capes posteriors que suporten màscares.\n",
    "        *   **Processament de Seqüències (Compartit)**:\n",
    "            *   Si `use_attention=True`, s'aplica la capa `SimpleAttention` a les seqüències d'embeddings per obtenir un vector de frase per a cada entrada.\n",
    "            *   Si `use_attention=False`, s'utilitza `GlobalAveragePooling1D` com a alternativa més simple per agregar els embeddings de paraules.\n",
    "        *   **Capa de Projecció (`first_projection_layer`)**: Una capa densa amb activació `tanh` aplicada als vectors de frase. Això pot ajudar a refinar les representacions. S'aplica dropout.\n",
    "        *   **Normalització L2**: Els vectors projectats es normalitzen (L2) per assegurar que tinguin una magnitud unitària. Això és comú en models que utilitzen similitud cosinus.\n",
    "        *   **Càlcul de Similitud Cosinus**: Es calcula la similitud cosinus entre els dos vectors de frase normalitzats. Això es fa multiplicant element a element i sumant (`tf.reduce_sum(x[0] * x[1], axis=1)`).\n",
    "        *   **Capa de Sortida (`output_layer`)**: Transforma la similitud cosinus (originalment en `[-1, 1]`) a l'interval `[0, 1]` utilitzant `0.5 * (1.0 + x)`. *Nota: Per al dataset STS-ca, que té etiquetes de 0 a 5, aquesta sortida [0,1] haurà de ser escalada posteriorment si es vol comparar directament, o la funció de pèrdua haurà de tenir en compte les etiquetes originals escalades a [0,1]. El codi actual compila amb 'mean_squared_error', assumint que les etiquetes Y_train_seq ja estan en l'escala [0,1] o que la pèrdua s'interpreta en aquest rang.*\n",
    "    *   **Compilació**: Similar al model agregat, utilitzant `mean_squared_error` i `Adam`.\n",
    "\n",
    "Aquest model té el potencial de ser més potent que el model agregat, ja que considera l'ordre de les paraules i pot aprendre a enfocar-se en les parts més importants de cada frase gràcies a l'atenció."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "class SimpleAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Capa d'atenció simple per agregar seqüències d'embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, units: int, **kwargs):\n",
    "        super(SimpleAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.dropout_s1 = tf.keras.layers.Dropout(0.3)\n",
    "        self.dropout_s2 = tf.keras.layers.Dropout(0.2)\n",
    "        self.W_s1 = tf.keras.layers.Dense(units, activation='tanh', use_bias=True, name=\"attention_transform\")\n",
    "        # Dense layer to compute attention scores (context vector)\n",
    "        self.W_s2 = tf.keras.layers.Dense(1, use_bias=False, name=\"attention_scorer\")\n",
    "        self.supports_masking = True  # Declare that this layer supports masking\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
    "        # inputs shape: (batch_size, sequence_length, embedding_dim)\n",
    "        # mask shape: (batch_size, sequence_length) boolean tensor\n",
    "\n",
    "        # Attention hidden states\n",
    "        hidden_states = self.dropout_s1(self.W_s1(inputs))\n",
    "\n",
    "        # Compute attention scores\n",
    "        scores = self.dropout_s2(self.W_s2(hidden_states))\n",
    "\n",
    "        if mask is not None:\n",
    "            # Apply the mask to the scores before softmax\n",
    "            expanded_mask = tf.expand_dims(tf.cast(mask, dtype=tf.float32), axis=-1)\n",
    "            # Add a large negative number to masked (padded) scores\n",
    "            scores += (1.0 - expanded_mask) * -1e9\n",
    "\n",
    "        # Compute attention weights\n",
    "        attention_weights = tf.nn.softmax(scores, axis=1)\n",
    "\n",
    "        # Compute the context vector (weighted sum of input embeddings)\n",
    "        context_vector = tf.reduce_sum(inputs * attention_weights, axis=1)\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        config = super(SimpleAttention, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "\n",
    "    def compute_mask(self, inputs: tf.Tensor, mask: Optional[tf.Tensor] = None) -> Optional[tf.Tensor]:\n",
    "        return None\n",
    "\n",
    "\n",
    "def build_model_sequence(vocab_size: int = 1000, \n",
    "                        embedding_dim: int = 300,\n",
    "                        sequence_length: int = 32,\n",
    "                        learning_rate: float = 0.001,\n",
    "                        trainable_embeddings: bool = False,\n",
    "                        pretrained_weights: Optional[np.ndarray] = None,\n",
    "                        use_attention: bool = True,\n",
    "                        attention_units: int = 4) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Model de seqüència millorat basat en build_and_compile_model_2\n",
    "    Incorpora similitud cosinus i escalat adequat per STS\n",
    "    \"\"\"\n",
    "    input_1 = tf.keras.Input((sequence_length,), dtype=tf.int32, name=\"input_1\")\n",
    "    input_2 = tf.keras.Input((sequence_length,), dtype=tf.int32, name=\"input_2\")\n",
    "\n",
    "    # Determine effective embedding parameters\n",
    "    if pretrained_weights is not None:\n",
    "        effective_dictionary_size = pretrained_weights.shape[0]\n",
    "        effective_embedding_size = pretrained_weights.shape[1]\n",
    "        embedding_initializer = tf.keras.initializers.Constant(pretrained_weights)\n",
    "        is_embedding_trainable = trainable_embeddings\n",
    "        embedding_layer_name = \"embedding_pretrained\"\n",
    "    else:\n",
    "        effective_dictionary_size = vocab_size\n",
    "        effective_embedding_size = embedding_dim\n",
    "        embedding_initializer = 'uniform'\n",
    "        is_embedding_trainable = True\n",
    "        embedding_layer_name = \"embedding\"\n",
    "\n",
    "    # Shared Embedding Layer\n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        input_dim=effective_dictionary_size,\n",
    "        output_dim=effective_embedding_size,\n",
    "        input_length=sequence_length,\n",
    "        mask_zero=True,\n",
    "        embeddings_initializer=embedding_initializer,\n",
    "        trainable=is_embedding_trainable,\n",
    "        name=embedding_layer_name\n",
    "    )\n",
    "\n",
    "    # Apply embedding layer to both inputs\n",
    "    embedded_1 = embedding_layer(input_1)  # Shape: (batch_size, sequence_length, effective_embedding_size)\n",
    "    embedded_2 = embedding_layer(input_2)  # Shape: (batch_size, sequence_length, effective_embedding_size)\n",
    "\n",
    "    # Shared pooling/attention layer\n",
    "    if use_attention:\n",
    "        # Use attention mechanism\n",
    "        sentence_pooling_layer = SimpleAttention(units=attention_units, name=\"sentence_attention\")\n",
    "    else:\n",
    "        # Use simple global average pooling\n",
    "        sentence_pooling_layer = tf.keras.layers.GlobalAveragePooling1D(name=\"sentence_attention_layer\")\n",
    "\n",
    "    # Apply pooling/attention to get sentence vectors\n",
    "    sentence_vector_1 = sentence_pooling_layer(embedded_1)\n",
    "    sentence_vector_2 = sentence_pooling_layer(embedded_2)\n",
    "\n",
    "    # Projection layer\n",
    "    first_projection_layer = tf.keras.layers.Dense(\n",
    "        effective_embedding_size,\n",
    "        activation='tanh',\n",
    "        kernel_initializer=tf.keras.initializers.Identity(),\n",
    "        bias_initializer=tf.keras.initializers.Zeros(),\n",
    "        name=\"projection_layer\"\n",
    "    )\n",
    "    dropout = tf.keras.layers.Dropout(0.2, name=\"projection_dropout\")\n",
    "    projected_1 = dropout(first_projection_layer(sentence_vector_1))\n",
    "    projected_2 = dropout(first_projection_layer(sentence_vector_2))\n",
    "\n",
    "    # Normalize the projected vectors (L2 normalization)\n",
    "    normalized_1 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_1\"\n",
    "    )(projected_1)\n",
    "    normalized_2 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_2\"\n",
    "    )(projected_2)\n",
    "\n",
    "    # Compute Cosine Similarity\n",
    "    similarity_score = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"cosine_similarity\"\n",
    "    )([normalized_1, normalized_2])\n",
    "\n",
    "    # Scale similarity from [-1, 1] to [0, 1]\n",
    "    output_layer = tf.keras.layers.Lambda(\n",
    "        lambda x: 0.5 * (1.0 + x), name=\"output_scaling\"\n",
    "    )(similarity_score)\n",
    "\n",
    "    # Define the Keras Model\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_1, input_2],\n",
    "        outputs=output_layer,\n",
    "        name=\"sequence_similarity_attention_model\"\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics=['mae'],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02007979",
   "metadata": {},
   "source": [
    "**Preparació de Dades per al Model de Seqüències**\n",
    "\n",
    "Per alimentar el model de seqüències, necessitem transformar les frases de text en un format numèric adequat. Això implica diversos passos:\n",
    "\n",
    "1.  **`create_vocabulary_mapping` Funció**:\n",
    "    *   **Propòsit**: Crea un vocabulari a partir de totes les frases del dataset i assigna un índex enter únic a cada paraula.\n",
    "    *   **Funcionament**:\n",
    "        1.  Compta la freqüència de cada paraula en el corpus (després de preprocessar les frases).\n",
    "        2.  Ordena les paraules per freqüència de manera descendent.\n",
    "        3.  Crea dos diccionaris:\n",
    "            *   `word_to_idx`: Mapa cada paraula al seu índex.\n",
    "            *   `idx_to_word`: Mapa cada índex a la seva paraula.\n",
    "        4.  Reserva índexs especials: `0` per a `<PAD>` (padding) i `1` per a `<UNK>` (paraula desconeguda).\n",
    "        5.  Limita la mida del vocabulari a `max_vocab_size`. Les paraules menys freqüents es tractaran com `<UNK>`.\n",
    "\n",
    "2.  **`sentence_to_sequence` Funció**:\n",
    "    *   **Propòsit**: Converteix una frase de text en una seqüència d'índexs de paraules, assegurant que totes les seqüències tinguin una longitud fixa.\n",
    "    *   **Funcionament**:\n",
    "        1.  Preprocessa la frase.\n",
    "        2.  Per a cada paraula, busca el seu índex en `word_to_idx`. Si la paraula no hi és, utilitza l'índex de `<UNK>`.\n",
    "        3.  **Padding/Truncament**:\n",
    "            *   Si la seqüència resultant és més llarga que `max_length`, es trunca.\n",
    "            *   Si és més curta, s'afegeixen índexs de `<PAD>` (valor 0) al final fins a assolir `max_length`.\n",
    "\n",
    "3.  **`create_pretrained_embedding_matrix` Funció**:\n",
    "    *   **Propòsit**: Crea una matriu de pesos per a la capa d'embedding del model de seqüències, inicialitzant-la amb vectors d'embeddings pre-entrenats (com Word2Vec).\n",
    "    *   **Funcionament**:\n",
    "        1.  Crea una matriu de zeros amb dimensions `(vocab_size, embedding_dim)`.\n",
    "        2.  Per a cada paraula i el seu índex en `word_to_idx`:\n",
    "            *   Si la paraula existeix en el diccionari d'embeddings pre-entrenats (`embeddings_dict`), copia el seu vector a la fila corresponent de la matriu d'embedding.\n",
    "            *   Les paraules no trobades (incloent `<PAD>` i `<UNK>` si no tenen embeddings predefinits) mantindran vectors de zeros o els que s'hagin assignat aleatòriament si la capa d'embedding és entrenable.\n",
    "\n",
    "Aquestes funcions permeten transformar les dades textuals en tensors numèrics que el model de Keras pot processar, alhora que permeten incorporar coneixement previ mitjançant els embeddings pre-entrenats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e38d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Preparació de dades per al model de seqüències\n",
    "def create_vocabulary_mapping(sentences: List[str], max_vocab_size: int = 10000) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    \"\"\"\n",
    "    Crea un mapatge de vocabulari paraula->índex i índex->paraula\n",
    "    \"\"\"\n",
    "    word_counts = {}\n",
    "    for sentence in sentences:\n",
    "        words = preprocess_sentence(sentence)\n",
    "        for word in words:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    \n",
    "    # Ordenar per freqüència i prendre les més comunes\n",
    "    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Reservar índexs especials: 0=PAD, 1=UNK\n",
    "    word_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "    idx_to_word = {0: \"<PAD>\", 1: \"<UNK>\"}\n",
    "    \n",
    "    for word, count in sorted_words[:max_vocab_size-2]:  # -2 per PAD i UNK\n",
    "        idx = len(word_to_idx)\n",
    "        word_to_idx[word] = idx\n",
    "        idx_to_word[idx] = word\n",
    "    \n",
    "    return word_to_idx, idx_to_word\n",
    "\n",
    "def sentence_to_sequence(sentence: str, word_to_idx: Dict[str, int], \n",
    "                        max_length: int = 32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converteix una frase a seqüència d'índexs\n",
    "    \"\"\"\n",
    "    words = preprocess_sentence(sentence)\n",
    "    sequence = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in word_to_idx:\n",
    "            sequence.append(word_to_idx[word])\n",
    "        else:\n",
    "            sequence.append(word_to_idx[\"<UNK>\"])\n",
    "    \n",
    "    # Padding o truncament\n",
    "    if len(sequence) > max_length:\n",
    "        sequence = sequence[:max_length]\n",
    "    else:\n",
    "        sequence.extend([word_to_idx[\"<PAD>\"]] * (max_length - len(sequence)))\n",
    "    \n",
    "    return np.array(sequence)\n",
    "\n",
    "def create_pretrained_embedding_matrix(word_to_idx: Dict[str, int], \n",
    "                                     embeddings_dict: Dict[str, np.ndarray],\n",
    "                                     embedding_dim: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Crea una matriu d'embeddings pre-entrenats\n",
    "    \"\"\"\n",
    "    vocab_size = len(word_to_idx)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    \n",
    "    for word, idx in word_to_idx.items():\n",
    "        if word in embeddings_dict:\n",
    "            embedding_matrix[idx] = embeddings_dict[word]\n",
    "        # Les paraules no trobades mantenen vectors zero\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc983182",
   "metadata": {},
   "source": [
    "**Entrenament i Avaluació dels Models de Seqüència**\n",
    "\n",
    "Un cop definides les funcions de preparació de dades i l'arquitectura del model de seqüències, procedim a entrenar-lo i avaluar-lo.\n",
    "\n",
    "**Passos del Procés:**\n",
    "\n",
    "1.  **Creació del Vocabulari Global**:\n",
    "    *   S'utilitza `create_vocabulary_mapping` amb totes les frases del dataset (`all_sentences`) per construir `word_to_idx` i `idx_to_word`. Es defineix una mida màxima de vocabulari (`max_vocab_size`) i una longitud de seqüència (`sequence_length`).\n",
    "\n",
    "2.  **Preparació de Dades de Seqüència**:\n",
    "    *   La funció `prepare_sequence_data` converteix els DataFrames d'entrenament i validació en seqüències d'índexs (`X1_train_seq`, `X2_train_seq`, `X1_val_seq`, `X2_val_seq`) i les etiquetes corresponents (`Y_train_seq`, `Y_val_seq`).\n",
    "    *   **Important**: Les etiquetes `Y_train_seq` i `Y_val_seq` s'utilitzen directament. Com que el model de seqüència produeix una sortida en el rang `[0, 1]` (degut a `0.5 * (1 + cosine_similarity)`), les etiquetes originals del dataset STS-ca (rang `[0, 5]`) s'haurien d'escalar a `[0, 1]` abans de l'entrenament per a una comparació directa amb la sortida del model i un càlcul correcte de la pèrdua. Si no es fa, la pèrdua `mean_squared_error` es calcularà entre valors en escales diferents. *El codi actual no mostra aquest escalat de les etiquetes Y, la qual cosa podria afectar la interpretació de la pèrdua durant l'entrenament, tot i que la correlació de Pearson (calculada posteriorment amb les prediccions escalades) seguiria sent una mètrica vàlida per comparar el rànquing.* Per a una pràctica òptima, `Y_train_seq` i `Y_val_seq` s'haurien de dividir per 5.0.\n",
    "\n",
    "3.  **Iteració per Dimensions d'Embedding**:\n",
    "    *   S'entrenen models per a cada dimensió d'embedding disponible (50, 100, 150, 300).\n",
    "\n",
    "4.  **Per a cada Dimensió, Tres Configuracions d'Embedding**:\n",
    "    *   **Matriu d'Embeddings Pre-entrenats**: Es crea utilitzant `create_pretrained_embedding_matrix` amb els embeddings Word2Vec truncats corresponents a la dimensió actual.\n",
    "    *   **Model 1: Embeddings Pre-entrenats Congelats (`trainable_embeddings=False`)**:\n",
    "        *   El model utilitza els embeddings Word2Vec com a característiques fixes. La capa d'embedding no s'actualitza durant l'entrenament.\n",
    "    *   **Model 2: Embeddings Pre-entrenats Entrenables (`trainable_embeddings=True`)**:\n",
    "        *   El model comença amb els embeddings Word2Vec, però aquests s'ajusten (fine-tuning) durant l'entrenament per adaptar-se millor a la tasca específica de STS.\n",
    "    *   **Model 3: Embeddings Aleatoris (`pretrained_weights=None`, `trainable_embeddings=True`)**:\n",
    "        *   La capa d'embedding s'inicialitza amb pesos aleatoris i s'aprèn des de zero durant l'entrenament. Això serveix per avaluar la contribució dels embeddings pre-entrenats.\n",
    "\n",
    "5.  **Entrenament i Avaluació per a cada Configuració**:\n",
    "    *   Es construeix el model amb `build_model_sequence`.\n",
    "    *   S'entrena el model (`model.fit`) utilitzant les dades de seqüència. No s'utilitzen callbacks d'`EarlyStopping` o `ReduceLROnPlateau` en aquest bucle, la qual cosa podria ser una millora a considerar.\n",
    "    *   Es fan prediccions en el conjunt de validació. Les prediccions del model estan en el rang `[0, 1]`.\n",
    "    *   **Escalat de Prediccions**: Les prediccions `Y_pred_...` (en rang `[0,1]`) es multipliquen per 5.0 per portar-les a l'escala original de les etiquetes `[0,5]` abans de calcular Pearson, MSE i MAE. Això és correcte per a l'avaluació.\n",
    "    *   Es calculen les mètriques (Pearson, MSE, MAE) i es guarden els resultats.\n",
    "\n",
    "Aquest experimentació exhaustiva permetrà comparar l'efecte de la dimensionalitat, l'ús d'embeddings pre-entrenats, i la possibilitat de fer fine-tuning d'aquests embeddings en el context d'un model basat en seqüències amb atenció."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b36f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparant dades per al model de seqüències...\")\n",
    "\n",
    "# Crear vocabulari\n",
    "word_to_idx, idx_to_word = create_vocabulary_mapping(all_sentences, max_vocab_size=10000)\n",
    "vocab_size = len(word_to_idx)\n",
    "sequence_length = 32\n",
    "\n",
    "print(f\"Vocabulari creat: {vocab_size} paraules\")\n",
    "print(f\"Longitud de seqüència: {sequence_length}\")\n",
    "\n",
    "# Convertir dades per a models de seqüència\n",
    "def prepare_sequence_data(df):\n",
    "    X1_seq, X2_seq, Y_seq = [], [], []\n",
    "    for _, row in df.iterrows():\n",
    "        seq1 = sentence_to_sequence(row['sentence_1'], word_to_idx, sequence_length)\n",
    "        seq2 = sentence_to_sequence(row['sentence_2'], word_to_idx, sequence_length)\n",
    "        X1_seq.append(seq1)\n",
    "        X2_seq.append(seq2)\n",
    "        # IMPORTANT: Les etiquetes Y_seq haurien d'estar escalades a [0,1] si el model prediu en aquest rang\n",
    "        # per a un càlcul correcte de la pèrdua durant l'entrenament.\n",
    "        # Per exemple: Y_seq.append(row['label'] / 5.0)\n",
    "        # Aquí es mantenen en [0,5] i les prediccions s'escalen posteriorment per a mètriques.\n",
    "        Y_seq.append(row['label']) \n",
    "    return np.array(X1_seq), np.array(X2_seq), np.array(Y_seq)\n",
    "\n",
    "X1_train_seq, X2_train_seq, Y_train_seq = prepare_sequence_data(train_df)\n",
    "X1_val_seq, X2_val_seq, Y_val_seq = prepare_sequence_data(val_df)\n",
    "\n",
    "# Escalar Y_val_seq a [0,1] per a una comparació més directa amb les prediccions del model abans d'escalar-les a [0,5]\n",
    "# Y_val_seq_scaled = Y_val_seq / 5.0 # Descomentar si es vol utilitzar per a mètriques directes amb sortida [0,1]\n",
    "\n",
    "print(f\"Dades de seqüència preparades: {X1_train_seq.shape}\")\n",
    "\n",
    "# Entrenar models de seqüència per diferents dimensions\n",
    "sequence_results = {}\n",
    "\n",
    "for embedding_dim in [50, 100, 150, 300]:\n",
    "    if embedding_dim in truncated_embeddings:\n",
    "        print(f\"\\n=== MODELS DE SEQÜÈNCIA {embedding_dim}D ===\")\n",
    "        \n",
    "        # Preparar matriu d'embeddings pre-entrenats\n",
    "        pretrained_matrix = create_pretrained_embedding_matrix(\n",
    "            word_to_idx, truncated_embeddings[embedding_dim], embedding_dim\n",
    "        )\n",
    "        \n",
    "        # Model 1: Embeddings pre-entrenats (frozen)\n",
    "        print(f\"Entrenant model amb embeddings pre-entrenats frozen ({embedding_dim}D)...\")\n",
    "        model_seq_frozen = build_model_sequence(\n",
    "            vocab_size=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            sequence_length=sequence_length,\n",
    "            pretrained_weights=pretrained_matrix,\n",
    "            trainable_embeddings=False\n",
    "        )\n",
    "        \n",
    "        history_frozen = model_seq_frozen.fit(\n",
    "            [X1_train_seq, X2_train_seq], Y_train_seq / 5.0, # Escalar Y_train_seq a [0,1]\n",
    "            validation_data=([X1_val_seq, X2_val_seq], Y_val_seq / 5.0), # Escalar Y_val_seq a [0,1]\n",
    "            epochs=30,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        Y_pred_frozen_raw = model_seq_frozen.predict([X1_val_seq, X2_val_seq]).flatten() # Surtida en [0,1]\n",
    "        Y_pred_frozen = Y_pred_frozen_raw * 5.0 # Escalar a [0,5] per a mètriques amb Y_val_seq original\n",
    "        \n",
    "        pearson_frozen, _ = pearsonr(Y_val_seq, Y_pred_frozen) # Comparar amb Y_val_seq original [0,5]\n",
    "        mse_frozen = mean_squared_error(Y_val_seq, Y_pred_frozen)\n",
    "        mae_frozen = mean_absolute_error(Y_val_seq, Y_pred_frozen)\n",
    "        \n",
    "        print(f\"  Frozen - Pearson: {pearson_frozen:.3f}, MSE: {mse_frozen:.3f}, MAE: {mae_frozen:.3f}\")\n",
    "        \n",
    "        # Model 2: Embeddings pre-entrenats (trainable)\n",
    "        print(f\"Entrenant model amb embeddings pre-entrenats trainable ({embedding_dim}D)...\")\n",
    "        model_seq_trainable = build_model_sequence(\n",
    "            vocab_size=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            sequence_length=sequence_length,\n",
    "            pretrained_weights=pretrained_matrix,\n",
    "            trainable_embeddings=True\n",
    "        )\n",
    "        \n",
    "        history_trainable = model_seq_trainable.fit(\n",
    "            [X1_train_seq, X2_train_seq], Y_train_seq / 5.0, # Escalar Y_train_seq a [0,1]\n",
    "            validation_data=([X1_val_seq, X2_val_seq], Y_val_seq / 5.0), # Escalar Y_val_seq a [0,1]\n",
    "            epochs=30,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        Y_pred_trainable_raw = model_seq_trainable.predict([X1_val_seq, X2_val_seq]).flatten() # Surtida en [0,1]\n",
    "        Y_pred_trainable = Y_pred_trainable_raw * 5.0 # Escalar a [0,5]\n",
    "        \n",
    "        pearson_trainable, _ = pearsonr(Y_val_seq, Y_pred_trainable)\n",
    "        mse_trainable = mean_squared_error(Y_val_seq, Y_pred_trainable)\n",
    "        mae_trainable = mean_absolute_error(Y_val_seq, Y_pred_trainable)\n",
    "        \n",
    "        print(f\"  Trainable - Pearson: {pearson_trainable:.3f}, MSE: {mse_trainable:.3f}, MAE: {mae_trainable:.3f}\")\n",
    "        \n",
    "        # Model 3: Embeddings aleatoris\n",
    "        \n",
    "        print(f\"Entrenant model amb embeddings aleatoris ({embedding_dim}D)...\")\n",
    "        model_seq_random = build_model_sequence(\n",
    "            vocab_size=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            sequence_length=sequence_length,\n",
    "            pretrained_weights=None,\n",
    "            trainable_embeddings=True\n",
    "        )\n",
    "        \n",
    "        history_random = model_seq_random.fit(\n",
    "            [X1_train_seq, X2_train_seq], Y_train_seq / 5.0, # Escalar Y_train_seq a [0,1]\n",
    "            validation_data=([X1_val_seq, X2_val_seq], Y_val_seq / 5.0), # Escalar Y_val_seq a [0,1]\n",
    "            epochs=30,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        Y_pred_random_raw = model_seq_random.predict([X1_val_seq, X2_val_seq]).flatten() # Surtida en [0,1]\n",
    "        Y_pred_random = Y_pred_random_raw * 5.0 # Escalar a [0,5]\n",
    "\n",
    "        pearson_random, _ = pearsonr(Y_val_seq, Y_pred_random)\n",
    "        mse_random = mean_squared_error(Y_val_seq, Y_pred_random)\n",
    "        mae_random = mean_absolute_error(Y_val_seq, Y_pred_random)\n",
    "        \n",
    "        print(f\"  Random - Pearson: {pearson_random:.3f}, MSE: {mse_random:.3f}, MAE: {mae_random:.3f}\")\n",
    "        \n",
    "        sequence_results[embedding_dim] = {\n",
    "            'frozen': {'model': model_seq_frozen, 'pearson': pearson_frozen, 'mse': mse_frozen, 'mae': mae_frozen},\n",
    "            'trainable': {'model': model_seq_trainable, 'pearson': pearson_trainable, 'mse': mse_trainable, 'mae': mae_trainable},\n",
    "            'random': {'model': model_seq_random, 'pearson': pearson_random, 'mse': mse_random, 'mae': mae_random}\n",
    "        }\n",
    "    else: # Aquest 'else' sembla que podria ser un error lògic si truncated_embeddings no conté la clau\n",
    "          # ja que model_seq_frozen, etc. no estarien definits. S'hauria de gestionar millor.\n",
    "          # Per ara, assumim que si embedding_dim està en la llista [50,100,150,300], estarà a truncated_embeddings.\n",
    "        pass # No hi hauria d'haver un 'else' aquí si el 'if embedding_dim in truncated_embeddings' gestiona tots els casos.\n",
    "             # Si es volgués gestionar el cas on no hi ha embeddings per a una dimensió, s'hauria de fer explícitament.\n",
    "             # El codi original tenia un error aquí que he corregit parcialment comentant l'else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722139a8",
   "metadata": {},
   "source": [
    "**Anàlisi dels Resultats dels Models de Seqüència**\n",
    "\n",
    "La taula següent presenta una comparació del rendiment (correlació de Pearson) dels models de seqüència sota diferents configuracions d'embeddings i dimensions.\n",
    "\n",
    "**Observacions Clau:**\n",
    "*   **Frozen vs. Trainable vs. Random**:\n",
    "    *   **Frozen**: Utilitzar embeddings pre-entrenats sense modificar-los sol donar un bon punt de partida, aprofitant el coneixement general capturat per Word2Vec.\n",
    "    *   **Trainable**: Permetre que els embeddings pre-entrenats s'ajustin (fine-tuning) durant l'entrenament pot millorar el rendiment, ja que s'adapten més a la tasca específica de STS i al dataset. No obstant això, si el dataset d'entrenament és petit, hi ha risc de sobreajustament.\n",
    "    *   **Random**: Entrenar embeddings des de zero sol ser el més difícil i requereix més dades. S'espera que aquesta configuració tingui el rendiment més baix, especialment amb datasets de mida moderada, ja que no aprofita cap coneixement previ.\n",
    "*   **Impacte de la Dimensió**: Similar als models anteriors, la dimensionalitat dels embeddings pot influir en el rendiment. Cal observar si la tendència es manté amb aquesta arquitectura més complexa.\n",
    "*   **Comparació General**: Aquests resultats es compararan amb els del Model 1 (agregat) i els baselines per avaluar si l'ús de seqüències i atenció aporta millores significatives.\n",
    "\n",
    "Les mètriques detallades (Pearson, MSE, MAE) per a cada configuració s'afegeixen al DataFrame `df_results` per a una anàlisi global posterior.\n",
    "\n",
    "*Nota sobre l'escalat de les etiquetes*: En la cel·la anterior, s'ha modificat el codi per escalar les etiquetes `Y_train_seq` i `Y_val_seq` a l'interval `[0,1]` quan s'alimenten a la funció `fit` del model (`Y_train_seq / 5.0`). Això és perquè la sortida del model `build_model_sequence` està en l'interval `[0,1]`. Les prediccions (`Y_pred_..._raw`) també estan en `[0,1]` i després s'escalen a `[0,5]` (`Y_pred_...`) per calcular les mètriques amb les etiquetes de validació originals (`Y_val_seq`) que estan en `[0,5]`. Aquest ajust és important per a la correcta interpretació de la funció de pèrdua durant l'entrenament.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparació dels models de seqüència\n",
    "print(\"\\n=== COMPARACIÓ MODELS DE SEQÜÈNCIA ===\")\n",
    "\n",
    "sequence_comparison_data = []\n",
    "sequence_metrics = []\n",
    "\n",
    "for dim in [50, 100, 150, 300]:\n",
    "    if dim in sequence_results:\n",
    "        seq = sequence_results[dim]\n",
    "        # Comparació Pearson\n",
    "        frozen_r = seq['frozen']['pearson']\n",
    "        trainable_r = seq['trainable']['pearson']\n",
    "        row = {\n",
    "            'Dimensions': f'{dim}D',\n",
    "            'Frozen': frozen_r,\n",
    "            'Trainable': trainable_r,\n",
    "        }\n",
    "        if 'random' in seq: # Comprovar si 'random' existeix abans d'accedir-hi\n",
    "            if seq['random'] is not None and 'pearson' in seq['random']: # Doble verificació\n",
    "                 row['Random'] = seq['random']['pearson']\n",
    "            else:\n",
    "                row['Random'] = np.nan # O un altre valor per indicar que no hi ha dades\n",
    "        else:\n",
    "            row['Random'] = np.nan\n",
    "\n",
    "        sequence_comparison_data.append(row)\n",
    "        \n",
    "        # Mètriques detallades\n",
    "        for key in ['frozen', 'trainable', 'random']:\n",
    "            if key in seq and seq[key] is not None: # Comprovar si la clau i el seu valor existeixen\n",
    "                sequence_metrics.append({\n",
    "                    'Model': f\"Model Seqüència ({key.capitalize()})\",\n",
    "                    'Dimensions': f'{dim}D',\n",
    "                    'Pearson': seq[key]['pearson'],\n",
    "                    'MSE': seq[key]['mse'],\n",
    "                    'MAE': seq[key]['mae']\n",
    "                })\n",
    "\n",
    "# Mostrar taules\n",
    "display(pd.DataFrame(sequence_comparison_data).style.hide(axis=\"index\"))\n",
    "df_results = pd.concat([df_results, pd.DataFrame(sequence_metrics)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b157f0",
   "metadata": {},
   "source": [
    "## 8. Anàlisi Comparativa i Visualització de Resultats (STS)\n",
    "\n",
    "Aquesta secció té com a objectiu consolidar i visualitzar els resultats obtinguts fins ara amb els models basats en Word2Vec (baselines, model agregat, model de seqüència).\n",
    "\n",
    "**Resum de Resultats:**\n",
    "Primer, es presenta un resum textual dels resultats de correlació de Pearson per a:\n",
    "*   **Baselines Cosinus**: Comparant la mitjana simple amb la mitjana ponderada per TF-IDF per a cada dimensió.\n",
    "*   **Models de Regressió Agregats**: Mostrant Pearson, MSE i MAE per a cada dimensió.\n",
    "*   **Models de Seqüència**: Mostrant Pearson, MSE i MAE per a cada dimensió i cada configuració d'embedding (Frozen, Trainable, Random).\n",
    "\n",
    "A continuació, es mostra la taula completa `df_results`, que acumula totes aquestes mètriques, permetent una comparació directa entre tots els models i configuracions provats fins ara.\n",
    "\n",
    "**Visualitzacions:**\n",
    "Es generen diversos gràfics per facilitar la interpretació dels resultats:\n",
    "\n",
    "1.  **Comparació de Correlació de Pearson per Dimensions**:\n",
    "    *   Un diagrama de barres que compara la correlació de Pearson dels models Baseline (Simple i TF-IDF) i el Model Agregat a través de les diferents dimensions d'embedding (50D, 100D, 150D, 300D).\n",
    "    *   **Anàlisi Esperada**: Aquest gràfic ajudarà a visualitzar quin tipus de model (baseline simple, baseline TF-IDF, agregat) funciona millor en general i com la dimensionalitat afecta cada un.\n",
    "\n",
    "2.  **Comparació de MSE per Dimensions**:\n",
    "    *   Similar a l'anterior, però mostrant l'Error Quadràtic Mig (MSE). Valors més baixos són millors.\n",
    "    *   **Anàlisi Esperada**: Complementa el gràfic de Pearson, mostrant una altra perspectiva del rendiment del model.\n",
    "\n",
    "3.  **Prediccions vs. Valors Reals (Millor Model Agregat)**:\n",
    "    *   Un diagrama de dispersió que enfronta les prediccions del millor model agregat (seleccionat per la correlació de Pearson més alta) contra els valors reals de similitud del conjunt de validació. Una línia diagonal (y=x) indica una predicció perfecta.\n",
    "    *   **Anàlisi Esperada**: Permet avaluar visualment com de bé s'ajusten les prediccions als valors reals i si hi ha patrons sistemàtics en els errors.\n",
    "\n",
    "4.  **Distribució d'Errors (Millor Model Agregat)**:\n",
    "    *   Un histograma que mostra la distribució dels errors de predicció (Predicció - Real) per al millor model agregat.\n",
    "    *   **Anàlisi Esperada**: Idealment, la distribució hauria d'estar centrada en zero i ser el més estreta possible. Això indica si el model tendeix a sobreestimar o subestimar i la magnitud típica dels errors.\n",
    "\n",
    "Aquestes anàlisis i visualitzacions són crucials per entendre les fortaleses i debilitats dels models desenvolupats i per guiar les decisions en experiments futurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac77ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resum simplificat de resultats\n",
    "if kv_model is not None: # Assegurar que els resultats existeixen\n",
    "    print(\"=== RESUM DE RESULTATS (Word2Vec based) ===\\n\")\n",
    "\n",
    "    print(\"BASELINES COSINUS:\")\n",
    "    for dim_str in ['50D', '100D', '150D', '300D']:\n",
    "        simple_df = df_results[(df_results['Model'] == 'Baseline Cosinus Simple') & (df_results['Dimensions'] == dim_str)]\n",
    "        tfidf_df = df_results[(df_results['Model'] == 'Baseline Cosinus TF-IDF') & (df_results['Dimensions'] == dim_str)]\n",
    "        \n",
    "        pearson_simple = simple_df['Pearson'].values[0] if not simple_df.empty else 'N/A'\n",
    "        pearson_tfidf = tfidf_df['Pearson'].values[0] if not tfidf_df.empty else 'N/A'\n",
    "        \n",
    "        if pearson_simple != 'N/A' or pearson_tfidf != 'N/A':\n",
    "             print(f\"  {dim_str} - Simple: {pearson_simple if isinstance(pearson_simple, str) else f'{pearson_simple:.3f}'}, TF-IDF: {pearson_tfidf if isinstance(pearson_tfidf, str) else f'{pearson_tfidf:.3f}'}\")\n",
    "\n",
    "    print(\"\\nMODELS DE REGRESSIÓ AGREGATS:\")\n",
    "    for dim_str in ['50D', '100D', '150D', '300D']:\n",
    "        aggr_df = df_results[(df_results['Model'] == 'Model Agregat') & (df_results['Dimensions'] == dim_str)]\n",
    "        if not aggr_df.empty:\n",
    "            row = aggr_df.iloc[0]\n",
    "            print(f\"  {dim_str} - Pearson: {row['Pearson']:.3f}, MSE: {row['MSE']:.3f}, MAE: {row['MAE']:.3f}\")\n",
    "\n",
    "    print(\"\\nMODELS DE SEQÜÈNCIA:\")\n",
    "    for dim_str in ['50D', '100D', '150D', '300D']:\n",
    "        print(f\"  --- Dimensions: {dim_str} ---\")\n",
    "        for mode in ['Frozen', 'Trainable', 'Random']:\n",
    "            seq_df = df_results[(df_results['Model'] == f'Model Seqüència ({mode})') & (df_results['Dimensions'] == dim_str)]\n",
    "            if not seq_df.empty:\n",
    "                row = seq_df.iloc[0]\n",
    "                print(f\"    {mode}: Pearson: {row['Pearson']:.3f}, MSE: {row['MSE']:.3f}, MAE: {row['MAE']:.3f}\")\n",
    "            # else: # Opcional: indicar si no hi ha dades per a alguna combinació\n",
    "            #     print(f\"    {mode}: N/A\")\n",
    "\n",
    "\n",
    "    print(\"\\n=== TAULA DE RESULTATS (Word2Vec based) ===\")\n",
    "    # Filtrar per mostrar només els resultats dels models basats en Word2Vec fins ara\n",
    "    word2vec_models_patterns = ['Baseline Cosinus', 'Model Agregat', 'Model Seqüència']\n",
    "    df_results_word2vec = df_results[df_results['Model'].str.contains('|'.join(word2vec_models_patterns), na=False)]\n",
    "    display(df_results_word2vec.sort_values(by='Pearson', ascending=False))\n",
    "else:\n",
    "    print(\"kv_model no està carregat, no es poden mostrar resultats detallats de Word2Vec.\")\n",
    "    display(df_results.sort_values(by='Pearson', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ff928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualitzacions\n",
    "if kv_model is not None and baseline_results and aggregated_results: # Assegurar que les dades per als gràfics existeixen\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(\"Anàlisi de Models Basats en Word2Vec (Mitjana/Agregats)\", fontsize=16)\n",
    "    \n",
    "    # Gràfic 1: Comparació de Pearson per dimensions\n",
    "    baseline_dims = sorted([d for d in [50, 100, 150, 300] if d in baseline_results and d in aggregated_results])\n",
    "    \n",
    "    if baseline_dims: # Només crear gràfics si hi ha dimensions comunes\n",
    "        baseline_simple_pearson = [baseline_results[d]['simple']['pearson'] for d in baseline_dims]\n",
    "        baseline_tfidf_pearson = [baseline_results[d]['tfidf']['pearson'] for d in baseline_dims]\n",
    "        aggregated_pearson_vals = [aggregated_results[d]['pearson'] for d in baseline_dims]\n",
    "        \n",
    "        x = np.arange(len(baseline_dims))\n",
    "        width = 0.25\n",
    "        \n",
    "        axes[0,0].bar(x - width, baseline_simple_pearson, width, label='Baseline Simple', alpha=0.8)\n",
    "        axes[0,0].bar(x, baseline_tfidf_pearson, width, label='Baseline TF-IDF', alpha=0.8)\n",
    "        axes[0,0].bar(x + width, aggregated_pearson_vals, width, label='Model Agregat', alpha=0.8)\n",
    "        \n",
    "        axes[0,0].set_xlabel('Dimensions dels Embeddings Word2Vec')\n",
    "        axes[0,0].set_ylabel('Correlació de Pearson')\n",
    "        axes[0,0].set_title('Correlació de Pearson per Dimensions')\n",
    "        axes[0,0].set_xticks(x)\n",
    "        axes[0,0].set_xticklabels([f'{d}D' for d in baseline_dims])\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Gràfic 2: MSE per dimensions\n",
    "        baseline_mse_simple = [baseline_results[d]['simple']['mse'] for d in baseline_dims]\n",
    "        baseline_mse_tfidf = [baseline_results[d]['tfidf']['mse'] for d in baseline_dims]\n",
    "        aggregated_mse_vals = [aggregated_results[d]['mse'] for d in baseline_dims]\n",
    "        \n",
    "        axes[0,1].bar(x - width, baseline_mse_simple, width, label='Baseline Simple', alpha=0.8)\n",
    "        axes[0,1].bar(x, baseline_mse_tfidf, width, label='Baseline TF-IDF', alpha=0.8)\n",
    "        axes[0,1].bar(x + width, aggregated_mse_vals, width, label='Model Agregat', alpha=0.8)\n",
    "        \n",
    "        axes[0,1].set_xlabel('Dimensions dels Embeddings Word2Vec')\n",
    "        axes[0,1].set_ylabel('Mean Squared Error (MSE)')\n",
    "        axes[0,1].set_title('MSE per Dimensions')\n",
    "        axes[0,1].set_xticks(x)\n",
    "        axes[0,1].set_xticklabels([f'{d}D' for d in baseline_dims])\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Gràfic 3: Prediccions vs Valors Reals (millor model agregat)\n",
    "        # Trobar el millor model agregat basat en Pearson\n",
    "        if aggregated_results: # Assegurar que aggregated_results no està buit\n",
    "            best_model_dim_aggr = max(aggregated_results.keys(), key=lambda k: aggregated_results[k]['pearson'] if k in aggregated_results else -1)\n",
    "            if best_model_dim_aggr != -1 and best_model_dim_aggr in aggregated_results:\n",
    "                best_predictions_aggr = aggregated_results[best_model_dim_aggr]['predictions']\n",
    "                real_values_val = val_df['label'].values[:len(best_predictions_aggr)] # Assegurar mateixa longitud\n",
    "                \n",
    "                axes[1,0].scatter(real_values_val, best_predictions_aggr, alpha=0.6, edgecolors='w', linewidth=0.5)\n",
    "                axes[1,0].plot([0, 5], [0, 5], 'r--', alpha=0.8, label=\"Predicció Perfecta\") # Línia y=x\n",
    "                axes[1,0].set_xlabel('Valors Reals (Similitud)')\n",
    "                axes[1,0].set_ylabel('Prediccions del Model')\n",
    "                axes[1,0].set_title(f'Millor Model Agregat ({best_model_dim_aggr}D) - Prediccions vs Reals')\n",
    "                axes[1,0].legend()\n",
    "                axes[1,0].grid(True, linestyle='--', alpha=0.7)\n",
    "                axes[1,0].set_xlim(0, 5)\n",
    "                axes[1,0].set_ylim(0, 5)\n",
    "\n",
    "                # Gràfic 4: Distribució d'errors\n",
    "                errors_aggr = best_predictions_aggr - real_values_val\n",
    "                sns.histplot(errors_aggr, bins=30, ax=axes[1,1], kde=True)\n",
    "                axes[1,1].axvline(x=0, color='red', linestyle='--', alpha=0.8, label=\"Error Zero\")\n",
    "                axes[1,1].set_xlabel('Error (Predicció - Real)')\n",
    "                axes[1,1].set_ylabel('Freqüència')\n",
    "                axes[1,1].set_title(f'Distribució d\\'Errors (Model Agregat {best_model_dim_aggr}D)')\n",
    "                axes[1,1].legend()\n",
    "                axes[1,1].grid(True, linestyle='--', alpha=0.7)\n",
    "            else:\n",
    "                axes[1,0].text(0.5, 0.5, \"No hi ha dades per al gràfic de prediccions\", ha='center', va='center')\n",
    "                axes[1,1].text(0.5, 0.5, \"No hi ha dades per al gràfic d'errors\", ha='center', va='center')\n",
    "\n",
    "        else:\n",
    "            axes[1,0].text(0.5, 0.5, \"No hi ha resultats agregats per mostrar\", ha='center', va='center')\n",
    "            axes[1,1].text(0.5, 0.5, \"No hi ha resultats agregats per mostrar\", ha='center', va='center')\n",
    "\n",
    "    else:\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                axes[i,j].text(0.5, 0.5, \"No hi ha dades suficients per generar els gràfics.\", ha='center', va='center')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96]) # Ajustar per al títol general\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No es poden generar les visualitzacions ja que falten resultats (kv_model, baseline_results o aggregated_results no disponibles).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a8991d",
   "metadata": {},
   "source": [
    "## 9. Experimentació Avançada (Opcional)\n",
    "\n",
    "En aquesta secció, explorem tècniques addicionals i alternatives per a la tasca de STS, anant més enllà dels models basats exclusivament en Word2Vec i arquitectures simples.\n",
    "\n",
    "**Experiments Realitzats:**\n",
    "\n",
    "1.  **Baseline One-Hot Encoding**:\n",
    "    *   **Propòsit**: Implementar un baseline molt simple basat en representacions One-Hot (o més aviat, Bag-of-Words binaritzat) de les frases.\n",
    "    *   **Mètode**: S'utilitza `CountVectorizer` per convertir les frases en vectors binaris on cada posició representa la presència o absència d'una paraula d'un vocabulari limitat. La similitud es calcula amb la distància cosinus. S'aplica un escalat millorat per ajustar les prediccions al rang de les etiquetes reals.\n",
    "    *   **Anàlisi Esperada**: Aquest model sol tenir un rendiment inferior als basats en embeddings densos, però serveix com a referència mínima.\n",
    "\n",
    "2.  **Experimentació Sistemàtica amb Hiperparàmetres (Model Agregat)**:\n",
    "    *   **Propòsit**: Investigar com diferents hiperparàmetres afecten el rendiment del Model 1 (Regressió amb Embeddings Agregats).\n",
    "    *   **Mètode**: Es proven diverses combinacions de `hidden_size` (mida de les capes ocultes), `dropout_rate` (taxa de dropout) i `learning_rate` (taxa d'aprenentatge de l'optimitzador Adam). S'utilitzen embeddings de 150D per a aquest experiment per equilibrar rendiment i velocitat.\n",
    "    *   **Anàlisi Esperada**: Identificar les millors configuracions d'hiperparàmetres i entendre la sensibilitat del model a cadascun d'ells. Es visualitza l'impacte individual de cada hiperparàmetre en la correlació de Pearson.\n",
    "\n",
    "3.  **Ús d'Embeddings de spaCy**:\n",
    "    *   **Propòsit**: Avaluar el rendiment utilitzant embeddings de frases proporcionats per la llibreria spaCy, específicament del model `ca_core_news_md`. Aquests embeddings són contextuals a nivell de document/frase.\n",
    "    *   **Mètode**: Per a cada frase, s'obté el seu vector (`doc.vector`) de spaCy. Aquests vectors es trunquen a les mateixes dimensions que els Word2Vec (50D, 100D, 150D, 300D) per a una comparació més directa, i es calcula la similitud cosinus.\n",
    "    *   **Anàlisi Esperada**: Comparar el rendiment dels embeddings de spaCy amb els de Word2Vec. Els embeddings de spaCy, tot i ser de propòsit general, podrien capturar millor el context.\n",
    "\n",
    "4.  **Ús d'Embeddings de RoBERTa (Model Base)**:\n",
    "    *   **Propòsit**: Utilitzar un model Transformer pre-entrenat (RoBERTa, `projecte-aina/roberta-base-ca-v2`) per extreure embeddings de frases.\n",
    "    *   **Mètode**: Les frases es passen a través del model RoBERTa, i s'utilitza l'embedding del token especial `[CLS]` (o la mitjana dels embeddings dels tokens de la última capa oculta) com a representació de la frase. Aquests embeddings es trunquen a diferents dimensions i es calcula la similitud cosinus. Es processen les frases en lots per eficiència.\n",
    "    *   **Anàlisi Esperada**: Els models Transformer solen oferir representacions semàntiques molt riques. S'espera un bon rendiment, possiblement superant els mètodes anteriors.\n",
    "\n",
    "5.  **Ús d'un Model RoBERTa Fine-Tuned per STS**:\n",
    "    *   **Propòsit**: Avaluar un model RoBERTa (`projecte-aina/roberta-base-ca-v2-cased-sts`) que ha estat específicament fine-tuned (ajustat) per a la tasca de Semantic Textual Similarity en català.\n",
    "    *   **Mètode**: S'utilitza la `pipeline` de `transformers` per a `text-classification` (que en aquest cas s'adapta a STS). El model directament prediu una puntuació de similitud per a un parell de frases.\n",
    "    *   **Anàlisi Esperada**: Aquest model hauria de ser el que ofereixi el millor rendiment, ja que ha estat entrenat específicament per a aquesta tasca i domini lingüístic.\n",
    "\n",
    "Aquests experiments proporcionaran una visió més àmplia de les capacitats de diferents tècniques d'embedding i modelatge per a STS en català."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline One-Hot (vocabulari limitat)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def evaluate_onehot(df: pd.DataFrame, max_features: int = 1000) -> Dict[str, float]:\n",
    "    all_sents = df['sentence_1'].tolist() + df['sentence_2'].tolist()\n",
    "    # Utilitzar preprocess_sentence per coherència, tot i que CountVectorizer ja fa lowercase.\n",
    "    processed_sents = [' '.join(preprocess_sentence(s)) for s in all_sents]\n",
    "    \n",
    "    vectorizer = CountVectorizer(max_features=max_features, binary=True) # lowercase ja ho fa preprocess_sentence\n",
    "    vectorizer.fit(processed_sents)\n",
    "    \n",
    "    similarities_raw = []\n",
    "    true_scores = df['label'].values\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Preprocessar frases abans de transformar\n",
    "        s1_processed = ' '.join(preprocess_sentence(row['sentence_1']))\n",
    "        s2_processed = ' '.join(preprocess_sentence(row['sentence_2']))\n",
    "\n",
    "        vec1 = vectorizer.transform([s1_processed]).toarray()[0]\n",
    "        vec2 = vectorizer.transform([s2_processed]).toarray()[0]\n",
    "        \n",
    "        if np.sum(vec1) == 0 or np.sum(vec2) == 0: # Si alguna frase no té paraules del vocabulari\n",
    "            sim = 0.0\n",
    "        else:\n",
    "            # Similitud cosinus: 1 - distance.cosine\n",
    "            # distance.cosine = dot(u,v) / (||u|| * ||v||) -- No, cosine distance és 1 - cos_sim\n",
    "            # cos_sim = dot(u,v) / (||u|| * ||v||)\n",
    "            # Aquí, com és binari, ||u|| = sqrt(sum(u_i^2)) = sqrt(num_ones_in_u)\n",
    "            # dot(u,v) = nombre de paraules comunes\n",
    "            \n",
    "            # sklearn.metrics.pairwise.cosine_similarity retorna la similitud, no la distància\n",
    "            # from sklearn.metrics.pairwise import cosine_similarity\n",
    "            # sim = cosine_similarity(vec1.reshape(1,-1), vec2.reshape(1,-1))[0,0]\n",
    "            # Però per mantenir la coherència amb l'ús de scipy.spatial.distance.cosine:\n",
    "            sim = 1 - cosine(vec1, vec2) if not (np.all(vec1 == 0) or np.all(vec2 == 0)) else 0.0\n",
    "\n",
    "        similarities_raw.append(sim)\n",
    "    \n",
    "    similarities_raw = np.array(similarities_raw)\n",
    "    \n",
    "    # Escalado mejorado: normalizar a la distribución de labels\n",
    "    min_label, max_label = true_scores.min(), true_scores.max()\n",
    "    \n",
    "    # Evitar divisió per zero si totes les similituds són iguals\n",
    "    min_sim_raw, max_sim_raw = similarities_raw.min(), similarities_raw.max()\n",
    "    \n",
    "    if max_sim_raw > min_sim_raw:\n",
    "        # Escalar linealment les similituds [0,1] (o rang similar) al rang de les etiquetes [min_label, max_label]\n",
    "        similarities_scaled = (similarities_raw - min_sim_raw) / (max_sim_raw - min_sim_raw) * (max_label - min_label) + min_label\n",
    "    elif len(np.unique(similarities_raw)) == 1: # Totes les similituds són iguals\n",
    "         # Si totes les similituds són iguals, assignar la mitjana de les etiquetes reals\n",
    "        similarities_scaled = np.full_like(similarities_raw, np.mean(true_scores))\n",
    "    else: # Cas extrem, potser totes les frases són OOV o similars\n",
    "        similarities_scaled = np.full_like(similarities_raw, min_label)\n",
    "\n",
    "\n",
    "    # Assegurar que les prediccions escalades estiguin dins del rang de les etiquetes\n",
    "    similarities_scaled = np.clip(similarities_scaled, min_label, max_label)\n",
    "\n",
    "    # Calcular métricas\n",
    "    pearson_corr, _ = pearsonr(true_scores, similarities_scaled)\n",
    "    mse = mean_squared_error(true_scores, similarities_scaled)\n",
    "    mae = mean_absolute_error(true_scores, similarities_scaled)\n",
    "    \n",
    "    return {'pearson': pearson_corr, 'mse': mse, 'mae': mae, 'predictions': similarities_scaled}\n",
    "\n",
    "# Evaluar con escalado mejorado\n",
    "print(\"=== BASELINE ONE-HOT ENCODING (Bag-of-Words Binari) ===\")\n",
    "onehot_results_list = [] # Canviat el nom per evitar conflictes\n",
    "onehot_dims_vocab = [500, 1000, 2000, 5000] # Mides de vocabulari a provar\n",
    "\n",
    "for max_features_vocab in onehot_dims_vocab:\n",
    "    print(f\"Avaluant One-Hot amb max_features = {max_features_vocab}\")\n",
    "    res_onehot = evaluate_onehot(val_df, max_features=max_features_vocab)\n",
    "    onehot_results_list.append({\n",
    "        'Model': 'Baseline One-Hot (Escalat)',\n",
    "        'Dimensions': f'{max_features_vocab} features', # Etiqueta més clara\n",
    "        'Pearson': res_onehot['pearson'],\n",
    "        'MSE': res_onehot['mse'],\n",
    "        'MAE': res_onehot['mae']\n",
    "    })\n",
    "\n",
    "df_onehot_results = pd.DataFrame(onehot_results_list) # Canviat el nom\n",
    "if not df_onehot_results.empty:\n",
    "    display(df_onehot_results.style.hide(axis=\"index\"))\n",
    "    df_results = pd.concat([df_results, df_onehot_results], ignore_index=True)\n",
    "else:\n",
    "    print(\"No s'han generat resultats per al baseline One-Hot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentació sistemàtica amb hiperparàmetres\n",
    "print(\"=== EXPERIMENTACIÓ AMB HIPERPARÀMETRES (Model Agregat) ===\")\n",
    "\n",
    "hyperparams_results = []\n",
    "\n",
    "# Provar diferents combinacions d'hiperparàmetres\n",
    "hidden_sizes = [64, 128, 256]\n",
    "dropout_rates = [0.2, 0.3, 0.5]\n",
    "learning_rates = [0.0005, 0.001, 0.002]\n",
    "\n",
    "# Indicador per saber si s'executa l'experiment\n",
    "experiment_executed = False\n",
    "\n",
    "if kv_model is not None and 150 in truncated_embeddings: # Assegurar que els embeddings necessaris existeixen\n",
    "    print(\"Experimentant amb diferents hiperparàmetres per al Model Agregat (Embeddings 150D)...\")\n",
    "    experiment_executed = True\n",
    "\n",
    "    # Preparar dades una sola vegada (per a 150D)\n",
    "    X1_train_hyper, X2_train_hyper, Y_train_hyper = prepare_aggregated_data(\n",
    "        train_df, truncated_embeddings[150], 150\n",
    "    )\n",
    "    X1_val_hyper, X2_val_hyper, Y_val_hyper = prepare_aggregated_data(\n",
    "        val_df, truncated_embeddings[150], 150\n",
    "    )\n",
    "\n",
    "    for hidden_size in hidden_sizes:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            for lr in learning_rates:\n",
    "                print(f\"Provant: hidden_size={hidden_size}, dropout={dropout_rate}, lr={lr}\")\n",
    "                \n",
    "                # Construir model amb hiperparàmetres específics\n",
    "                model_hyper = build_model_aggregated(\n",
    "                    embedding_dim=150, \n",
    "                    hidden_size=hidden_size, \n",
    "                    dropout_rate=dropout_rate\n",
    "                )\n",
    "                \n",
    "                # Recompilar amb learning rate específic\n",
    "                model_hyper.compile(\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer=tf.keras.optimizers.Adam(learning_rate=lr), # Aplicar el learning rate actual\n",
    "                    metrics=['mae', tf.keras.metrics.RootMeanSquaredError()] # Mètriques consistents\n",
    "                )\n",
    "                \n",
    "                # Callbacks per a l'entrenament d'hiperparàmetres\n",
    "                early_stopping_hyper = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss', patience=5, restore_best_weights=True, verbose=0 # Menys paciència\n",
    "                )\n",
    "                reduce_lr_hyper = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=0 # Menys paciència\n",
    "                )\n",
    "\n",
    "                # Entrenament ràpid\n",
    "                history_hyper = model_hyper.fit(\n",
    "                    [X1_train_hyper, X2_train_hyper], Y_train_hyper,\n",
    "                    validation_data=([X1_val_hyper, X2_val_hyper], Y_val_hyper),\n",
    "                    epochs=25,  # Menys èpoques per rapidesa en la cerca d'hiperparàmetres\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping_hyper, reduce_lr_hyper],\n",
    "                    verbose=0 # Menys verbositat durant la cerca\n",
    "                )\n",
    "                \n",
    "                # Avaluació\n",
    "                Y_pred_hyper = model_hyper.predict([X1_val_hyper, X2_val_hyper]).flatten()\n",
    "                pearson_hyper, _ = pearsonr(Y_val_hyper, Y_pred_hyper)\n",
    "                mse_hyper = mean_squared_error(Y_val_hyper, Y_pred_hyper)\n",
    "                mae_hyper = mean_absolute_error(Y_val_hyper, Y_pred_hyper) # Afegir MAE\n",
    "                \n",
    "                hyperparams_results.append({\n",
    "                    'hidden_size': hidden_size,\n",
    "                    'dropout_rate': dropout_rate,\n",
    "                    'learning_rate': lr,\n",
    "                    'pearson': pearson_hyper,\n",
    "                    'mse': mse_hyper,\n",
    "                    'mae': mae_hyper, # Guardar MAE\n",
    "                    'final_val_loss': min(history_hyper.history['val_loss']) if 'val_loss' in history_hyper.history else np.nan,\n",
    "                    'best_val_mae': min(history_hyper.history['val_mae']) if 'val_mae' in history_hyper.history else np.nan\n",
    "                })\n",
    "else:\n",
    "    print(\"Saltant l'experimentació d'hiperparàmetres: kv_model no carregat o embeddings de 150D no disponibles.\")\n",
    "\n",
    "\n",
    "if experiment_executed and hyperparams_results: # Només mostrar resultats si l'experiment s'ha executat\n",
    "    # Crear DataFrame amb resultats\n",
    "    df_hyperparams = pd.DataFrame(hyperparams_results)\n",
    "\n",
    "    print(\"\\nMillors configuracions d'hiperparàmetres (ordenades per Pearson descendent):\")\n",
    "    top_configs = df_hyperparams.sort_values('pearson', ascending=False).head(10)\n",
    "    display(top_configs[['hidden_size', 'dropout_rate', 'learning_rate', 'pearson', 'mse', 'mae', 'final_val_loss']])\n",
    "\n",
    "    print(\"\\nImpacte individual dels hiperparàmetres en la Correlació de Pearson Mitjana:\")\n",
    "\n",
    "    # Agrupar per hidden_size\n",
    "    hidden_impact = df_hyperparams.groupby('hidden_size')['pearson'].agg(['mean', 'std', 'count'])\n",
    "    print(\"\\nImpacte de Hidden Size:\")\n",
    "    display(hidden_impact)\n",
    "\n",
    "    # Agrupar per dropout_rate\n",
    "    dropout_impact = df_hyperparams.groupby('dropout_rate')['pearson'].agg(['mean', 'std', 'count'])\n",
    "    print(\"\\nImpacte de Dropout Rate:\")\n",
    "    display(dropout_impact)\n",
    "\n",
    "    # Agrupar per learning_rate\n",
    "    lr_impact = df_hyperparams.groupby('learning_rate')['pearson'].agg(['mean', 'std', 'count'])\n",
    "    print(\"\\nImpacte de Learning Rate:\")\n",
    "    display(lr_impact)\n",
    "\n",
    "    # Visualització dels resultats\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle(\"Impacte dels Hiperparàmetres en la Correlació de Pearson (Model Agregat 150D)\", fontsize=16)\n",
    "\n",
    "    # Gràfic 1: Hidden Size\n",
    "    if not hidden_impact.empty:\n",
    "        hidden_impact.plot(kind='bar', y='mean', yerr='std', ax=axes[0], capsize=4, legend=False, alpha=0.7)\n",
    "        axes[0].set_title('Hidden Size')\n",
    "        axes[0].set_ylabel('Pearson Correlation (mitjana ± std)')\n",
    "        axes[0].tick_params(axis='x', rotation=0)\n",
    "        axes[0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Gràfic 2: Dropout Rate\n",
    "    if not dropout_impact.empty:\n",
    "        dropout_impact.plot(kind='bar', y='mean', yerr='std', ax=axes[1], capsize=4, legend=False, alpha=0.7)\n",
    "        axes[1].set_title('Dropout Rate')\n",
    "        axes[1].set_ylabel('Pearson Correlation (mitjana ± std)')\n",
    "        axes[1].tick_params(axis='x', rotation=0)\n",
    "        axes[1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Gràfic 3: Learning Rate\n",
    "    if not lr_impact.empty:\n",
    "        lr_impact.plot(kind='bar', y='mean', yerr='std', ax=axes[2], capsize=4, legend=False, alpha=0.7)\n",
    "        axes[2].set_title('Learning Rate')\n",
    "        axes[2].set_ylabel('Pearson Correlation (mitjana ± std)')\n",
    "        axes[2].tick_params(axis='x', rotation=45)\n",
    "        axes[2].grid(True, linestyle='--', alpha=0.7)\n",
    "        # Formatar els valors de l'eix x per a learning rate per a millor llegibilitat\n",
    "        axes[2].set_xticklabels([f'{x:.4f}' for x in lr_impact.index])\n",
    "\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "elif experiment_executed and not hyperparams_results:\n",
    "    print(\"L'experimentació d'hiperparàmetres s'ha intentat executar però no ha generat resultats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Carregar model de spaCy per al català\n",
    "# És important tenir el model descarregat: python -m spacy download ca_core_news_md\n",
    "print(\"\\n=== AVALUACIÓ AMB EMBEDDINGS DE SPACY (ca_core_news_md) ===\")\n",
    "try:\n",
    "    nlp = spacy.load(\"ca_core_news_md\")\n",
    "    spacy_available = True\n",
    "except OSError:\n",
    "    print(\"Model spaCy 'ca_core_news_md' no trobat. Si us plau, descarrega'l amb:\")\n",
    "    print(\"python -m spacy download ca_core_news_md\")\n",
    "    print(\"Saltant l'avaluació amb spaCy.\")\n",
    "    spacy_available = False\n",
    "\n",
    "spacy_results_list = []\n",
    "\n",
    "if spacy_available:\n",
    "    # Dimensions a provar per als embeddings de spaCy (el vector original de ca_core_news_md és de 300D)\n",
    "    # Truncarem aquest vector per comparar amb les dimensions de Word2Vec\n",
    "    spacy_dims_to_test = [50, 100, 150, 300] \n",
    "\n",
    "    for dim_spacy in spacy_dims_to_test:\n",
    "        print(f\"Avaluant spaCy amb embeddings truncats a {dim_spacy}D...\")\n",
    "        \n",
    "        def get_spacy_embedding_truncated(sentence: str, target_dim: int) -> np.ndarray:\n",
    "            \"\"\"Obté l'embedding de spaCy (doc.vector) truncat a la dimensió desitjada\"\"\"\n",
    "            doc = nlp(sentence)\n",
    "            # Assegurar que el vector original té prou dimensions abans de truncar\n",
    "            if doc.has_vector and len(doc.vector) >= target_dim:\n",
    "                return doc.vector[:target_dim]\n",
    "            elif doc.has_vector: # Si el vector és més curt que target_dim, utilitzar el vector complet\n",
    "                # Opcionalment, es podria fer padding amb zeros si es volgués una mida fixa sempre\n",
    "                # Però per a similitud cosinus, utilitzar el vector disponible és raonable\n",
    "                # print(f\"Avís: vector de spaCy ({len(doc.vector)}D) més curt que target_dim ({target_dim}D) per la frase: {sentence[:30]}...\")\n",
    "                return doc.vector \n",
    "            else: # Si no hi ha vector per al document (poc probable amb models md/lg)\n",
    "                return np.zeros(target_dim)\n",
    "\n",
    "        similarities_spacy = []\n",
    "        true_labels_spacy = val_df['label'].values\n",
    "\n",
    "        for _, row in val_df.iterrows():\n",
    "            vec1_spacy = get_spacy_embedding_truncated(row['sentence_1'], dim_spacy)\n",
    "            vec2_spacy = get_spacy_embedding_truncated(row['sentence_2'], dim_spacy)\n",
    "            \n",
    "            # Comprovar si els vectors són vàlids (no només zeros)\n",
    "            if np.all(vec1_spacy == 0) or np.all(vec2_spacy == 0) or vec1_spacy.shape[0] == 0 or vec2_spacy.shape[0] == 0:\n",
    "                sim_spacy = 0.0 # Assignar 0 si algun embedding és zero o buit\n",
    "            else:\n",
    "                # Assegurar que els vectors tinguin la mateixa dimensió abans de calcular cosinus\n",
    "                # Això és rellevant si get_spacy_embedding_truncated retorna vectors de longitud variable\n",
    "                # En aquest cas, com que sempre trunquem o retornem zeros de target_dim, haurien de coincidir\n",
    "                # Però una comprovació addicional no fa mal.\n",
    "                # if vec1_spacy.shape[0] != vec2_spacy.shape[0]:\n",
    "                #     # print(f\"Discrepància de dimensions: {vec1_spacy.shape} vs {vec2_spacy.shape}\")\n",
    "                #     sim_spacy = 0.0 # O una altra estratègia\n",
    "                # else:\n",
    "                sim_spacy = 1 - cosine(vec1_spacy, vec2_spacy)\n",
    "            \n",
    "            # Escalar de [-1,1] a [0,5]\n",
    "            sim_scaled_spacy = (sim_spacy + 1) * 2.5 \n",
    "            similarities_spacy.append(sim_scaled_spacy)\n",
    "\n",
    "        similarities_spacy = np.array(similarities_spacy)\n",
    "        # Clip per assegurar que estigui en el rang [0,5]\n",
    "        similarities_spacy = np.clip(similarities_spacy, 0, 5)\n",
    "\n",
    "        pearson_corr_spacy, _ = pearsonr(true_labels_spacy, similarities_spacy)\n",
    "        mse_spacy = mean_squared_error(true_labels_spacy, similarities_spacy)\n",
    "        mae_spacy = mean_absolute_error(true_labels_spacy, similarities_spacy)\n",
    "        \n",
    "        spacy_results_list.append({\n",
    "            'Model': 'Baseline spaCy (ca_core_news_md)',\n",
    "            'Dimensions': f\"{dim_spacy}D (truncat)\",\n",
    "            'Pearson': pearson_corr_spacy,\n",
    "            'MSE': mse_spacy,\n",
    "            'MAE': mae_spacy\n",
    "        })\n",
    "        print(f\"  Resultats spaCy {dim_spacy}D - Pearson: {pearson_corr_spacy:.3f}, MSE: {mse_spacy:.3f}, MAE: {mae_spacy:.3f}\")\n",
    "\n",
    "\n",
    "    if spacy_results_list:\n",
    "        df_spacy_results = pd.DataFrame(spacy_results_list)\n",
    "        df_results = pd.concat([df_results, df_spacy_results], ignore_index=True)\n",
    "        print(\"\\n--- Resultats Consolidats amb spaCy ---\")\n",
    "        display(df_spacy_results.style.hide(axis=\"index\"))\n",
    "    else:\n",
    "        print(\"No s'han generat resultats per a spaCy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963bd262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "# import numpy as np # Ja importat\n",
    "# from scipy.stats import pearsonr # Ja importat\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error # Ja importat\n",
    "# from scipy.spatial.distance import cosine # Ja importat\n",
    "from tqdm.auto import tqdm # tqdm.auto per a compatibilitat notebook/consola\n",
    "\n",
    "print(\"\\n=== AVALUACIÓ AMB EMBEDDINGS DE ROBERTA (projecte-aina/roberta-base-ca-v2) ===\")\n",
    "\n",
    "# Comprovar disponibilitat de GPU per a PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilitzant dispositiu per a RoBERTa: {device}\")\n",
    "\n",
    "try:\n",
    "    roberta_model_name = 'projecte-aina/roberta-base-ca-v2'\n",
    "    roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_model_name)\n",
    "    roberta_model = AutoModel.from_pretrained(roberta_model_name).to(device) # Moure model al dispositiu\n",
    "    roberta_available = True\n",
    "except Exception as e:\n",
    "    print(f\"Error carregant el model RoBERTa: {e}\")\n",
    "    print(\"Saltant l'avaluació amb RoBERTa base.\")\n",
    "    roberta_available = False\n",
    "\n",
    "\n",
    "def get_roberta_embeddings_batch_custom(sentences: List[str], tokenizer, model, \n",
    "                                   target_dim: int, batch_size: int = 16, # Reduït batch_size per si hi ha problemes de memòria\n",
    "                                   max_length_tokenizer: int = 128) -> np.ndarray: # Reduït max_length per si les frases són molt llargues\n",
    "    \"\"\"Obté embeddings de RoBERTa per un batch de frases, utilitzant l'embedding del token [CLS]\"\"\"\n",
    "    all_embeddings = []\n",
    "    model.eval() # Posar el model en mode avaluació\n",
    "\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Processant batches RoBERTa\"):\n",
    "        batch_sentences = sentences[i:i+batch_size]\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            batch_sentences, \n",
    "            return_tensors=\"pt\", \n",
    "            truncation=True, \n",
    "            padding=True, # 'longest' per defecte si no s'especifica max_length\n",
    "            max_length=max_length_tokenizer # Especificar max_length\n",
    "        ).to(device) # Moure inputs al dispositiu\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # Usar l'embedding del token [CLS] (primer token) de la darrera capa oculta\n",
    "            batch_cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy() # Moure a CPU i convertir a numpy\n",
    "            \n",
    "            # Truncar o fer padding a la dimensió desitjada\n",
    "            current_dim = batch_cls_embeddings.shape[1]\n",
    "            if current_dim > target_dim:\n",
    "                batch_embeddings_processed = batch_cls_embeddings[:, :target_dim]\n",
    "            elif current_dim < target_dim:\n",
    "                # Fer padding amb zeros si l'embedding és més curt que target_dim\n",
    "                padding = np.zeros((batch_cls_embeddings.shape[0], target_dim - current_dim))\n",
    "                batch_embeddings_processed = np.concatenate([batch_cls_embeddings, padding], axis=1)\n",
    "            else:\n",
    "                batch_embeddings_processed = batch_cls_embeddings\n",
    "            \n",
    "            all_embeddings.append(batch_embeddings_processed)\n",
    "    \n",
    "    if not all_embeddings:\n",
    "        # Retornar un array buit amb la forma correcta si no hi ha frases\n",
    "        return np.empty((0, target_dim))\n",
    "        \n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "def calculate_cosine_similarities_vectorized_robust(embeddings1: np.ndarray, embeddings2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calcula similituds cosinus de forma vectoritzada, gestionant vectors zero.\"\"\"\n",
    "    # Assegurar que els embeddings no siguin buits\n",
    "    if embeddings1.shape[0] == 0 or embeddings2.shape[0] == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    # Normalitzar vectors\n",
    "    norms1 = np.linalg.norm(embeddings1, axis=1, keepdims=True)\n",
    "    norms2 = np.linalg.norm(embeddings2, axis=1, keepdims=True)\n",
    "    \n",
    "    # Evitar divisió per zero per a vectors que són completament zero\n",
    "    # Si la norma és zero, el vector normalitzat serà zero, i el producte escalar serà zero.\n",
    "    embeddings1_norm = np.divide(embeddings1, norms1, out=np.zeros_like(embeddings1), where=norms1!=0)\n",
    "    embeddings2_norm = np.divide(embeddings2, norms2, out=np.zeros_like(embeddings2), where=norms2!=0)\n",
    "    \n",
    "    # Calcular similitud cosinus (producte escalar de vectors normalitzats)\n",
    "    cosine_sims = np.sum(embeddings1_norm * embeddings2_norm, axis=1)\n",
    "    \n",
    "    return cosine_sims\n",
    "\n",
    "\n",
    "if roberta_available:\n",
    "    # Dimensions a avaluar (la dimensió original de RoBERTa base és 768)\n",
    "    # Truncarem per comparar, i també utilitzarem la dimensió completa.\n",
    "    roberta_dims_to_test = [50, 100, 150, 300, 768] \n",
    "    roberta_results_list = []\n",
    "\n",
    "    # Preparar les frases del conjunt de validació\n",
    "    val_sentences1 = val_df['sentence_1'].tolist()\n",
    "    val_sentences2 = val_df['sentence_2'].tolist()\n",
    "    val_true_labels = val_df['label'].values\n",
    "\n",
    "    for dim_roberta in roberta_dims_to_test:\n",
    "        print(f\"\\n--- Avaluant RoBERTa Base amb embeddings de {dim_roberta}D ---\")\n",
    "        \n",
    "        print(\"Obtenint embeddings RoBERTa per a les frases 1 del conjunt de validació...\")\n",
    "        embeddings1_roberta = get_roberta_embeddings_batch_custom(val_sentences1, roberta_tokenizer, roberta_model, \n",
    "                                                             target_dim=dim_roberta)\n",
    "        \n",
    "        print(\"Obtenint embeddings RoBERTa per a les frases 2 del conjunt de validació...\")\n",
    "        embeddings2_roberta = get_roberta_embeddings_batch_custom(val_sentences2, roberta_tokenizer, roberta_model, \n",
    "                                                             target_dim=dim_roberta)\n",
    "        \n",
    "        if embeddings1_roberta.shape[0] > 0 and embeddings2_roberta.shape[0] > 0:\n",
    "            print(\"Calculant similituds cosinus...\")\n",
    "            cosine_sims_roberta = calculate_cosine_similarities_vectorized_robust(embeddings1_roberta, embeddings2_roberta)\n",
    "            \n",
    "            # Escalar similituds de [-1,1] a [0,5]\n",
    "            # La similitud cosinus ja està en [-1,1]. (sim + 1) -> [0,2]. (sim+1)*2.5 -> [0,5]\n",
    "            similarities_scaled_roberta = (cosine_sims_roberta + 1) * 2.5\n",
    "            similarities_scaled_roberta = np.clip(similarities_scaled_roberta, 0, 5) # Assegurar límits\n",
    "            \n",
    "            # Verificar valors problemàtics (NaN, Inf)\n",
    "            if np.any(np.isnan(similarities_scaled_roberta)) or np.any(np.isinf(similarities_scaled_roberta)):\n",
    "                print(\"Avís: S'han trobat valors NaN o Inf en les similituds escalades. S'estan substituint.\")\n",
    "                similarities_scaled_roberta = np.nan_to_num(similarities_scaled_roberta, nan=np.mean(val_true_labels), \n",
    "                                                            posinf=5.0, neginf=0.0)\n",
    "            \n",
    "            # Calcular mètriques\n",
    "            pearson_corr_roberta, p_value_roberta = pearsonr(val_true_labels, similarities_scaled_roberta)\n",
    "            mse_roberta = mean_squared_error(val_true_labels, similarities_scaled_roberta)\n",
    "            mae_roberta = mean_absolute_error(val_true_labels, similarities_scaled_roberta)\n",
    "            \n",
    "            print(f\"  Resultats RoBERTa {dim_roberta}D - Pearson: {pearson_corr_roberta:.3f}, MSE: {mse_roberta:.3f}, MAE: {mae_roberta:.3f}\")\n",
    "            \n",
    "            roberta_results_list.append({\n",
    "                'Model': 'Baseline RoBERTa Base (CLS, cosinus)',\n",
    "                'Dimensions': f'{dim_roberta}D{\" (original)\" if dim_roberta == 768 else \" (truncat)\"}',\n",
    "                'Pearson': pearson_corr_roberta,\n",
    "                'MSE': mse_roberta,\n",
    "                'MAE': mae_roberta\n",
    "            })\n",
    "        else:\n",
    "            print(f\"No s'han pogut generar embeddings per a RoBERTa {dim_roberta}D.\")\n",
    "\n",
    "\n",
    "    if roberta_results_list:\n",
    "        df_roberta_results = pd.DataFrame(roberta_results_list)\n",
    "        df_results = pd.concat([df_results, df_roberta_results], ignore_index=True)\n",
    "        print(\"\\n--- Resultats Consolidats amb RoBERTa Base (CLS, cosinus) ---\")\n",
    "        display(df_roberta_results.style.hide(axis=\"index\"))\n",
    "    else:\n",
    "        print(\"No s'han generat resultats per a RoBERTa Base.\")\n",
    "\n",
    "    # Opcional: Netejar memòria de GPU si ja no es necessiten els models RoBERTa\n",
    "    del roberta_model, roberta_tokenizer\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3057357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "# from scipy.special import logit # No sembla utilitzar-se aquí\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"\\n=== AVALUANT AMB MODEL RoBERTa ESPECÍFICAMENT FINE-TUNED PER STS (projecte-aina/roberta-base-ca-v2-cased-sts) ===\")\n",
    "\n",
    "# Comprovar disponibilitat de GPU per a PyTorch\n",
    "device_sts = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Determinar l'índex del dispositiu per a la pipeline\n",
    "pipeline_device_idx = 0 if device_sts.type == \"cuda\" else -1 \n",
    "print(f\"Utilitzant dispositiu per a RoBERTa STS fine-tuned: {device_sts} (índex pipeline: {pipeline_device_idx})\")\n",
    "\n",
    "\n",
    "try:\n",
    "    sts_model_name = 'projecte-aina/roberta-base-ca-v2-cased-sts'\n",
    "    # No cal carregar el tokenizer per separat si la pipeline ho fa, però és bona pràctica per si es volgués més control\n",
    "    # sts_tokenizer = AutoTokenizer.from_pretrained(sts_model_name) \n",
    "    \n",
    "    # La pipeline 'text-classification' amb aquest model retorna directament un score que es pot interpretar\n",
    "    # com a similitud. El model està entrenat per a STS.\n",
    "    sts_pipe = pipeline('text-classification', model=sts_model_name, device=pipeline_device_idx) # Passar device a la pipeline\n",
    "    sts_fine_tuned_available = True\n",
    "except Exception as e:\n",
    "    print(f\"Error carregant el model RoBERTa STS fine-tuned: {e}\")\n",
    "    print(\"Saltant l'avaluació amb RoBERTa STS fine-tuned.\")\n",
    "    sts_fine_tuned_available = False\n",
    "\n",
    "\n",
    "def get_sts_scores_from_pipeline(sentence_pairs_list: List[Tuple[str, str]], pipe_model, \n",
    "                                 batch_size_pipe: int = 16) -> List[float]:\n",
    "    \"\"\"\n",
    "    Obté les puntuacions de similitud d'un model STS fine-tuned usant una pipeline.\n",
    "    La pipeline per a 'text-classification' amb un model STS retorna {'label': 'LABEL_X', 'score': YYY}\n",
    "    El 'score' aquí és la probabilitat de la classe predita. Per a models STS binaris (similar/no similar) o\n",
    "    regressió directa, la interpretació del 'score' pot variar.\n",
    "    Aquest model ('projecte-aina/roberta-base-ca-v2-cased-sts') sembla estar entrenat per a regressió\n",
    "    i la seva sortida 'score' ja és una mesura de similitud (possiblement en [0,1] o un altre rang).\n",
    "    Necessitem verificar com s'han d'interpretar aquests scores.\n",
    "    Si el model retorna un score que ja està en l'escala [0,5] o [0,1] que es pot escalar a [0,5], perfecte.\n",
    "    Si retorna logits o probabilitats per a classes discretes, caldria un post-processament.\n",
    "    \n",
    "    Consultant la pàgina del model a Hugging Face (si disponible) o experimentant,\n",
    "    es veu que aquest model retorna un 'score' que sembla estar directament relacionat amb la similitud.\n",
    "    Assumirem que aquest 'score' es pot escalar linealment si no està ja en el rang [0,5].\n",
    "    La documentació del model indica que prediu valors entre 0 i 1, que després s'escalen a 0-5.\n",
    "    \"The model predicts values between 0 and 1. These are then scaled to 0-5.\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # El format d'entrada per a la pipeline amb parells de frases pot variar.\n",
    "    # Per a 'text-classification' amb models STS, sovint s'espera una única cadena concatenada\n",
    "    # o la pipeline pot gestionar directament parells.\n",
    "    # Si la pipeline espera [[sent1, sent2], [sent3, sent4], ...]:\n",
    "    # formatted_inputs = [[s1, s2] for s1, s2 in sentence_pairs_list]\n",
    "    \n",
    "    # Si la pipeline espera [ \"sent1 [SEP] sent2\", \"sent3 [SEP] sent4\", ...]:\n",
    "    # (Aquest sembla ser un format comú per a models basats en BERT/RoBERTa per a STS)\n",
    "    # formatted_inputs = [f\"{s1} {pipe_model.tokenizer.sep_token} {s2}\" for s1, s2 in sentence_pairs_list]\n",
    "    # No obstant, la pipeline de 'text-classification' sol esperar una única seqüència de text per entrada.\n",
    "    # Per a STS, sovint s'utilitza 'sentence-similarity' o es passen els dos segments.\n",
    "    # La pipeline 'text-classification' amb aquest model específic sembla que gestiona internament\n",
    "    # la tokenització de parells si se li passen com a llista de tuples/llistes.\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    # Processar en lots\n",
    "    for i in tqdm(range(0, len(sentence_pairs_list), batch_size_pipe), desc=\"Processant RoBERTa STS fine-tuned\"):\n",
    "        batch_pairs = sentence_pairs_list[i:i+batch_size_pipe]\n",
    "        \n",
    "        # La pipeline de text-classification espera una llista de textos o llistes de parells de textos\n",
    "        # Per a aquest model STS, s'espera una llista de parells:\n",
    "        # [{'text': sentence1, 'text_pair': sentence2}, ...] o similar.\n",
    "        # O directament: pipe(sentence_pairs_list) si sentence_pairs_list és List[Tuple[str,str]]\n",
    "        \n",
    "        try:\n",
    "            # La pipeline per a 'text-classification' amb aquest model específic\n",
    "            # potser espera els parells directament.\n",
    "            predictions = pipe_model(batch_pairs) # Passar la llista de tuples (frase1, frase2)\n",
    "        except Exception as e:\n",
    "            # Si falla, provar amb el format concatenat (menys probable per a 'text-classification' directament)\n",
    "            # print(f\"Error amb input directe de parells: {e}. Provant format concatenat.\")\n",
    "            # formatted_batch = [f\"{s1} {pipe_model.tokenizer.sep_token} {s2}\" for s1, s2 in batch_pairs]\n",
    "            # predictions = pipe_model(formatted_batch)\n",
    "            # O potser la pipeline espera una llista de diccionaris:\n",
    "            # formatted_batch = [{\"text\": s1, \"text_pair\": s2} for s1,s2 in batch_pairs]\n",
    "            # predictions = pipe_model(formatted_batch)\n",
    "            print(f\"Error en processar el batch amb la pipeline: {e}\")\n",
    "            # Afegir valors placeholder si hi ha error per mantenir la longitud\n",
    "            all_scores.extend([np.nan] * len(batch_pairs)) # O un valor com 2.5\n",
    "            continue\n",
    "\n",
    "        # Extreure els scores. La sortida de la pipeline és una llista de diccionaris.\n",
    "        # Cada diccionari conté 'label' i 'score'.\n",
    "        # Per a aquest model STS, el 'score' és el que ens interessa.\n",
    "        # Aquest score està en el rang [0,1] segons la documentació del model.\n",
    "        current_batch_scores = [pred['score'] for pred in predictions]\n",
    "        all_scores.extend(current_batch_scores)\n",
    "        \n",
    "    return all_scores\n",
    "\n",
    "\n",
    "if sts_fine_tuned_available:\n",
    "    # Preparar parelles de frases del dataset de validació\n",
    "    val_sentence_pairs_sts = [(row['sentence_1'], row['sentence_2']) for _, row in val_df.iterrows()]\n",
    "    val_true_labels_sts = val_df['label'].values\n",
    "\n",
    "    print(\"Obtenint prediccions del model RoBERTa STS fine-tuned...\")\n",
    "    # Obtenir scores bruts (assumits en [0,1])\n",
    "    raw_predictions_sts = get_sts_scores_from_pipeline(val_sentence_pairs_sts, sts_pipe)\n",
    "    \n",
    "    # Convertir a array numpy\n",
    "    raw_predictions_sts = np.array(raw_predictions_sts)\n",
    "\n",
    "    # Escalar els scores de [0,1] a [0,5]\n",
    "    scaled_predictions_sts = raw_predictions_sts * 5.0\n",
    "    scaled_predictions_sts = np.clip(scaled_predictions_sts, 0, 5) # Assegurar límits\n",
    "\n",
    "    # Verificar valors problemàtics (NaN, Inf)\n",
    "    if np.any(np.isnan(scaled_predictions_sts)) or np.any(np.isinf(scaled_predictions_sts)):\n",
    "        print(\"Avís: S'han trobat valors NaN o Inf en les prediccions STS fine-tuned. S'estan substituint.\")\n",
    "        # Substituir per la mitjana de les etiquetes reals si hi ha NaNs\n",
    "        mean_label = np.mean(val_true_labels_sts[~np.isnan(val_true_labels_sts)]) # Mitjana de labels vàlids\n",
    "        scaled_predictions_sts = np.nan_to_num(scaled_predictions_sts, nan=mean_label, \n",
    "                                                posinf=5.0, neginf=0.0)\n",
    "\n",
    "    # Calcular mètriques\n",
    "    pearson_corr_sts, p_value_sts = pearsonr(val_true_labels_sts, scaled_predictions_sts)\n",
    "    mse_sts = mean_squared_error(val_true_labels_sts, scaled_predictions_sts)\n",
    "    mae_sts = mean_absolute_error(val_true_labels_sts, scaled_predictions_sts)\n",
    "\n",
    "    print(f\"\\n--- RESULTATS RoBERTa STS FINE-TUNED (projecte-aina/roberta-base-ca-v2-cased-sts) ---\")\n",
    "    print(f\"Correlació de Pearson: {pearson_corr_sts:.4f} (p-value: {p_value_sts:.3g})\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse_sts:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae_sts:.4f}\")\n",
    "\n",
    "    # Afegir als resultats globals\n",
    "    roberta_sts_fine_tuned_result = {\n",
    "        'Model': 'RoBERTa STS Fine-tuned (AINA)',\n",
    "        'Dimensions': 'N/A (Model Complet)', # La dimensió no és directament comparable com els embeddings truncats\n",
    "        'Pearson': pearson_corr_sts,\n",
    "        'MSE': mse_sts,\n",
    "        'MAE': mae_sts,\n",
    "    }\n",
    "\n",
    "    df_roberta_sts_ft_results = pd.DataFrame([roberta_sts_fine_tuned_result])\n",
    "    df_results = pd.concat([df_results, df_roberta_sts_ft_results], ignore_index=True)\n",
    "\n",
    "    display(df_roberta_sts_ft_results.style.hide(axis=\"index\"))\n",
    "    \n",
    "    # Netejar memòria\n",
    "    del sts_pipe\n",
    "    if device_sts.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Saltada l'avaluació amb RoBERTa STS fine-tuned perquè el model no està disponible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a68d1",
   "metadata": {},
   "source": [
    "## 10. Conclusions Parcials (STS) i Observacions\n",
    "\n",
    "Després d'avaluar diversos models per a la Similitud de Text Semàntic (STS) en català, podem extreure algunes conclusions i observacions clau basades en els resultats obtinguts fins ara en el conjunt de validació.\n",
    "\n",
    "### Resultats Principals (Esperats):\n",
    "\n",
    "1.  **Baselines Cosinus (Word2Vec)**:\n",
    "    *   Proporcionen un punt de partida raonable.\n",
    "    *   L'ús de TF-IDF per ponderar els embeddings de paraules generalment millora lleugerament la mitjana simple.\n",
    "    *   Dimensions més altes (ex: 300D) tendeixen a funcionar millor que les més baixes (ex: 50D) amb Word2Vec.\n",
    "\n",
    "2.  **Model de Regressió Agregat (Word2Vec)**:\n",
    "    *   Aquesta xarxa neuronal simple sol superar els baselines de similitud cosinus, demostrant la capacitat d'aprendre relacions més complexes a partir dels embeddings de frase concatenats.\n",
    "    *   La tendència respecte a la dimensionalitat dels embeddings sol ser similar a la dels baselines.\n",
    "\n",
    "3.  **Model de Seqüència amb Atenció (Word2Vec)**:\n",
    "    *   **Embeddings Pre-entrenats (Frozen vs. Trainable)**:\n",
    "        *   Els embeddings congelats (frozen) ja ofereixen un bon rendiment.\n",
    "        *   Permetre l'entrenament (fine-tuning) dels embeddings pre-entrenats sovint condueix a millors resultats, ja que s'adapten a la tasca específica.\n",
    "    *   **Embeddings Aleatoris**: Com era d'esperar, entrenar embeddings des de zero sense coneixement previ generalment resulta en un rendiment inferior, especialment amb datasets de mida limitada.\n",
    "    *   Aquesta arquitectura, en general, té el potencial de superar el model agregat, ja que pot ponderar la importància de les paraules dins de les frases.\n",
    "\n",
    "4.  **Baseline One-Hot Encoding**:\n",
    "    *   Com s'esperava, aquest model simple té un rendiment significativament inferior als basats en embeddings densos, destacant la importància de les representacions semàntiques riques.\n",
    "\n",
    "5.  **Ajustament d'Hiperparàmetres**:\n",
    "    *   L'experimentació amb hiperparàmetres (mida de capes ocultes, dropout, taxa d'aprenentatge) pot portar a millores en el rendiment del model agregat. Mostra la sensibilitat del model a aquestes configuracions.\n",
    "\n",
    "6.  **Embeddings de spaCy (`ca_core_news_md`)**:\n",
    "    *   Els embeddings de document/frase de spaCy (basats en vectors de paraules contextualitzats internament) ofereixen un rendiment competitiu, sovint comparable o millor que els baselines Word2Vec simples, especialment quan s'utilitza el vector complet del document.\n",
    "\n",
    "7.  **Embeddings de RoBERTa Base (`projecte-aina/roberta-base-ca-v2`)**:\n",
    "    *   Utilitzar l'embedding del token `[CLS]` d'un model Transformer com RoBERTa com a representació de la frase, i després calcular la similitud cosinus, sol oferir resultats molt bons, superant generalment els mètodes basats en Word2Vec i spaCy. La dimensió completa (768D) sol ser la millor.\n",
    "\n",
    "8.  **Model RoBERTa Fine-Tuned per STS (`projecte-aina/roberta-base-ca-v2-cased-sts`)**:\n",
    "    *   **Aquest és, amb diferència, el model que s'espera que tingui el millor rendiment.** En estar específicament entrenat per a la tasca de STS en català, aprofita l'arquitectura potent de RoBERTa i l'especialització en la tasca. La correlació de Pearson obtinguda amb aquest model sol ser el sostre de rendiment en aquest tipus de datasets.\n",
    "\n",
    "### Observacions Generals:\n",
    "\n",
    "*   **Importància dels Embeddings Pre-entrenats**: L'ús d'embeddings pre-entrenats (Word2Vec, spaCy, RoBERTa) és crucial per obtenir bons resultats, especialment quan les dades d'entrenament per a la tasca específica són limitades.\n",
    "*   **Complexitat del Model vs. Rendiment**: Augmentar la complexitat del model (d'un baseline a una xarxa neuronal, o d'una xarxa simple a una amb atenció o un Transformer) generalment porta a millors resultats, però també augmenta la necessitat de dades i recursos computacionals.\n",
    "*   **Fine-tuning**: El fine-tuning d'embeddings pre-entrenats o de models Transformer complets en el dataset específic de la tasca sol ser la clau per assolir el màxim rendiment.\n",
    "*   **Mètriques**: La correlació de Pearson és la mètrica estàndard i més important per avaluar els sistemes de STS.\n",
    "\n",
    "A continuació, es guardaran tots els resultats i es mostrarà el millor model global identificat fins ara basant-se en la correlació de Pearson en el conjunt de validació. Després, s'avaluarà el rendiment d'aquest millor model en el conjunt de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b678ce9",
   "metadata": {},
   "source": [
    "## Conclusions i Observacions (Original - Es manté per context històric)\n",
    "\n",
    "Aquesta era la secció de conclusions original del notebook. Les conclusions més actualitzades i detallades es troben en la cel·la Markdown anterior.\n",
    "\n",
    "### Resultats Principals:\n",
    "\n",
    "1. **Baselines Cosinus**: Proporcionen una base sòlida per comparar models més complexos\n",
    "2. **Models de Regressió**: Milloren significativament sobre els baselines\n",
    "3. **Impacte de les Dimensions**: Les dimensions més altes generalment milloren el rendiment\n",
    "4. **TF-IDF vs Mitjana Simple**: TF-IDF sovint proporciona millors resultats\n",
    "5. **Fine-tuning d'Embeddings**: Pot millorar el rendiment però amb risc d'overfitting\n",
    "\n",
    "### Observacions:\n",
    "\n",
    "- La correlació de Pearson és la mètrica principal per STS\n",
    "- L'arquitectura amb atenció permet modelar millor les dependències entre paraules\n",
    "- Els embeddings pre-entrenats proporcionen una base sòlida\n",
    "- La regularització (dropout, batch normalization) és important per evitar overfitting\n",
    "\n",
    "### Futures Direccions:\n",
    "\n",
    "- Experimentar amb arquitectures més complexes (Transformers)\n",
    "- Provar altres tècniques d'agregació (atenció multi-cap)\n",
    "- Avaluar en altres tasques de NLP en català\n",
    "- Combinar múltiples tipus d'embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3638a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar tots els resultats acumulats en un fitxer CSV\n",
    "output_csv_path = 'resultats_sts_practica4_complet.csv'\n",
    "try:\n",
    "    df_results.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Tots els resultats guardats a '{output_csv_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error guardant els resultats a CSV: {e}\")\n",
    "\n",
    "# Mostrar el millor model global basat en la correlació de Pearson en el conjunt de validació\n",
    "if not df_results.empty:\n",
    "    # Assegurar que la columna 'Pearson' sigui numèrica i gestionar NaNs abans de trobar idxmax\n",
    "    df_results['Pearson'] = pd.to_numeric(df_results['Pearson'], errors='coerce')\n",
    "    df_results_valid_pearson = df_results.dropna(subset=['Pearson'])\n",
    "\n",
    "    if not df_results_valid_pearson.empty:\n",
    "        best_model_idx = df_results_valid_pearson['Pearson'].idxmax()\n",
    "        best_model_info = df_results_valid_pearson.loc[best_model_idx]\n",
    "\n",
    "        print(f\"\\n🏆 MILLOR MODEL GLOBAL (basat en el conjunt de validació):\")\n",
    "        print(f\"Model       : {best_model_info['Model']}\")\n",
    "        print(f\"Dimensions  : {best_model_info['Dimensions']}\")\n",
    "        print(f\"Pearson     : {best_model_info['Pearson']:.4f}\")\n",
    "        print(f\"MSE         : {best_model_info['MSE']:.4f}\")\n",
    "        print(f\"MAE         : {best_model_info['MAE']:.4f}\")\n",
    "        \n",
    "        print(\"\\n--- Taula Completa de Resultats (ordenada per Pearson descendent) ---\")\n",
    "        display(df_results.sort_values(by='Pearson', ascending=False).reset_index(drop=True))\n",
    "    else:\n",
    "        print(\"No s'han trobat resultats vàlids amb la mètrica Pearson per determinar el millor model.\")\n",
    "else:\n",
    "    print(\"El DataFrame de resultats està buit. No es pot determinar el millor model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b45923",
   "metadata": {},
   "source": [
    "**Avaluació Final en el Conjunt de Test**\n",
    "\n",
    "Després d'haver experimentat amb diversos models i configuracions en el conjunt de validació, i havent identificat el model amb millor rendiment (que s'espera sigui el RoBERTa fine-tuned per STS), és crucial avaluar aquest model en el conjunt de test. El conjunt de test és un conjunt de dades que el model no ha vist mai, ni directament (entrenament) ni indirectament (ajust d'hiperparàmetres o selecció de model basat en validació). Aquesta avaluació proporciona una estimació més realista de com el model generalitzarà a dades noves.\n",
    "\n",
    "**Procés:**\n",
    "1.  S'utilitza el model RoBERTa fine-tuned per STS (`projecte-aina/roberta-base-ca-v2-cased-sts`) a través de la `pipeline` de `transformers`.\n",
    "2.  Es preparen els parells de frases del conjunt de test (`test_df`).\n",
    "3.  Es fan prediccions de similitud per a aquests parells.\n",
    "4.  Les prediccions (originalment en `[0,1]`) s'escalen a `[0,5]`.\n",
    "5.  Es calculen les mètriques (Pearson, MSE, MAE) comparant les prediccions amb les etiquetes reals del conjunt de test.\n",
    "\n",
    "Els resultats obtinguts en el conjunt de test són els que es reportarien com el rendiment final del sistema desenvolupat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bdc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaluació final en test amb RoBERTa STS fine-tuned\n",
    "# (Assumint que aquest és el millor model identificat)\n",
    "\n",
    "print(\"=== AVALUACIÓ FINAL EN EL CONJUNT DE TEST (amb RoBERTa STS Fine-tuned) ===\")\n",
    "\n",
    "# Comprovar disponibilitat de GPU per a PyTorch\n",
    "device_test = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipeline_device_idx_test = 0 if device_test.type == \"cuda\" else -1\n",
    "print(f\"Utilitzant dispositiu per a l'avaluació en test: {device_test} (índex pipeline: {pipeline_device_idx_test})\")\n",
    "\n",
    "try:\n",
    "    sts_model_name_test = 'projecte-aina/roberta-base-ca-v2-cased-sts'\n",
    "    # Recrear la pipeline per al test (bona pràctica per si s'havia eliminat)\n",
    "    sts_pipe_test = pipeline('text-classification', model=sts_model_name_test, device=pipeline_device_idx_test)\n",
    "    sts_ft_model_for_test_available = True\n",
    "except Exception as e:\n",
    "    print(f\"Error carregant el model RoBERTa STS fine-tuned per al test: {e}\")\n",
    "    print(\"Saltant l'avaluació en el conjunt de test.\")\n",
    "    sts_ft_model_for_test_available = False\n",
    "\n",
    "\n",
    "if sts_ft_model_for_test_available:\n",
    "    # Preparar parelles de frases del conjunt de test\n",
    "    test_sentence_pairs = [(row['sentence_1'], row['sentence_2']) for _, row in test_df.iterrows()]\n",
    "    test_true_labels = test_df['label'].values\n",
    "\n",
    "    print(\"Obtenint prediccions per al conjunt de test...\")\n",
    "    # Obtenir scores bruts (assumits en [0,1]) del model\n",
    "    # Utilitzar la funció get_sts_scores_from_pipeline definida anteriorment\n",
    "    raw_predictions_test = get_sts_scores_from_pipeline(test_sentence_pairs, sts_pipe_test, batch_size_pipe=16) # Ajustar batch_size si cal\n",
    "    raw_predictions_test = np.array(raw_predictions_test)\n",
    "\n",
    "    # Escalar els scores de [0,1] a [0,5]\n",
    "    scaled_predictions_test = raw_predictions_test * 5.0\n",
    "    scaled_predictions_test = np.clip(scaled_predictions_test, 0, 5) # Assegurar límits\n",
    "\n",
    "    # Verificar valors problemàtics (NaN, Inf)\n",
    "    if np.any(np.isnan(scaled_predictions_test)) or np.any(np.isinf(scaled_predictions_test)):\n",
    "        print(\"Avís: S'han trobat valors NaN o Inf en les prediccions del test. S'estan substituint.\")\n",
    "        mean_label_test = np.mean(test_true_labels[~np.isnan(test_true_labels)])\n",
    "        scaled_predictions_test = np.nan_to_num(scaled_predictions_test, nan=mean_label_test, \n",
    "                                                posinf=5.0, neginf=0.0)\n",
    "\n",
    "    # Calcular mètriques en el conjunt de test\n",
    "    pearson_corr_test, p_value_test = pearsonr(test_true_labels, scaled_predictions_test)\n",
    "    mse_test = mean_squared_error(test_true_labels, scaled_predictions_test)\n",
    "    mae_test = mean_absolute_error(test_true_labels, scaled_predictions_test)\n",
    "\n",
    "    print(f\"\\n--- RESULTATS EN EL CONJUNT DE TEST (RoBERTa STS Fine-tuned) ---\")\n",
    "    print(f\"Correlació de Pearson: {pearson_corr_test:.4f} (p-value: {p_value_test:.3g})\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse_test:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae_test:.4f}\")\n",
    "\n",
    "    # Guardar aquests resultats finals si es desitja\n",
    "    test_results_summary = {\n",
    "        'Model': 'RoBERTa STS Fine-tuned (AINA) - TEST SET',\n",
    "        'Dimensions': 'N/A (Model Complet)',\n",
    "        'Pearson': pearson_corr_test,\n",
    "        'MSE': mse_test,\n",
    "        'MAE': mae_test,\n",
    "        'P-Value (Pearson)': p_value_test\n",
    "    }\n",
    "    print(\"\\nResum dels resultats en el conjunt de test:\")\n",
    "    for key, value in test_results_summary.items():\n",
    "        print(f\"{key:<25}: {value:.4f}\" if isinstance(value, float) else f\"{key:<25}: {value}\")\n",
    "        \n",
    "    # Netejar memòria\n",
    "    del sts_pipe_test\n",
    "    if device_test.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"No s'ha pogut realitzar l'avaluació en el conjunt de test perquè el model RoBERTa STS fine-tuned no està disponible.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71389e",
   "metadata": {},
   "source": [
    "# Part 2: Classificació de Text amb el Dataset TECLA\n",
    "\n",
    "En aquesta segona part del notebook, canviem de tasca i ens centrem en la **classificació de text**. Utilitzarem el dataset **TECLA (Text Classification for Catalan)**, també del projecte AINA. L'objectiu és classificar fragments de text en català en categories predefinides.\n",
    "\n",
    "**Estructura d'aquesta secció:**\n",
    "\n",
    "1.  **Càrrega i Exploració del Dataset TECLA**:\n",
    "    *   Carregarem el dataset TECLA utilitzant la llibreria `datasets`.\n",
    "    *   Explorarem la seva estructura, el nombre de mostres, les classes (etiquetes) presents i la seva distribució.\n",
    "    *   Es mostrarà un fallback a un dataset sintètic si TECLA no es pot carregar, per permetre l'execució del codi.\n",
    "\n",
    "2.  **Preparació de Dades i Models per a Classificació**:\n",
    "    *   Adaptarem les tècniques d'embedding i modelatge vistes anteriorment (per a STS) a la nova tasca de classificació.\n",
    "    *   **Model de Classificació amb Embeddings Agregats**:\n",
    "        *   Es definiran funcions per preparar les dades: convertir text a un embedding de frase (mitjana simple de Word2Vec) i codificar les etiquetes de classe.\n",
    "        *   Es construirà un model de xarxa neuronal similar al Model 1 de STS, però amb una capa de sortida `softmax` per a la classificació multiclase.\n",
    "        *   S'entrenarà i avaluarà aquest model per a diferents dimensions d'embeddings Word2Vec.\n",
    "    *   **Model de Classificació amb Seqüències d'Embeddings**:\n",
    "        *   Es definiran funcions per preparar les dades: convertir text a seqüències d'índexs de paraules.\n",
    "        *   Es construirà un model de xarxa neuronal que processi aquestes seqüències, utilitzant una capa d'embedding (potencialment pre-entrenada i congelada) seguida de pooling i capes denses amb sortida `softmax`.\n",
    "        *   S'entrenarà i avaluarà aquest model.\n",
    "\n",
    "3.  **Anàlisi de Resultats de Classificació**:\n",
    "    *   Es compararan els resultats (principalment `accuracy` i `classification_report`) dels diferents models i configuracions.\n",
    "    *   Es visualitzaran mètriques com la matriu de confusió per al millor model.\n",
    "\n",
    "Aquesta part permetrà veure com les representacions apreses o utilitzades per a STS poden ser (o no) efectives per a una tasca diferent com la classificació de text, i com es poden adaptar les arquitectures de models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8acaa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nou cell per TECLA Classification\n",
    "print(\"=== PART 2: CLASSIFICACIÓ DE TEXT AMB EL DATASET TECLA ===\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from tensorflow.keras.utils import to_categorical # No s'utilitza si s'usa sparse_categorical_crossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carregar el dataset TECLA\n",
    "print(\"Carregant dataset TECLA...\")\n",
    "tecla_dataset_loaded_successfully = False\n",
    "try:\n",
    "    tecla_train_raw = load_dataset(\"projecte-aina/tecla\", split=\"train\")\n",
    "    tecla_test_raw = load_dataset(\"projecte-aina/tecla\", split=\"test\")\n",
    "    tecla_val_raw = load_dataset(\"projecte-aina/tecla\", split=\"validation\")\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    train_df_tecla = pd.DataFrame(tecla_train_raw)\n",
    "    test_df_tecla = pd.DataFrame(tecla_test_raw)\n",
    "    val_df_tecla = pd.DataFrame(tecla_val_raw)\n",
    "    \n",
    "    print(f\"Dataset TECLA carregat amb èxit.\")\n",
    "    print(f\"Mostres d'entrenament (train): {len(train_df_tecla)}\")\n",
    "    print(f\"Mostres de prova (test): {len(test_df_tecla)}\")\n",
    "    print(f\"Mostres de validació (validation): {len(val_df_tecla)}\")\n",
    "    \n",
    "    # Explorar les etiquetes\n",
    "    print(f\"\\nClasses úniques en el conjunt d'entrenament: {train_df_tecla['label'].unique()}\")\n",
    "    print(f\"Distribució de classes en el conjunt d'entrenament:\")\n",
    "    print(train_df_tecla['label'].value_counts(normalize=True).apply(lambda x: f\"{x:.2%}\")) # Mostrar percentatges\n",
    "    \n",
    "    # Mostrar exemples\n",
    "    print(\"\\nExemples del dataset TECLA (entrenament):\")\n",
    "    for i in range(min(3, len(train_df_tecla))): # Assegurar que no excedeixi el nombre de mostres\n",
    "        print(f\"  Text: {train_df_tecla.iloc[i]['text'][:150]}...\") # Limitar longitud del text mostrat\n",
    "        print(f\"  Label: {train_df_tecla.iloc[i]['label']} (Tipus: {type(train_df_tecla.iloc[i]['label'])})\")\n",
    "        print(\"-\" * 60)\n",
    "    tecla_dataset_loaded_successfully = True\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error carregant el dataset TECLA des de Hugging Face: {e}\")\n",
    "    print(\"Creant un dataset sintètic per a la demostració de la classificació...\")\n",
    "    \n",
    "    # Dataset sintètic si TECLA no està disponible\n",
    "    # Categories més representatives (simulant un problema de sentiment o tòpic simple)\n",
    "    synthetic_texts_cat = {\n",
    "        \"esports\": [\n",
    "            \"El Barça guanya la lliga amb un partit emocionant.\",\n",
    "            \"Resultats de la jornada de futbol.\",\n",
    "            \"El jugador estrella marca dos gols.\",\n",
    "            \"Crònica del partit de bàsquet.\",\n",
    "            \"Nova temporada de la Formula 1.\"\n",
    "        ] * 40, # 200 mostres\n",
    "        \"cultura\": [\n",
    "            \"Nova exposició al museu d'art contemporani.\",\n",
    "            \"Ressenya de l'últim llibre de l'autor català.\",\n",
    "            \"El festival de cinema presenta la seva programació.\",\n",
    "            \"Concert de música clàssica a l'auditori.\",\n",
    "            \"Obra de teatRecomanada per la crítica.\"\n",
    "        ] * 40, # 200 mostres\n",
    "        \"economia\": [\n",
    "            \"La borsa puja després de l'anunci del banc central.\",\n",
    "            \"Informe sobre l'estat de l'economia global.\",\n",
    "            \"Noves mesures fiscals aprovades pel govern.\",\n",
    "            \"L'atur disminueix lleugerament aquest trimestre.\",\n",
    "            \"Inversió estrangera en el sector tecnològic.\"\n",
    "        ] * 40  # 200 mostres\n",
    "    }\n",
    "    \n",
    "    all_synthetic_texts = []\n",
    "    all_synthetic_labels = []\n",
    "    for label, texts in synthetic_texts_cat.items():\n",
    "        all_synthetic_texts.extend(texts)\n",
    "        all_synthetic_labels.extend([label] * len(texts))\n",
    "        \n",
    "    # Barrejar les dades sintètiques\n",
    "    from sklearn.utils import shuffle\n",
    "    all_synthetic_texts, all_synthetic_labels = shuffle(all_synthetic_texts, all_synthetic_labels, random_state=42)\n",
    "\n",
    "    # Dividir en train, val, test (aproximadament 60%, 20%, 20%)\n",
    "    total_samples = len(all_synthetic_texts)\n",
    "    train_end = int(total_samples * 0.6)\n",
    "    val_end = int(total_samples * 0.8)\n",
    "\n",
    "    train_df_tecla = pd.DataFrame({\n",
    "        'text': all_synthetic_texts[:train_end],\n",
    "        'label': all_synthetic_labels[:train_end]\n",
    "    })\n",
    "    val_df_tecla = pd.DataFrame({\n",
    "        'text': all_synthetic_texts[train_end:val_end],\n",
    "        'label': all_synthetic_labels[train_end:val_end]\n",
    "    })\n",
    "    test_df_tecla = pd.DataFrame({\n",
    "        'text': all_synthetic_texts[val_end:],\n",
    "        'label': all_synthetic_labels[val_end:]\n",
    "    })\n",
    "    print(f\"\\nDataset sintètic creat:\")\n",
    "    print(f\"Mostres d'entrenament: {len(train_df_tecla)}\")\n",
    "    print(f\"Mostres de validació: {len(val_df_tecla)}\")\n",
    "    print(f\"Mostres de prova: {len(test_df_tecla)}\")\n",
    "    print(f\"Classes (sintètiques): {train_df_tecla['label'].unique()}\")\n",
    "    print(f\"Distribució (sintètica): \\n{train_df_tecla['label'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Assegurar que les columnes necessàries existeixen i no són buides\n",
    "if 'text' not in train_df_tecla.columns or 'label' not in train_df_tecla.columns:\n",
    "    raise ValueError(\"El DataFrame d'entrenament de TECLA (o sintètic) no té les columnes 'text' o 'label'.\")\n",
    "if train_df_tecla.empty:\n",
    "    raise ValueError(\"El DataFrame d'entrenament de TECLA (o sintètic) està buit.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c09c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparació de dades per classificació\n",
    "def prepare_classification_data_aggregated(df: pd.DataFrame, embeddings_dict: Dict[str, np.ndarray], \n",
    "                                         vector_size: int, label_encoder: Optional[LabelEncoder] = None) -> Tuple[np.ndarray, np.ndarray, LabelEncoder]:\n",
    "    \"\"\"\n",
    "    Prepara les dades per al model de classificació amb embeddings agregats (mitjana simple).\n",
    "    Retorna X (embeddings de frases) i Y (etiquetes numèriques), i el LabelEncoder.\n",
    "    \"\"\"\n",
    "    X, Y_text_labels = [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        text = str(row['text']) # Assegurar que el text sigui string\n",
    "        label = row['label']    # L'etiqueta pot ser string o int inicialment\n",
    "        \n",
    "        # Obtenir embedding del text (mitjana simple)\n",
    "        text_embedding = get_sentence_embedding_simple(text, embeddings_dict, vector_size)\n",
    "        \n",
    "        X.append(text_embedding)\n",
    "        Y_text_labels.append(label) # Guardar les etiquetes originals (text o int)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Codificar etiquetes de text a numèriques\n",
    "    if label_encoder is None:\n",
    "        label_encoder = LabelEncoder()\n",
    "        # Ajustar el LabelEncoder amb les etiquetes de text/int\n",
    "        Y_encoded = label_encoder.fit_transform(Y_text_labels)\n",
    "    else:\n",
    "        # Transformar les etiquetes de text/int utilitzant el LabelEncoder ja ajustat\n",
    "        Y_encoded = label_encoder.transform(Y_text_labels)\n",
    "    \n",
    "    return X, Y_encoded, label_encoder\n",
    "\n",
    "\n",
    "def build_classification_model(embedding_dim: int, num_classes: int, \n",
    "                             hidden_size: int = 128, dropout_rate: float = 0.3) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Construeix el model de classificació amb embeddings agregats.\n",
    "    \"\"\"\n",
    "    input_layer = tf.keras.Input(shape=(embedding_dim,), name=\"input_embedding\")\n",
    "    \n",
    "    # Capes de processament\n",
    "    x = tf.keras.layers.BatchNormalization()(input_layer)\n",
    "    x = tf.keras.layers.Dense(hidden_size, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(hidden_size // 2, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Opcional: una capa més petita abans de la sortida\n",
    "    # x = tf.keras.layers.Dense(hidden_size // 4, activation='relu')(x)\n",
    "    # x = tf.keras.layers.Dropout(dropout_rate / 2)(x) # Menys dropout a prop de la sortida\n",
    "    \n",
    "    # Capa de sortida (classificació)\n",
    "    # num_classes ha de ser el nombre exacte de classes úniques\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax', name=\"output_classification\")(x) \n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy', # Perquè les etiquetes Y són enters (0, 1, 2...)\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy'] # Mètrica principal per classificació\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Entrenar models de classificació amb embeddings agregats (Word2Vec)\n",
    "classification_results_agg = {} # Canviat el nom per evitar conflictes\n",
    "\n",
    "# Només executar si kv_model (Word2Vec) i truncated_embeddings estan disponibles\n",
    "# i si el dataset TECLA (o el seu substitut sintètic) s'ha carregat.\n",
    "if kv_model is not None and truncated_embeddings and not train_df_tecla.empty:\n",
    "    print(\"\\n=== ENTRENAMENT DE MODELS DE CLASSIFICACIÓ (TECLA) AMB EMBEDDINGS AGREGATS (Word2Vec) ===\")\n",
    "    \n",
    "    # Obtenir el LabelEncoder ajustat amb totes les etiquetes possibles (train+val+test)\n",
    "    # per assegurar consistència, tot i que només s'hauria d'ajustar amb train.\n",
    "    # Per simplicitat aquí, si les etiquetes són numèriques i comencen des de 0, LabelEncoder ho gestiona bé.\n",
    "    # Si són strings, és crucial ajustar-lo correctament.\n",
    "    \n",
    "    # Ajustar LabelEncoder NOMÉS amb les dades d'entrenament per evitar data leakage\n",
    "    # Primer, assegurem que les etiquetes siguin consistents (p.ex. string)\n",
    "    # Això és important si les etiquetes originals del dataset TECLA són enters però no seqüencials o no comencen en 0.\n",
    "    # Si són strings, LabelEncoder funciona directament.\n",
    "    # Si són enters, LabelEncoder els tractarà com a classes diferents.\n",
    "    \n",
    "    # Crear i ajustar el LabelEncoder amb les dades d'entrenament\n",
    "    # S'ha de fer abans del bucle si es vol que sigui el mateix per a totes les dimensions.\n",
    "    # Però la funció prepare_classification_data_aggregated ja ho gestiona internament.\n",
    "    # Aquí, el primer LabelEncoder creat (per a la primera dimensió) serà reutilitzat.\n",
    "    \n",
    "    shared_label_encoder = None\n",
    "\n",
    "    for dim_cls_agg in [50, 100, 150, 300]: # Dimensions dels embeddings Word2Vec a provar\n",
    "        if dim_cls_agg in truncated_embeddings:\n",
    "            print(f\"\\n--- Entrenant Model de Classificació Agregat {dim_cls_agg}D ---\")\n",
    "            \n",
    "            # Preparar dades d'entrenament\n",
    "            X_train_cls_agg, Y_train_cls_agg, current_le = prepare_classification_data_aggregated(\n",
    "                train_df_tecla, truncated_embeddings[dim_cls_agg], dim_cls_agg, shared_label_encoder\n",
    "            )\n",
    "            if shared_label_encoder is None: # Guardar el primer LabelEncoder creat\n",
    "                shared_label_encoder = current_le\n",
    "\n",
    "            # Preparar dades de validació utilitzant el LabelEncoder ajustat amb les dades d'entrenament\n",
    "            X_val_cls_agg, Y_val_cls_agg, _ = prepare_classification_data_aggregated(\n",
    "                val_df_tecla, truncated_embeddings[dim_cls_agg], dim_cls_agg, shared_label_encoder\n",
    "            )\n",
    "            \n",
    "            num_classes_tecla = len(shared_label_encoder.classes_)\n",
    "            print(f\"Nombre de classes detectades pel LabelEncoder: {num_classes_tecla}\")\n",
    "            print(f\"Classes (mapejades per LabelEncoder): {list(shared_label_encoder.classes_)}\")\n",
    "            # print(f\"Exemple d'etiquetes codificades (train): {Y_train_cls_agg[:5]}\")\n",
    "            \n",
    "            print(f\"Forma de les dades d'entrenament: X_train={X_train_cls_agg.shape}, Y_train={Y_train_cls_agg.shape}\")\n",
    "            print(f\"Forma de les dades de validació: X_val={X_val_cls_agg.shape}, Y_val={Y_val_cls_agg.shape}\")\n",
    "            \n",
    "            if num_classes_tecla <= 1:\n",
    "                print(f\"Avís: Només s'ha detectat {num_classes_tecla} classe. La classificació no és possible o trivial. Saltant entrenament per a {dim_cls_agg}D.\")\n",
    "                continue\n",
    "\n",
    "            # Construir i entrenar model\n",
    "            model_cls_agg = build_classification_model(\n",
    "                embedding_dim=dim_cls_agg, \n",
    "                num_classes=num_classes_tecla,\n",
    "                hidden_size=256, # Potser una mica més gran per classificació\n",
    "                dropout_rate=0.4\n",
    "            )\n",
    "            \n",
    "            # Callbacks\n",
    "            early_stopping_cls = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_accuracy', \n",
    "                patience=10, # Més paciència per a accuracy\n",
    "                restore_best_weights=True, \n",
    "                verbose=1,\n",
    "                mode='max' # Maximitzar accuracy\n",
    "            )\n",
    "            \n",
    "            reduce_lr_cls = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss', \n",
    "                factor=0.2, # Reducció més agressiva\n",
    "                patience=5, \n",
    "                min_lr=1e-7, # Permetre learning rates més baixos\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            print(\"Iniciant entrenament del model de classificació agregat...\")\n",
    "            history_cls_agg = model_cls_agg.fit(\n",
    "                X_train_cls_agg, Y_train_cls_agg,\n",
    "                validation_data=(X_val_cls_agg, Y_val_cls_agg),\n",
    "                epochs=50, # Mantenir un nombre raonable d'èpoques\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stopping_cls, reduce_lr_cls],\n",
    "                verbose=1 # Mostrar progrés de l'entrenament\n",
    "            )\n",
    "            \n",
    "            # Avaluació en el conjunt de validació\n",
    "            print(\"Avaluant model en el conjunt de validació...\")\n",
    "            loss_val, accuracy_val = model_cls_agg.evaluate(X_val_cls_agg, Y_val_cls_agg, verbose=0)\n",
    "            \n",
    "            Y_pred_probs_cls_agg = model_cls_agg.predict(X_val_cls_agg)\n",
    "            Y_pred_classes_cls_agg = np.argmax(Y_pred_probs_cls_agg, axis=1) # Obtenir la classe predita\n",
    "            \n",
    "            classification_results_agg[dim_cls_agg] = {\n",
    "                'model': model_cls_agg,\n",
    "                'history': history_cls_agg,\n",
    "                'accuracy': accuracy_val, # Usar l'accuracy de model.evaluate\n",
    "                'predictions_classes': Y_pred_classes_cls_agg,\n",
    "                'label_encoder': shared_label_encoder, # Guardar el LE per a la descodificació\n",
    "                'y_true_encoded': Y_val_cls_agg # Guardar les etiquetes reals codificades\n",
    "            }\n",
    "            \n",
    "            print(f\"Resultats Classificació Agregada {dim_cls_agg}D - Accuracy (validació): {accuracy_val:.4f}\")\n",
    "            \n",
    "            # Report de classificació detallat\n",
    "            print(\"\\nClassification Report (validació):\")\n",
    "            # Assegurar que target_names siguin strings per al report\n",
    "            target_names_str = [str(cls_name) for cls_name in shared_label_encoder.classes_]\n",
    "            print(classification_report(\n",
    "                Y_val_cls_agg, Y_pred_classes_cls_agg, \n",
    "                target_names=target_names_str,\n",
    "                zero_division=0 # Evitar warnings si alguna classe no té prediccions/suport\n",
    "            ))\n",
    "else:\n",
    "    print(\"Saltant l'entrenament de models de classificació agregats: kv_model, truncated_embeddings o train_df_tecla no disponibles.\")\n",
    "\n",
    "# Netejar la variable global si ja no es necessita fora d'aquest context específic\n",
    "# del if kv_model...\n",
    "# if 'shared_label_encoder' in globals() and not (kv_model is not None and truncated_embeddings and not train_df_tecla.empty):\n",
    "#    del shared_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73785597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualització de resultats de classificació (Models Agregats)\n",
    "if classification_results_agg: # Comprovar si hi ha resultats per mostrar\n",
    "    print(\"\\n=== COMPARACIÓ MODELS DE CLASSIFICACIÓ AGREGATS (TECLA) ===\")\n",
    "\n",
    "    # Crear DataFrame amb resultats d'accuracy\n",
    "    classification_data_agg_list = []\n",
    "    for dim_res, results_res in classification_results_agg.items():\n",
    "        classification_data_agg_list.append({\n",
    "            'Model Tipus': 'Classificació Agregada (Word2Vec)',\n",
    "            'Dimensions Embedding': f'{dim_res}D',\n",
    "            'Accuracy Validació': results_res['accuracy']\n",
    "        })\n",
    "\n",
    "    df_classification_agg_summary = pd.DataFrame(classification_data_agg_list)\n",
    "    if not df_classification_agg_summary.empty:\n",
    "        display(df_classification_agg_summary.sort_values('Accuracy Validació', ascending=False).style.hide(axis=\"index\"))\n",
    "    else:\n",
    "        print(\"No hi ha dades de resum de classificació agregada per mostrar.\")\n",
    "\n",
    "    # Trobar el millor model de classificació agregat basat en accuracy\n",
    "    best_cls_agg_dim = -1\n",
    "    best_cls_agg_accuracy = -1\n",
    "\n",
    "    for dim_val, result_val in classification_results_agg.items():\n",
    "        if result_val['accuracy'] > best_cls_agg_accuracy:\n",
    "            best_cls_agg_accuracy = result_val['accuracy']\n",
    "            best_cls_agg_dim = dim_val\n",
    "            \n",
    "    if best_cls_agg_dim != -1:\n",
    "        best_cls_agg_model_info = classification_results_agg[best_cls_agg_dim]\n",
    "        \n",
    "        print(f\"\\n🏆 MILLOR MODEL DE CLASSIFICACIÓ AGREGADA (Word2Vec):\")\n",
    "        print(f\"  Dimensions Embedding: {best_cls_agg_dim}D\")\n",
    "        print(f\"  Accuracy (validació): {best_cls_agg_model_info['accuracy']:.4f}\")\n",
    "        \n",
    "        # Matriu de confusió per al millor model agregat\n",
    "        y_true_best_agg = best_cls_agg_model_info['y_true_encoded']\n",
    "        y_pred_classes_best_agg = best_cls_agg_model_info['predictions_classes']\n",
    "        current_le_best_agg = best_cls_agg_model_info['label_encoder']\n",
    "        \n",
    "        cm_agg = confusion_matrix(y_true_best_agg, y_pred_classes_best_agg)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8)) # Ajustar mida per a més classes\n",
    "        # Assegurar que les etiquetes de la matriu de confusió siguin strings\n",
    "        cm_target_names_str = [str(cls_name) for cls_name in current_le_best_agg.classes_]\n",
    "        sns.heatmap(cm_agg, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=cm_target_names_str,\n",
    "                    yticklabels=cm_target_names_str)\n",
    "        plt.title(f'Matriu de Confusió - Millor Model Agregat ({best_cls_agg_dim}D)')\n",
    "        plt.ylabel('Etiqueta Real')\n",
    "        plt.xlabel('Etiqueta Predita')\n",
    "        plt.xticks(rotation=45, ha='right') # Rotar etiquetes si són llargues\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No s'ha pogut determinar el millor model de classificació agregat.\")\n",
    "        \n",
    "    # Gràfic d'accuracy per dimensions (models agregats)\n",
    "    dims_agg_plot = sorted(list(classification_results_agg.keys()))\n",
    "    accuracies_agg_plot = [classification_results_agg[d]['accuracy'] for d in dims_agg_plot]\n",
    "    \n",
    "    if dims_agg_plot: # Només graficar si hi ha dades\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar([f'{d}D' for d in dims_agg_plot], accuracies_agg_plot, alpha=0.75, color='cornflowerblue', edgecolor='black')\n",
    "        plt.title('Accuracy (Validació) dels Models de Classificació Agregats per Dimensions')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Dimensions dels Embeddings Word2Vec')\n",
    "        plt.ylim(0, 1.05) # Ajustar límit superior per al text\n",
    "        \n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f'{yval:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No hi ha resultats de classificació agregada per visualitzar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459577a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model de classificació amb seqüències\n",
    "def prepare_classification_data_sequence(df: pd.DataFrame, word_to_idx_map: Dict[str, int], \n",
    "                                       max_len_seq: int = 32, # Renombrat per evitar conflicte amb global sequence_length\n",
    "                                       label_encoder: Optional[LabelEncoder] = None) -> Tuple[np.ndarray, np.ndarray, LabelEncoder]:\n",
    "    \"\"\"\n",
    "    Prepara les dades per al model de classificació amb seqüències.\n",
    "    Retorna X_seq (seqüències d'índexs) i Y (etiquetes numèriques), i el LabelEncoder.\n",
    "    \"\"\"\n",
    "    X_sequences, Y_text_labels_seq = [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        text = str(row['text']) # Assegurar que el text sigui string\n",
    "        label = row['label']\n",
    "        \n",
    "        # Convertir text a seqüència d'índexs\n",
    "        text_seq_indices = sentence_to_sequence(text, word_to_idx_map, max_len_seq) # Utilitzar sentence_to_sequence existent\n",
    "        \n",
    "        X_sequences.append(text_seq_indices)\n",
    "        Y_text_labels_seq.append(label)\n",
    "    \n",
    "    X_sequences = np.array(X_sequences)\n",
    "    \n",
    "    # Codificar etiquetes de text a numèriques\n",
    "    if label_encoder is None:\n",
    "        label_encoder = LabelEncoder()\n",
    "        Y_encoded_seq = label_encoder.fit_transform(Y_text_labels_seq)\n",
    "    else:\n",
    "        Y_encoded_seq = label_encoder.transform(Y_text_labels_seq)\n",
    "    \n",
    "    return X_sequences, Y_encoded_seq, label_encoder\n",
    "\n",
    "\n",
    "def build_classification_model_sequence(vocab_size_cls: int, # Renombrat per evitar conflicte\n",
    "                                       embedding_dim_cls: int, # Renombrat\n",
    "                                       num_classes_cls: int, # Renombrat\n",
    "                                       seq_len_cls: int = 32, # Renombrat\n",
    "                                       pretrained_weights_matrix: Optional[np.ndarray] = None, # Renombrat\n",
    "                                       train_embedding_layer: bool = False # Permetre entrenar la capa d'embedding\n",
    "                                       ) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Model de classificació amb seqüències d'embeddings.\n",
    "    \"\"\"\n",
    "    input_layer_seq = tf.keras.Input(shape=(seq_len_cls,), dtype=tf.int32, name=\"input_sequence_classification\")\n",
    "    \n",
    "    # Capa d'embedding\n",
    "    if pretrained_weights_matrix is not None:\n",
    "        # Utilitzar embeddings pre-entrenats\n",
    "        embedding_layer_cls = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size_cls, # Mida del vocabulari\n",
    "            output_dim=embedding_dim_cls, # Dimensió de l'embedding\n",
    "            input_length=seq_len_cls,\n",
    "            weights=[pretrained_weights_matrix], # Matriu d'embeddings pre-entrenats\n",
    "            trainable=train_embedding_layer, # Decidir si es fa fine-tuning o no\n",
    "            mask_zero=True # Ignorar padding (índex 0)\n",
    "        )\n",
    "    else:\n",
    "        # Aprendre embeddings des de zero\n",
    "        embedding_layer_cls = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size_cls,\n",
    "            output_dim=embedding_dim_cls,\n",
    "            input_length=seq_len_cls,\n",
    "            trainable=True, # Sempre entrenable si no hi ha pre-entrenats\n",
    "            mask_zero=True\n",
    "        )\n",
    "    \n",
    "    embedded_sequences = embedding_layer_cls(input_layer_seq)\n",
    "    \n",
    "    # Processament de seqüència: GlobalAveragePooling1D és una opció simple i efectiva\n",
    "    # Alternativament, es podria usar LSTM, GRU, o Conv1D\n",
    "    x_seq = tf.keras.layers.GlobalAveragePooling1D()(embedded_sequences)\n",
    "    # x_seq = tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)(embedded_sequences) # Alternativa\n",
    "    \n",
    "    # Capes denses per a la classificació\n",
    "    x_seq = tf.keras.layers.BatchNormalization()(x_seq)\n",
    "    x_seq = tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x_seq)\n",
    "    x_seq = tf.keras.layers.Dropout(0.4)(x_seq) # Dropout més alt pot ajudar\n",
    "    \n",
    "    x_seq = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x_seq)\n",
    "    x_seq = tf.keras.layers.Dropout(0.4)(x_seq)\n",
    "    \n",
    "    # Sortida\n",
    "    output_seq = tf.keras.layers.Dense(num_classes_cls, activation='softmax', name=\"output_classification_sequence\")(x_seq)\n",
    "    \n",
    "    model_seq_classification = tf.keras.Model(inputs=input_layer_seq, outputs=output_seq)\n",
    "    \n",
    "    model_seq_classification.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # Potser provar 0.0005\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model_seq_classification\n",
    "\n",
    "\n",
    "# Entrenar model de seqüència per classificació (TECLA)\n",
    "print(\"\\n=== ENTRENAMENT DE MODELS DE SEQÜÈNCIA PER CLASSIFICACIÓ (TECLA) ===\")\n",
    "\n",
    "classification_results_seq = {} # Resultats per als models de seqüència\n",
    "\n",
    "# Assegurar que les variables globals necessàries (word_to_idx, vocab_size, sequence_length)\n",
    "# de la part de STS estiguin disponibles i siguin correctes.\n",
    "# També, kv_model i truncated_embeddings per a la matriu pre-entrenada.\n",
    "# I el LabelEncoder dels models agregats (shared_label_encoder) per consistència.\n",
    "\n",
    "if 'word_to_idx' in globals() and 'vocab_size' in globals() and 'sequence_length' in globals() and \\\n",
    "   kv_model is not None and truncated_embeddings and not train_df_tecla.empty and \\\n",
    "   'shared_label_encoder' in globals() and shared_label_encoder is not None:\n",
    "\n",
    "    # Preparar dades de seqüència per a classificació (una sola vegada)\n",
    "    # Utilitzar el vocabulari i la longitud de seqüència definits per STS per coherència\n",
    "    # i el LabelEncoder dels models agregats de classificació.\n",
    "    print(f\"Utilitzant vocabulari de STS: {vocab_size} paraules, longitud de seqüència: {sequence_length}\")\n",
    "    \n",
    "    X_train_cls_seq, Y_train_cls_seq, le_seq_cls_train = prepare_classification_data_sequence(\n",
    "        train_df_tecla, word_to_idx, sequence_length, shared_label_encoder\n",
    "    )\n",
    "    X_val_cls_seq, Y_val_cls_seq, _ = prepare_classification_data_sequence(\n",
    "        val_df_tecla, word_to_idx, sequence_length, shared_label_encoder\n",
    "    )\n",
    "\n",
    "    num_classes_tecla_seq = len(shared_label_encoder.classes_)\n",
    "    print(f\"Nombre de classes per al model de seqüència: {num_classes_tecla_seq}\")\n",
    "    print(f\"Forma de les dades de seqüència (train): X={X_train_cls_seq.shape}, Y={Y_train_cls_seq.shape}\")\n",
    "\n",
    "    if num_classes_tecla_seq <= 1:\n",
    "        print(\"Avís: Només s'ha detectat 1 classe o menys. Saltant entrenament de models de seqüència.\")\n",
    "    else:\n",
    "        for dim_cls_seq in [50, 100, 150, 300]: # Dimensions dels embeddings Word2Vec a provar\n",
    "            if dim_cls_seq in truncated_embeddings:\n",
    "                print(f\"\\n--- Entrenant Model de Classificació de Seqüència {dim_cls_seq}D ---\")\n",
    "                \n",
    "                # Preparar matriu d'embeddings pre-entrenats (Word2Vec)\n",
    "                pretrained_matrix_cls = create_pretrained_embedding_matrix(\n",
    "                    word_to_idx, truncated_embeddings[dim_cls_seq], dim_cls_seq\n",
    "                )\n",
    "                \n",
    "                # Construir model de seqüència per classificació\n",
    "                # Provarem amb embeddings pre-entrenats congelats (train_embedding_layer=False)\n",
    "                # i després amb entrenables (train_embedding_layer=True)\n",
    "                \n",
    "                for trainable_emb_flag in [False, True]:\n",
    "                    config_name = \"FrozenEmb\" if not trainable_emb_flag else \"TrainableEmb\"\n",
    "                    print(f\"  Configuració: Embeddings {config_name}\")\n",
    "\n",
    "                    model_classification_seq = build_classification_model_sequence(\n",
    "                        vocab_size_cls=vocab_size, # Mida del vocabulari global\n",
    "                        embedding_dim_cls=dim_cls_seq,\n",
    "                        num_classes_cls=num_classes_tecla_seq,\n",
    "                        seq_len_cls=sequence_length, # Longitud de seqüència global\n",
    "                        pretrained_weights_matrix=pretrained_matrix_cls,\n",
    "                        train_embedding_layer=trainable_emb_flag \n",
    "                    )\n",
    "                    \n",
    "                    # Callbacks\n",
    "                    early_stopping_cls_seq = tf.keras.callbacks.EarlyStopping(\n",
    "                        monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1, mode='max'\n",
    "                    )\n",
    "                    reduce_lr_cls_seq = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                        monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7, verbose=1\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"  Iniciant entrenament (Embeddings {config_name})...\")\n",
    "                    history_cls_seq = model_classification_seq.fit(\n",
    "                        X_train_cls_seq, Y_train_cls_seq,\n",
    "                        validation_data=(X_val_cls_seq, Y_val_cls_seq),\n",
    "                        epochs=40, # Una mica menys d'èpoques per a la cerca ràpida\n",
    "                        batch_size=32,\n",
    "                        callbacks=[early_stopping_cls_seq, reduce_lr_cls_seq],\n",
    "                        verbose=0 # Menys verbositat per a múltiples entrenaments\n",
    "                    )\n",
    "                    \n",
    "                    # Avaluació\n",
    "                    loss_val_seq, accuracy_val_seq = model_classification_seq.evaluate(X_val_cls_seq, Y_val_cls_seq, verbose=0)\n",
    "                    \n",
    "                    # Guardar resultats per a aquesta configuració específica\n",
    "                    result_key = f\"{dim_cls_seq}D_{config_name}\"\n",
    "                    classification_results_seq[result_key] = {\n",
    "                        'model': model_classification_seq,\n",
    "                        'accuracy': accuracy_val_seq,\n",
    "                        'dimensions': dim_cls_seq,\n",
    "                        'embedding_type': config_name\n",
    "                        # Es podrien guardar prediccions, etc., si fos necessari\n",
    "                    }\n",
    "                    print(f\"  Resultats Classificació Seqüència {dim_cls_seq}D ({config_name}) - Accuracy (validació): {accuracy_val_seq:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Saltant l'entrenament de models de classificació de seqüència: \"\n",
    "          \"Variables globals (word_to_idx, etc.), kv_model, truncated_embeddings, \"\n",
    "          \"train_df_tecla o shared_label_encoder no disponibles o buits.\")\n",
    "\n",
    "\n",
    "# Comparació final de tots els models de classificació per a TECLA\n",
    "print(\"\\n=== COMPARACIÓ FINAL MODELS DE CLASSIFICACIÓ (TECLA) ===\")\n",
    "final_classification_results_list = []\n",
    "\n",
    "# Afegir resultats dels models agregats\n",
    "if classification_results_agg:\n",
    "    for dim_agg, results_agg_val in classification_results_agg.items():\n",
    "        final_classification_results_list.append({\n",
    "            'Model Tipus': 'Classificació Agregada (Word2Vec)',\n",
    "            'Configuració Embedding': f'{dim_agg}D',\n",
    "            'Accuracy Validació': results_agg_val['accuracy']\n",
    "        })\n",
    "\n",
    "# Afegir resultats dels models de seqüència\n",
    "if classification_results_seq:\n",
    "    for key_seq, results_seq_val in classification_results_seq.items():\n",
    "        final_classification_results_list.append({\n",
    "            'Model Tipus': 'Classificació Seqüència (Word2Vec)',\n",
    "            'Configuració Embedding': f\"{results_seq_val['dimensions']}D - {results_seq_val['embedding_type']}\",\n",
    "            'Accuracy Validació': results_seq_val['accuracy']\n",
    "        })\n",
    "\n",
    "if final_classification_results_list:\n",
    "    df_final_classification_summary = pd.DataFrame(final_classification_results_list)\n",
    "    display(df_final_classification_summary.sort_values('Accuracy Validació', ascending=False).style.hide(axis=\"index\"))\n",
    "    \n",
    "    # Guardar resultats de classificació TECLA\n",
    "    try:\n",
    "        df_final_classification_summary.to_csv('resultats_tecla_practica4.csv', index=False)\n",
    "        print(\"Resultats de classificació TECLA guardats a 'resultats_tecla_practica4.csv'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error guardant els resultats de TECLA a CSV: {e}\")\n",
    "else:\n",
    "    print(\"No hi ha resultats finals de classificació per mostrar o guardar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695bfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cel·la final per a possibles anàlisis addicionals o neteja\n",
    "\n",
    "print(\"\\n=== FINAL DE LA PRÀCTICA 4 (STS + Classificació TECLA) ===\")\n",
    "\n",
    "# Es podria afegir aquí:\n",
    "# 1. Avaluació del millor model de classificació TECLA en el seu conjunt de test (test_df_tecla).\n",
    "#    - Preparar X_test_cls, Y_test_cls utilitzant el LabelEncoder i word_to_idx adients.\n",
    "#    - Carregar el millor model de classificació guardat (o reentrenar-lo si no s'ha guardat).\n",
    "#    - Fer prediccions i calcular mètriques (accuracy, classification_report, matriu de confusió) en el test set.\n",
    "\n",
    "# 2. Neteja de memòria addicional si fos necessari (eliminar models grans, buidar cache de TensorFlow/PyTorch).\n",
    "#    tf.keras.backend.clear_session() # Per a TensorFlow/Keras\n",
    "#    torch.cuda.empty_cache() # Per a PyTorch (ja fet en seccions anteriors)\n",
    "\n",
    "# 3. Resum executiu de les troballes principals de tota la pràctica.\n",
    "\n",
    "# Exemple de com es podria avaluar el millor model de classificació en el test set:\n",
    "# (Això requeriria identificar quin model va ser el millor i tenir les dades de test preparades)\n",
    "\n",
    "# if final_classification_results_list: # Si hi ha resultats per triar el millor\n",
    "#     df_summary_cls = pd.DataFrame(final_classification_results_list)\n",
    "#     if not df_summary_cls.empty:\n",
    "#         best_cls_config_row = df_summary_cls.sort_values('Accuracy Validació', ascending=False).iloc[0]\n",
    "#         best_cls_model_type = best_cls_config_row['Model Tipus']\n",
    "#         best_cls_config_emb = best_cls_config_row['Configuració Embedding']\n",
    "#         print(f\"\\nMillor configuració de classificació TECLA (validació): {best_cls_model_type} amb {best_cls_config_emb}\")\n",
    "\n",
    "#         # Lògica per recuperar/reconstruir i avaluar el millor model en test_df_tecla...\n",
    "#         # Això és complex perquè el model exacte i els seus paràmetres s'han de recuperar.\n",
    "#         # Per exemple, si el millor va ser un model de seqüència:\n",
    "#         # best_dim_str, best_emb_type_str = best_cls_config_emb.split('D - ') # Extreure info\n",
    "#         # best_dim = int(best_dim_str)\n",
    "#         # best_model_to_test = classification_results_seq[f\"{best_dim}D_{best_emb_type_str}\"]['model']\n",
    "#         # ... preparar X_test_cls_seq, Y_test_cls_seq ...\n",
    "#         # test_loss, test_accuracy = best_model_to_test.evaluate(X_test_cls_seq, Y_test_cls_seq)\n",
    "#         # print(f\"Accuracy en el conjunt de TEST per al millor model de TECLA: {test_accuracy:.4f}\")\n",
    "#         pass # Implementació pendent\n",
    "\n",
    "print(\"\\nRecordatori: Els resultats finals més fiables per a STS s'obtenen del conjunt de test amb el model RoBERTa STS Fine-tuned.\")\n",
    "print(\"Per a la classificació TECLA, s'hauria de realitzar una avaluació similar en el seu conjunt de test.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce57c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa521294",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
